{
    "name": "Some Default",
    "origin": "",
    "cpu_info": {
        "Architecture": "x86_64",
        "CPU op-mode(s)": "32-bit, 64-bit",
        "Byte Order": "Little Endian",
        "Address sizes": "46 bits physical, 48 bits virtual",
        "CPU(s)": "112",
        "On-line CPU(s) list": "0-111",
        "Thread(s) per core": "2",
        "Core(s) per socket": "28",
        "Socket(s)": "2",
        "NUMA node(s)": "2",
        "Vendor ID": "GenuineIntel",
        "CPU family": "6",
        "Model": "85",
        "Model name": "Intel(R) Xeon(R) Platinum 8180 CPU @ 2.50GHz",
        "Stepping": "4",
        "CPU MHz": "2500.060",
        "BogoMIPS": "5000.00",
        "Virtualization": "VT-x",
        "L1d cache": "1.8 MiB",
        "L1i cache": "1.8 MiB",
        "L2 cache": "56 MiB",
        "L3 cache": "77 MiB",
        "NUMA node0 CPU(s)": "0-27,56-83",
        "NUMA node1 CPU(s)": "28-55,84-111",
        "Vulnerability Itlb multihit": "KVM",
        "Vulnerability L1tf": "Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable",
        "Vulnerability Mds": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Vulnerability Meltdown": "Mitigation; PTI",
        "Vulnerability Spec store bypass": "Mitigation; Speculative Store Bypass disabled via prctl and seccomp",
        "Vulnerability Spectre v1": "Mitigation; usercopy/swapgs barriers and __user pointer sanitization",
        "Vulnerability Spectre v2": "Mitigation; Full generic retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling",
        "Vulnerability Srbds": "Not affected",
        "Vulnerability Tsx async abort": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Flags": "fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm arat pln pts pku ospke md_clear flush_l1d"
    },
    "layers": [
        {
            "name": "DistributedDataParallel/op-1",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-1"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 203,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 203,
                "start": 490919,
                "end": 491122
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/op-2",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-2"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 491260,
                "end": 491262
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/op-3",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-3"
            ],
            "outputs": [
                "t-4"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 7,
                "flops": 0.0
            },
            "args": [
                [
                    -1,
                    784
                ]
            ],
            "runtime": {
                "duration": 7,
                "start": 491454,
                "end": 491461
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 45, in forward\n    x = x.view(-1, 28 * 28)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-4",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-4",
                "t-5",
                "t-6"
            ],
            "outputs": [
                "t-7"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 809,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 809,
                "start": 491607,
                "end": 492416
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-5",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-7"
            ],
            "outputs": [
                "t-8"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1320,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 1320,
                "start": 492572,
                "end": 493892
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-6",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-8",
                "t-9",
                "t-10"
            ],
            "outputs": [
                "t-11"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 750,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 750,
                "start": 494024,
                "end": 494774
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-7",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-11"
            ],
            "outputs": [
                "t-12"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 540,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 540,
                "start": 494902,
                "end": 495442
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-8",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-12",
                "t-13",
                "t-14"
            ],
            "outputs": [
                "t-15"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 733,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 733,
                "start": 495561,
                "end": 496294
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-9",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-15"
            ],
            "outputs": [
                "t-16"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 540,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 540,
                "start": 496418,
                "end": 496958
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-10",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-16",
                "t-17",
                "t-18"
            ],
            "outputs": [
                "t-19"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 725,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 725,
                "start": 497081,
                "end": 497806
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-11",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-19"
            ],
            "outputs": [
                "t-20"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 561,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 561,
                "start": 497930,
                "end": 498491
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-12",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-20",
                "t-21",
                "t-22"
            ],
            "outputs": [
                "t-23"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 727,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 727,
                "start": 498612,
                "end": 499339
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-13",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-23"
            ],
            "outputs": [
                "t-24"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 563,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 563,
                "start": 499466,
                "end": 500029
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-14",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-24",
                "t-25",
                "t-26"
            ],
            "outputs": [
                "t-27"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 796,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 796,
                "start": 500152,
                "end": 500948
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-15",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-27"
            ],
            "outputs": [
                "t-28"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 589,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 589,
                "start": 501076,
                "end": 501665
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-16",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-28",
                "t-29",
                "t-30"
            ],
            "outputs": [
                "t-31"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 929,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 929,
                "start": 501790,
                "end": 502719
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-17",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-31"
            ],
            "outputs": [
                "t-32"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1023,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 1023,
                "start": 502916,
                "end": 503939
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-18",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-32",
                "t-33",
                "t-34"
            ],
            "outputs": [
                "t-35"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1048,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 1048,
                "start": 504134,
                "end": 505182
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-19",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-35"
            ],
            "outputs": [
                "t-36"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 568,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 568,
                "start": 505319,
                "end": 505887
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "CrossEntropyLoss/op-20",
            "optype": "aten::cross_entropy_loss",
            "params": {},
            "inputs": [
                "t-36",
                "t-37"
            ],
            "outputs": [
                "t-38"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 951,
                "flops": 0.0
            },
            "args": [
                1,
                -100,
                0.0
            ],
            "runtime": {
                "duration": 951,
                "start": 506067,
                "end": 507018
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    loss = loss_model(output, target)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 1150, in forward\n    return F.cross_entropy(input, target, weight=self.weight,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 2846, in cross_entropy\n    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n"
            ]
        },
        {
            "name": "op-21",
            "optype": "aten::ones_like",
            "params": {},
            "inputs": [
                "t-38"
            ],
            "outputs": [
                "t-39"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 261,
                "flops": 0.0
            },
            "args": [
                6,
                0,
                false,
                1
            ],
            "runtime": {
                "duration": 261,
                "start": 507491,
                "end": 507752
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 172, in train_and_test\n    loss.backward()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 150, in backward\n    grad_tensors_ = _make_grads(tensors, grad_tensors_)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 52, in _make_grads\n    new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/NllLossBackward0/op-22",
            "optype": "aten::nll_loss_backward",
            "params": {},
            "inputs": [
                "t-39",
                "t-40",
                "t-37",
                "t-41",
                "t-42"
            ],
            "outputs": [
                "t-43"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 99,
                "flops": 0.0
            },
            "args": [
                1,
                -100
            ],
            "runtime": {
                "duration": 99,
                "start": 508211,
                "end": 508310
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-23",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-43"
            ],
            "outputs": [
                "t-44"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 508363,
                "end": 508417
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-24",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-44"
            ],
            "outputs": [
                "t-45"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 508455,
                "end": 508506
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-25",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-45"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 57,
                "start": 508539,
                "end": 508596
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/LogSoftmaxBackward0/op-26",
            "optype": "aten::_log_softmax_backward_data",
            "params": {},
            "inputs": [
                "t-43",
                "t-44",
                "t-36"
            ],
            "outputs": [
                "t-46"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 17,
                "start": 508700,
                "end": 508717
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-27",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-46"
            ],
            "outputs": [
                "t-47"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 508750,
                "end": 508788
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-28",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-47"
            ],
            "outputs": [
                "t-48"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 508816,
                "end": 508862
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-29",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-48"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 50,
                "start": 508888,
                "end": 508938
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-30",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-46",
                "t-49"
            ],
            "outputs": [
                "t-50"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 80,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 80,
                "start": 509030,
                "end": 509110
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-31",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-51"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 509142,
                "end": 509180
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-32",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-51"
            ],
            "outputs": [
                "t-52"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 509209,
                "end": 509258
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-33",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-52"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 509286,
                "end": 509333
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-34",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-53"
            ],
            "outputs": [
                "t-54"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 509417,
                "end": 509475
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-35",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    10
                ],
                "mat2_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-50",
                "t-54"
            ],
            "outputs": [
                "t-55"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 23,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 23,
                "start": 509521,
                "end": 509544
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-36",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-56"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 509573,
                "end": 509632
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-37",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    10,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-56",
                "t-32"
            ],
            "outputs": [
                "t-57"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 509659,
                "end": 509675
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-38",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-57"
            ],
            "outputs": [
                "t-58"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 509706,
                "end": 509760
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-39",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-59"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 22,
                "start": 509800,
                "end": 509822
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-40",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-59"
            ],
            "outputs": [
                "t-60"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 509849,
                "end": 509853
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-41",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-60"
            ],
            "outputs": [
                "t-61"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 509889,
                "end": 509933
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-42",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-61"
            ],
            "outputs": [
                "t-62"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 509957,
                "end": 510001
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-43",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-62"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 49,
                "start": 510024,
                "end": 510073
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-44",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-55"
            ],
            "outputs": [
                "t-63"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 510101,
                "end": 510151
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-45",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-63"
            ],
            "outputs": [
                "t-64"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 510176,
                "end": 510234
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-46",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-64"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 510258,
                "end": 510299
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-47",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-65"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 510325,
                "end": 510374
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-48",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-65"
            ],
            "outputs": [
                "t-66"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 510397,
                "end": 510443
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-49",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-66"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 510467,
                "end": 510505
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-50",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-67",
                "t-60"
            ],
            "outputs": [
                "t-68"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 17,
                "start": 510620,
                "end": 510637
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-51",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-68",
                "t-65",
                "t-69"
            ],
            "outputs": [
                "t-70"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 10.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 510691,
                "end": 510708
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-52",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-71"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 510802,
                "end": 510860
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-53",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-71"
            ],
            "outputs": [
                "t-72"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 510889,
                "end": 510931
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-54",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-72"
            ],
            "outputs": [
                "t-73"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 510954,
                "end": 511007
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-55",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-73"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 511031,
                "end": 511071
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-56",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-74",
                "t-71"
            ],
            "outputs": [
                "t-75"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 511160,
                "end": 511174
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-57",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-75",
                "t-72",
                "t-76"
            ],
            "outputs": [
                "t-77"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 5120.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 511220,
                "end": 511233
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-58",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-55",
                "t-78"
            ],
            "outputs": [
                "t-79"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 75,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 75,
                "start": 511324,
                "end": 511399
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-59",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-80"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 511432,
                "end": 511471
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-60",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-80"
            ],
            "outputs": [
                "t-81"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 511494,
                "end": 511551
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-61",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-81"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 511575,
                "end": 511620
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-62",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-82"
            ],
            "outputs": [
                "t-83"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 511706,
                "end": 511760
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-63",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-79",
                "t-83"
            ],
            "outputs": [
                "t-84"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 24,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 24,
                "start": 511789,
                "end": 511813
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-64",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-85"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 511839,
                "end": 511894
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-65",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-85",
                "t-28"
            ],
            "outputs": [
                "t-86"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 511921,
                "end": 511939
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-66",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-86"
            ],
            "outputs": [
                "t-87"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 511970,
                "end": 512026
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-67",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-88"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 512053,
                "end": 512073
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-68",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-88"
            ],
            "outputs": [
                "t-89"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 512105,
                "end": 512109
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-69",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-89"
            ],
            "outputs": [
                "t-90"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 512142,
                "end": 512180
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-70",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-90"
            ],
            "outputs": [
                "t-91"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 512203,
                "end": 512254
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-71",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-91"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 512277,
                "end": 512321
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-72",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-84"
            ],
            "outputs": [
                "t-92"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 512348,
                "end": 512389
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-73",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-92"
            ],
            "outputs": [
                "t-93"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 512415,
                "end": 512469
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-74",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-93"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 512494,
                "end": 512537
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-75",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-94"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 512562,
                "end": 512604
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-76",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-94"
            ],
            "outputs": [
                "t-95"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 512629,
                "end": 512679
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-77",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-95"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 512704,
                "end": 512749
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-78",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-96",
                "t-89"
            ],
            "outputs": [
                "t-97"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 512840,
                "end": 512855
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-79",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-97",
                "t-94",
                "t-98"
            ],
            "outputs": [
                "t-99"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 512902,
                "end": 512916
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-80",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-100"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 64,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 64,
                "start": 512997,
                "end": 513061
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-81",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-100"
            ],
            "outputs": [
                "t-101"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 513085,
                "end": 513134
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-82",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-101"
            ],
            "outputs": [
                "t-102"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 513158,
                "end": 513208
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-83",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-102"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 513234,
                "end": 513278
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-84",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-103",
                "t-100"
            ],
            "outputs": [
                "t-104"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 513362,
                "end": 513375
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-85",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-104",
                "t-101",
                "t-105"
            ],
            "outputs": [
                "t-106"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 513422,
                "end": 513436
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-86",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 513512,
                "end": 513563
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-87",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-84",
                "t-108"
            ],
            "outputs": [
                "t-109"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 79,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 79,
                "start": 513661,
                "end": 513740
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-88",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-110"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 513773,
                "end": 513813
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-89",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-110"
            ],
            "outputs": [
                "t-111"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 513842,
                "end": 513898
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-90",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-111"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 49,
                "start": 513924,
                "end": 513973
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-91",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-112"
            ],
            "outputs": [
                "t-113"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 70,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 70,
                "start": 514057,
                "end": 514127
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-92",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-109",
                "t-113"
            ],
            "outputs": [
                "t-114"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 22,
                "start": 514157,
                "end": 514179
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-93",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-115"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 514212,
                "end": 514261
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-94",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-115",
                "t-24"
            ],
            "outputs": [
                "t-116"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 514296,
                "end": 514314
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-95",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-116"
            ],
            "outputs": [
                "t-117"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 514341,
                "end": 514398
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-96",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-118"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 21,
                "start": 514429,
                "end": 514450
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-97",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-118"
            ],
            "outputs": [
                "t-119"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 514477,
                "end": 514481
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-98",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-119"
            ],
            "outputs": [
                "t-120"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 514516,
                "end": 514561
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-99",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-120"
            ],
            "outputs": [
                "t-121"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 514585,
                "end": 514630
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-100",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-121"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 514655,
                "end": 514702
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-101",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-114"
            ],
            "outputs": [
                "t-122"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 514733,
                "end": 514769
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-102",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-122"
            ],
            "outputs": [
                "t-123"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 514793,
                "end": 514849
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-103",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-123"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 514874,
                "end": 514914
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-104",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-124"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 514941,
                "end": 514983
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-105",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-124"
            ],
            "outputs": [
                "t-125"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 515010,
                "end": 515061
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-106",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-125"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 515087,
                "end": 515124
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-107",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-126",
                "t-119"
            ],
            "outputs": [
                "t-127"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 16,
                "start": 515215,
                "end": 515231
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-108",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-127",
                "t-124",
                "t-128"
            ],
            "outputs": [
                "t-129"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 515272,
                "end": 515287
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-109",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-130"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 515374,
                "end": 515433
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-110",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-130"
            ],
            "outputs": [
                "t-131"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 515459,
                "end": 515499
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-111",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-131"
            ],
            "outputs": [
                "t-132"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 515525,
                "end": 515579
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-112",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-132"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 515606,
                "end": 515647
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-113",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-133",
                "t-130"
            ],
            "outputs": [
                "t-134"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 515735,
                "end": 515749
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-114",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-134",
                "t-131",
                "t-135"
            ],
            "outputs": [
                "t-136"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 515790,
                "end": 515804
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-115",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-114",
                "t-137"
            ],
            "outputs": [
                "t-138"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 71,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 71,
                "start": 515887,
                "end": 515958
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-116",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-139"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 515990,
                "end": 516026
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-117",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-139"
            ],
            "outputs": [
                "t-140"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 516048,
                "end": 516104
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-118",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-140"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 516131,
                "end": 516172
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-119",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-141"
            ],
            "outputs": [
                "t-142"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 516259,
                "end": 516318
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-120",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-138",
                "t-142"
            ],
            "outputs": [
                "t-143"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 21,
                "start": 516347,
                "end": 516368
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-121",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-144"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 516394,
                "end": 516447
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-122",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-144",
                "t-20"
            ],
            "outputs": [
                "t-145"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 516477,
                "end": 516495
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-123",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-145"
            ],
            "outputs": [
                "t-146"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 516519,
                "end": 516576
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-124",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-147"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 18,
                "start": 516603,
                "end": 516621
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-125",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-147"
            ],
            "outputs": [
                "t-148"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 516652,
                "end": 516656
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-126",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-148"
            ],
            "outputs": [
                "t-149"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 516688,
                "end": 516726
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-127",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-149"
            ],
            "outputs": [
                "t-150"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 516750,
                "end": 516799
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-128",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-150"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 516822,
                "end": 516864
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-129",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-143"
            ],
            "outputs": [
                "t-151"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 516894,
                "end": 516936
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-130",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-151"
            ],
            "outputs": [
                "t-152"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 516960,
                "end": 517012
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-131",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-152"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 517042,
                "end": 517080
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-132",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-153"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 517106,
                "end": 517148
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-133",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-153"
            ],
            "outputs": [
                "t-154"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 517171,
                "end": 517218
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-134",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-154"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 517242,
                "end": 517285
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-135",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-155",
                "t-148"
            ],
            "outputs": [
                "t-156"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 517372,
                "end": 517387
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-136",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-156",
                "t-153",
                "t-157"
            ],
            "outputs": [
                "t-158"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 517433,
                "end": 517448
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-137",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-159"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 517526,
                "end": 517582
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-138",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-159"
            ],
            "outputs": [
                "t-160"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 517608,
                "end": 517651
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-139",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-160"
            ],
            "outputs": [
                "t-161"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 517677,
                "end": 517728
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-140",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-161"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 517752,
                "end": 517797
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-141",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-162",
                "t-159"
            ],
            "outputs": [
                "t-163"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 517877,
                "end": 517890
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-142",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-163",
                "t-160",
                "t-164"
            ],
            "outputs": [
                "t-165"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 517936,
                "end": 517951
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-143",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-143",
                "t-166"
            ],
            "outputs": [
                "t-167"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 72,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 72,
                "start": 518030,
                "end": 518102
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-144",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-168"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 518141,
                "end": 518187
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-145",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-168"
            ],
            "outputs": [
                "t-169"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 518212,
                "end": 518264
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-146",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-169"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 518290,
                "end": 518337
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-147",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-170"
            ],
            "outputs": [
                "t-171"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 60,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 60,
                "start": 518421,
                "end": 518481
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-148",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-167",
                "t-171"
            ],
            "outputs": [
                "t-172"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 518512,
                "end": 518531
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-149",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-173"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 518566,
                "end": 518625
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-150",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-173",
                "t-16"
            ],
            "outputs": [
                "t-174"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 518655,
                "end": 518673
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-151",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-174"
            ],
            "outputs": [
                "t-175"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 518697,
                "end": 518752
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-152",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-176"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 518783,
                "end": 518802
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-153",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-176"
            ],
            "outputs": [
                "t-177"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 518829,
                "end": 518833
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-154",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-177"
            ],
            "outputs": [
                "t-178"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 518865,
                "end": 518910
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-155",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-178"
            ],
            "outputs": [
                "t-179"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 518934,
                "end": 518976
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-156",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-179"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 519006,
                "end": 519050
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-157",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-172"
            ],
            "outputs": [
                "t-180"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 519078,
                "end": 519117
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-158",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-180"
            ],
            "outputs": [
                "t-181"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 519145,
                "end": 519196
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-159",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-181"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 519221,
                "end": 519263
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-160",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-182"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 519294,
                "end": 519334
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-161",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-182"
            ],
            "outputs": [
                "t-183"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 519357,
                "end": 519410
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-162",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-183"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 519436,
                "end": 519475
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-163",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-184",
                "t-177"
            ],
            "outputs": [
                "t-185"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 16,
                "start": 519574,
                "end": 519590
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-164",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-185",
                "t-182",
                "t-186"
            ],
            "outputs": [
                "t-187"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 519633,
                "end": 519647
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-165",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-188"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 519732,
                "end": 519791
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-166",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-188"
            ],
            "outputs": [
                "t-189"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 519818,
                "end": 519857
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-167",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-189"
            ],
            "outputs": [
                "t-190"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 61,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 61,
                "start": 519881,
                "end": 519942
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-168",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-190"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 519967,
                "end": 520011
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-169",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-191",
                "t-188"
            ],
            "outputs": [
                "t-192"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 520110,
                "end": 520123
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-170",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-192",
                "t-189",
                "t-193"
            ],
            "outputs": [
                "t-194"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 520168,
                "end": 520183
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-171",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-172",
                "t-195"
            ],
            "outputs": [
                "t-196"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 77,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 77,
                "start": 520269,
                "end": 520346
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-172",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-197"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 520377,
                "end": 520412
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-173",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-197"
            ],
            "outputs": [
                "t-198"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 520434,
                "end": 520491
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-174",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-198"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 520517,
                "end": 520562
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-175",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-199"
            ],
            "outputs": [
                "t-200"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 520649,
                "end": 520708
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-176",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-196",
                "t-200"
            ],
            "outputs": [
                "t-201"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 520737,
                "end": 520756
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-177",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-202"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 520784,
                "end": 520838
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-178",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-202",
                "t-12"
            ],
            "outputs": [
                "t-203"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 23,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 23,
                "start": 520936,
                "end": 520959
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-179",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-203"
            ],
            "outputs": [
                "t-204"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 521002,
                "end": 521056
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-180",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-205"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 23,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 23,
                "start": 521088,
                "end": 521111
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-181",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-205"
            ],
            "outputs": [
                "t-206"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 521143,
                "end": 521147
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-182",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-206"
            ],
            "outputs": [
                "t-207"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 521180,
                "end": 521219
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-183",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-207"
            ],
            "outputs": [
                "t-208"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 521249,
                "end": 521292
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-184",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-208"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 521316,
                "end": 521363
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-185",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-201"
            ],
            "outputs": [
                "t-209"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 521390,
                "end": 521427
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-186",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-209"
            ],
            "outputs": [
                "t-210"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 521451,
                "end": 521510
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-187",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-210"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 521534,
                "end": 521572
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-188",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-211"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 521600,
                "end": 521645
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-189",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-211"
            ],
            "outputs": [
                "t-212"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 521670,
                "end": 521721
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-190",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-212"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 521752,
                "end": 521791
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-191",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-213",
                "t-206"
            ],
            "outputs": [
                "t-214"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 521888,
                "end": 521903
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-192",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-214",
                "t-211",
                "t-215"
            ],
            "outputs": [
                "t-216"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 521944,
                "end": 521958
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-193",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-217"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 522040,
                "end": 522096
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-194",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-217"
            ],
            "outputs": [
                "t-218"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 522134,
                "end": 522173
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-195",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-218"
            ],
            "outputs": [
                "t-219"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 522197,
                "end": 522253
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-196",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-219"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 522279,
                "end": 522322
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-197",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-220",
                "t-217"
            ],
            "outputs": [
                "t-221"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 522411,
                "end": 522425
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-198",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-221",
                "t-218",
                "t-222"
            ],
            "outputs": [
                "t-223"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 522465,
                "end": 522480
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-199",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-201",
                "t-224"
            ],
            "outputs": [
                "t-225"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 81,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 81,
                "start": 522567,
                "end": 522648
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-200",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-226"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 522681,
                "end": 522719
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-201",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-226"
            ],
            "outputs": [
                "t-227"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 522742,
                "end": 522798
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-202",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-227"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 522823,
                "end": 522865
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-203",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-228"
            ],
            "outputs": [
                "t-229"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 522953,
                "end": 523011
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-204",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-225",
                "t-229"
            ],
            "outputs": [
                "t-230"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 523042,
                "end": 523062
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-205",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-231"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 523090,
                "end": 523145
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-206",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-231",
                "t-8"
            ],
            "outputs": [
                "t-232"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 523175,
                "end": 523193
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-207",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-232"
            ],
            "outputs": [
                "t-233"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 61,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 61,
                "start": 523219,
                "end": 523280
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-208",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-234"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 523310,
                "end": 523330
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-209",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-234"
            ],
            "outputs": [
                "t-235"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 523363,
                "end": 523367
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-210",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-235"
            ],
            "outputs": [
                "t-236"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 523398,
                "end": 523438
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-211",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-236"
            ],
            "outputs": [
                "t-237"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 523461,
                "end": 523510
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-212",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-237"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 523532,
                "end": 523575
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-213",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-230"
            ],
            "outputs": [
                "t-238"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 523602,
                "end": 523646
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-214",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-238"
            ],
            "outputs": [
                "t-239"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 523672,
                "end": 523725
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-215",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-239"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 65,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 65,
                "start": 523751,
                "end": 523816
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-216",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-240"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 75,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 75,
                "start": 523957,
                "end": 524032
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-217",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-240"
            ],
            "outputs": [
                "t-241"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 99,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 99,
                "start": 524143,
                "end": 524242
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-218",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-241"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 169,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 169,
                "start": 524346,
                "end": 524515
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-219",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-242",
                "t-235"
            ],
            "outputs": [
                "t-243"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 18,
                "start": 524776,
                "end": 524794
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-220",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-243",
                "t-240",
                "t-244"
            ],
            "outputs": [
                "t-245"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 635,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 635,
                "start": 524917,
                "end": 525552
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-221",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-246"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 64,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 64,
                "start": 525658,
                "end": 525722
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-222",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-246"
            ],
            "outputs": [
                "t-247"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 224,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 224,
                "start": 525760,
                "end": 525984
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-223",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-247"
            ],
            "outputs": [
                "t-248"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 526013,
                "end": 526068
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-224",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-248"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 65,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 65,
                "start": 526094,
                "end": 526159
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-225",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-249",
                "t-246"
            ],
            "outputs": [
                "t-250"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 526247,
                "end": 526262
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-226",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-250",
                "t-247",
                "t-251"
            ],
            "outputs": [
                "t-252"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 526313,
                "end": 526328
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-227",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-230",
                "t-253"
            ],
            "outputs": [
                "t-254"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 77,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 77,
                "start": 526411,
                "end": 526488
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-228",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-255"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 526526,
                "end": 526570
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-229",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-255"
            ],
            "outputs": [
                "t-256"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 526594,
                "end": 526651
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-230",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-256"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 526681,
                "end": 526725
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-231",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-257"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 526806,
                "end": 526865
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-232",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    784
                ]
            },
            "inputs": [
                "t-257",
                "t-4"
            ],
            "outputs": [
                "t-258"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 23,
                "flops": 205520896.0
            },
            "args": [],
            "runtime": {
                "duration": 23,
                "start": 526901,
                "end": 526924
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-233",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-258"
            ],
            "outputs": [
                "t-259"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 526951,
                "end": 527007
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-234",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-260"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 527036,
                "end": 527056
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-235",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-260"
            ],
            "outputs": [
                "t-261"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 527084,
                "end": 527088
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-236",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-261"
            ],
            "outputs": [
                "t-262"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 527118,
                "end": 527161
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-237",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-262"
            ],
            "outputs": [
                "t-263"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 527187,
                "end": 527230
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-238",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-263"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 49,
                "start": 527255,
                "end": 527304
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-239",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-264"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 527331,
                "end": 527370
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-240",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-264"
            ],
            "outputs": [
                "t-265"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 60,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 60,
                "start": 527395,
                "end": 527455
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-241",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-265"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 55,
                "start": 527480,
                "end": 527535
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-242",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-266",
                "t-261"
            ],
            "outputs": [
                "t-267"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 527636,
                "end": 527651
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-243",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-267",
                "t-264",
                "t-268"
            ],
            "outputs": [
                "t-269"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 527693,
                "end": 527707
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-244",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-270"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 61,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 61,
                "start": 527794,
                "end": 527855
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-245",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-270"
            ],
            "outputs": [
                "t-271"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 527882,
                "end": 527923
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-246",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-271"
            ],
            "outputs": [
                "t-272"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 527953,
                "end": 528008
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-247",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-272"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 528034,
                "end": 528080
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-248",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-273",
                "t-270"
            ],
            "outputs": [
                "t-274"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 528168,
                "end": 528182
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-249",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-274",
                "t-271",
                "t-275"
            ],
            "outputs": [
                "t-276"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 401408.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 528230,
                "end": 528244
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-250",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 528313,
                "end": 528355
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-251",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-278"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 5,
                "start": 528423,
                "end": 528428
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-252",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-279"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    10,
                    512
                ],
                [
                    512,
                    1
                ],
                10
            ],
            "runtime": {
                "duration": 2,
                "start": 528452,
                "end": 528454
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-253",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-280"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                5130
            ],
            "runtime": {
                "duration": 1,
                "start": 528479,
                "end": 528480
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-254",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-281"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                5642
            ],
            "runtime": {
                "duration": 1,
                "start": 528505,
                "end": 528506
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-255",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-68",
                "t-278"
            ],
            "outputs": [
                "t-282"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 20,
                "start": 528552,
                "end": 528572
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-256",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-75",
                "t-279"
            ],
            "outputs": [
                "t-283"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 12,
                "start": 528599,
                "end": 528611
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-257",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-97",
                "t-280"
            ],
            "outputs": [
                "t-284"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 528638,
                "end": 528648
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-258",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-104",
                "t-281"
            ],
            "outputs": [
                "t-285"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 528672,
                "end": 528683
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-259",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-286"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 3,
                "start": 528722,
                "end": 528725
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-260",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-287"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                512
            ],
            "runtime": {
                "duration": 2,
                "start": 528751,
                "end": 528753
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-261",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-288"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                262656
            ],
            "runtime": {
                "duration": 2,
                "start": 528775,
                "end": 528777
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-262",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-289"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                263168
            ],
            "runtime": {
                "duration": 2,
                "start": 528800,
                "end": 528802
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-263",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-290"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                525312
            ],
            "runtime": {
                "duration": 2,
                "start": 528824,
                "end": 528826
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-264",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-291"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 6,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                525824
            ],
            "runtime": {
                "duration": 6,
                "start": 528848,
                "end": 528854
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-265",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-292"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                787968
            ],
            "runtime": {
                "duration": 2,
                "start": 528881,
                "end": 528883
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-266",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-293"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                788480
            ],
            "runtime": {
                "duration": 2,
                "start": 528905,
                "end": 528907
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-267",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-294"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1050624
            ],
            "runtime": {
                "duration": 2,
                "start": 528936,
                "end": 528938
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-268",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-295"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                1051136
            ],
            "runtime": {
                "duration": 2,
                "start": 528960,
                "end": 528962
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-269",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-296"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 6,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1313280
            ],
            "runtime": {
                "duration": 6,
                "start": 528984,
                "end": 528990
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-270",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-297"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    784
                ],
                [
                    784,
                    1
                ],
                1313792
            ],
            "runtime": {
                "duration": 2,
                "start": 529017,
                "end": 529019
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-271",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-127",
                "t-286"
            ],
            "outputs": [
                "t-298"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 14,
                "start": 529045,
                "end": 529059
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-272",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-134",
                "t-287"
            ],
            "outputs": [
                "t-299"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 12,
                "start": 529084,
                "end": 529096
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-273",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-156",
                "t-288"
            ],
            "outputs": [
                "t-300"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 529119,
                "end": 529130
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-274",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-163",
                "t-289"
            ],
            "outputs": [
                "t-301"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 529164,
                "end": 529175
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-275",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-185",
                "t-290"
            ],
            "outputs": [
                "t-302"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 529203,
                "end": 529213
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-276",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-192",
                "t-291"
            ],
            "outputs": [
                "t-303"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 529239,
                "end": 529248
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-277",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-214",
                "t-292"
            ],
            "outputs": [
                "t-304"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 529279,
                "end": 529290
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-278",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-221",
                "t-293"
            ],
            "outputs": [
                "t-305"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 529316,
                "end": 529326
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-279",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-243",
                "t-294"
            ],
            "outputs": [
                "t-306"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 529350,
                "end": 529359
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-280",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-250",
                "t-295"
            ],
            "outputs": [
                "t-307"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 529389,
                "end": 529400
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-281",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-267",
                "t-296"
            ],
            "outputs": [
                "t-308"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 529428,
                "end": 529437
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-282",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-274",
                "t-297"
            ],
            "outputs": [
                "t-309"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 529462,
                "end": 529472
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-283",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-310"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 143,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 143,
                "start": 529829,
                "end": 529972
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-284",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-311"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 530090,
                "end": 530092
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-285",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-309",
                "t-5"
            ],
            "outputs": [
                "t-312"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 401408.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 34,
                "start": 530587,
                "end": 530621
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-286",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-313",
                "t-314"
            ],
            "outputs": [
                "t-315"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 530734,
                "end": 530754
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-287",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-315",
                "t-312"
            ],
            "outputs": [
                "t-316"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 13,
                "start": 530842,
                "end": 530855
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-288",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-317",
                "t-314"
            ],
            "outputs": [
                "t-318"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 530937,
                "end": 530950
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-289",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-318",
                "t-312",
                "t-312"
            ],
            "outputs": [
                "t-319"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 15,
                "start": 531057,
                "end": 531072
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-290",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-319"
            ],
            "outputs": [
                "t-320"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 531164,
                "end": 531182
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-291",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-320",
                "t-224"
            ],
            "outputs": [
                "t-321"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 531277,
                "end": 531295
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-292",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-321",
                "t-320"
            ],
            "outputs": [
                "t-322"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 531382,
                "end": 531395
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-293",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-5",
                "t-316",
                "t-322"
            ],
            "outputs": [
                "t-323"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 15,
                "start": 531494,
                "end": 531509
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-294",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-308",
                "t-6"
            ],
            "outputs": [
                "t-324"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 18,
                "start": 531604,
                "end": 531622
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-295",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-325",
                "t-326"
            ],
            "outputs": [
                "t-327"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 531714,
                "end": 531727
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-296",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-327",
                "t-324"
            ],
            "outputs": [
                "t-328"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 12,
                "start": 531807,
                "end": 531819
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-297",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-329",
                "t-326"
            ],
            "outputs": [
                "t-330"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 531904,
                "end": 531915
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-298",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-330",
                "t-324",
                "t-324"
            ],
            "outputs": [
                "t-331"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 532002,
                "end": 532014
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-299",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-331"
            ],
            "outputs": [
                "t-332"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 532089,
                "end": 532105
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-300",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-332",
                "t-333"
            ],
            "outputs": [
                "t-334"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 532192,
                "end": 532207
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-301",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-334",
                "t-332"
            ],
            "outputs": [
                "t-335"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 532301,
                "end": 532313
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-302",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-6",
                "t-328",
                "t-335"
            ],
            "outputs": [
                "t-336"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 532398,
                "end": 532410
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-303",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-307",
                "t-9"
            ],
            "outputs": [
                "t-337"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 532501,
                "end": 532517
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-304",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-338",
                "t-332"
            ],
            "outputs": [
                "t-339"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 532601,
                "end": 532614
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-305",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-339",
                "t-337"
            ],
            "outputs": [
                "t-340"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 532697,
                "end": 532708
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-306",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-341",
                "t-332"
            ],
            "outputs": [
                "t-342"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 532796,
                "end": 532806
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-307",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-342",
                "t-337",
                "t-337"
            ],
            "outputs": [
                "t-343"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 532886,
                "end": 532897
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-308",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-343"
            ],
            "outputs": [
                "t-344"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 532978,
                "end": 532993
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-309",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-344",
                "t-345"
            ],
            "outputs": [
                "t-346"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 533076,
                "end": 533091
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-310",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-346",
                "t-344"
            ],
            "outputs": [
                "t-347"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 533177,
                "end": 533190
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-311",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-9",
                "t-340",
                "t-347"
            ],
            "outputs": [
                "t-348"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 533273,
                "end": 533285
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-312",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-306",
                "t-10"
            ],
            "outputs": [
                "t-349"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 533379,
                "end": 533395
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-313",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-350",
                "t-344"
            ],
            "outputs": [
                "t-351"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 533478,
                "end": 533490
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-314",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-351",
                "t-349"
            ],
            "outputs": [
                "t-352"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 533571,
                "end": 533582
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-315",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-353",
                "t-344"
            ],
            "outputs": [
                "t-354"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 533663,
                "end": 533674
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-316",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-354",
                "t-349",
                "t-349"
            ],
            "outputs": [
                "t-355"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 533756,
                "end": 533768
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-317",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-355"
            ],
            "outputs": [
                "t-356"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 533845,
                "end": 533858
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-318",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-356",
                "t-357"
            ],
            "outputs": [
                "t-358"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 533941,
                "end": 533955
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-319",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-358",
                "t-356"
            ],
            "outputs": [
                "t-359"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 534039,
                "end": 534050
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-320",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-10",
                "t-352",
                "t-359"
            ],
            "outputs": [
                "t-360"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 534147,
                "end": 534160
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-321",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-305",
                "t-13"
            ],
            "outputs": [
                "t-361"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 534258,
                "end": 534274
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-322",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-362",
                "t-356"
            ],
            "outputs": [
                "t-363"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 534357,
                "end": 534371
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-323",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-363",
                "t-361"
            ],
            "outputs": [
                "t-364"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 534455,
                "end": 534466
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-324",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-365",
                "t-356"
            ],
            "outputs": [
                "t-366"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 534547,
                "end": 534558
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-325",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-366",
                "t-361",
                "t-361"
            ],
            "outputs": [
                "t-367"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 13,
                "start": 534646,
                "end": 534659
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-326",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-367"
            ],
            "outputs": [
                "t-368"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 534745,
                "end": 534760
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-327",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-368",
                "t-369"
            ],
            "outputs": [
                "t-370"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 534846,
                "end": 534861
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-328",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-370",
                "t-368"
            ],
            "outputs": [
                "t-371"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 534949,
                "end": 534961
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-329",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-13",
                "t-364",
                "t-371"
            ],
            "outputs": [
                "t-372"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 535047,
                "end": 535059
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-330",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-304",
                "t-14"
            ],
            "outputs": [
                "t-373"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 535150,
                "end": 535165
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-331",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-374",
                "t-368"
            ],
            "outputs": [
                "t-375"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 535247,
                "end": 535260
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-332",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-375",
                "t-373"
            ],
            "outputs": [
                "t-376"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 535339,
                "end": 535349
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-333",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-377",
                "t-368"
            ],
            "outputs": [
                "t-378"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 535428,
                "end": 535439
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-334",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-378",
                "t-373",
                "t-373"
            ],
            "outputs": [
                "t-379"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 535520,
                "end": 535532
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-335",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-379"
            ],
            "outputs": [
                "t-380"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 535611,
                "end": 535625
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-336",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-380",
                "t-381"
            ],
            "outputs": [
                "t-382"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 535707,
                "end": 535721
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-337",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-382",
                "t-380"
            ],
            "outputs": [
                "t-383"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 535806,
                "end": 535818
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-338",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-14",
                "t-376",
                "t-383"
            ],
            "outputs": [
                "t-384"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 535902,
                "end": 535914
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-339",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-303",
                "t-17"
            ],
            "outputs": [
                "t-385"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 536004,
                "end": 536019
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-340",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-386",
                "t-380"
            ],
            "outputs": [
                "t-387"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 536099,
                "end": 536112
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-341",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-387",
                "t-385"
            ],
            "outputs": [
                "t-388"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 536193,
                "end": 536204
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-342",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-389",
                "t-380"
            ],
            "outputs": [
                "t-390"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 536285,
                "end": 536296
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-343",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-390",
                "t-385",
                "t-385"
            ],
            "outputs": [
                "t-391"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 536377,
                "end": 536389
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-344",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-391"
            ],
            "outputs": [
                "t-392"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 536463,
                "end": 536477
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-345",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-392",
                "t-393"
            ],
            "outputs": [
                "t-394"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 536560,
                "end": 536575
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-346",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-394",
                "t-392"
            ],
            "outputs": [
                "t-395"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 536672,
                "end": 536685
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-347",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-17",
                "t-388",
                "t-395"
            ],
            "outputs": [
                "t-396"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 536767,
                "end": 536779
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-348",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-302",
                "t-18"
            ],
            "outputs": [
                "t-397"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 536887,
                "end": 536903
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-349",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-398",
                "t-392"
            ],
            "outputs": [
                "t-399"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 536994,
                "end": 537007
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-350",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-399",
                "t-397"
            ],
            "outputs": [
                "t-400"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 537092,
                "end": 537102
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-351",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-401",
                "t-392"
            ],
            "outputs": [
                "t-402"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 537197,
                "end": 537209
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-352",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-402",
                "t-397",
                "t-397"
            ],
            "outputs": [
                "t-403"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 537296,
                "end": 537308
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-353",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-403"
            ],
            "outputs": [
                "t-404"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 537385,
                "end": 537398
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-354",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-404",
                "t-405"
            ],
            "outputs": [
                "t-406"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 537482,
                "end": 537497
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-355",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-406",
                "t-404"
            ],
            "outputs": [
                "t-407"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 537584,
                "end": 537596
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-356",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-18",
                "t-400",
                "t-407"
            ],
            "outputs": [
                "t-408"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 537687,
                "end": 537699
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-357",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-301",
                "t-21"
            ],
            "outputs": [
                "t-409"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 537793,
                "end": 537808
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-358",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-410",
                "t-404"
            ],
            "outputs": [
                "t-411"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 537902,
                "end": 537915
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-359",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-411",
                "t-409"
            ],
            "outputs": [
                "t-412"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 537996,
                "end": 538006
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-360",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-413",
                "t-404"
            ],
            "outputs": [
                "t-414"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 538093,
                "end": 538112
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-361",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-414",
                "t-409",
                "t-409"
            ],
            "outputs": [
                "t-415"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 538199,
                "end": 538211
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-362",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-415"
            ],
            "outputs": [
                "t-416"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 538306,
                "end": 538321
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-363",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-416",
                "t-417"
            ],
            "outputs": [
                "t-418"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 538424,
                "end": 538439
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-364",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-418",
                "t-416"
            ],
            "outputs": [
                "t-419"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 538545,
                "end": 538557
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-365",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-21",
                "t-412",
                "t-419"
            ],
            "outputs": [
                "t-420"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 538661,
                "end": 538674
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-366",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-300",
                "t-22"
            ],
            "outputs": [
                "t-421"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 538788,
                "end": 538804
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-367",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-422",
                "t-416"
            ],
            "outputs": [
                "t-423"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 538889,
                "end": 538902
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-368",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-423",
                "t-421"
            ],
            "outputs": [
                "t-424"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 538982,
                "end": 538993
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-369",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-425",
                "t-416"
            ],
            "outputs": [
                "t-426"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 539088,
                "end": 539099
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-370",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-426",
                "t-421",
                "t-421"
            ],
            "outputs": [
                "t-427"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 539197,
                "end": 539208
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-371",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-427"
            ],
            "outputs": [
                "t-428"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 539303,
                "end": 539318
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-372",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-428",
                "t-429"
            ],
            "outputs": [
                "t-430"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 539420,
                "end": 539435
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-373",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-430",
                "t-428"
            ],
            "outputs": [
                "t-431"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 539540,
                "end": 539551
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-374",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-22",
                "t-424",
                "t-431"
            ],
            "outputs": [
                "t-432"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 539651,
                "end": 539664
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-375",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-299",
                "t-25"
            ],
            "outputs": [
                "t-433"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 18,
                "start": 539820,
                "end": 539838
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-376",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-434",
                "t-428"
            ],
            "outputs": [
                "t-435"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 539951,
                "end": 539966
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-377",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-435",
                "t-433"
            ],
            "outputs": [
                "t-436"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 540052,
                "end": 540063
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-378",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-437",
                "t-428"
            ],
            "outputs": [
                "t-438"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 540160,
                "end": 540172
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-379",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-438",
                "t-433",
                "t-433"
            ],
            "outputs": [
                "t-439"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 540255,
                "end": 540267
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-380",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-439"
            ],
            "outputs": [
                "t-440"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 540355,
                "end": 540372
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-381",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-440",
                "t-441"
            ],
            "outputs": [
                "t-442"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 540462,
                "end": 540477
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-382",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-442",
                "t-440"
            ],
            "outputs": [
                "t-443"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 540564,
                "end": 540576
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-383",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-25",
                "t-436",
                "t-443"
            ],
            "outputs": [
                "t-444"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 540666,
                "end": 540679
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-384",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-298",
                "t-26"
            ],
            "outputs": [
                "t-445"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 540777,
                "end": 540793
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-385",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-446",
                "t-440"
            ],
            "outputs": [
                "t-447"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 540885,
                "end": 540898
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-386",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-447",
                "t-445"
            ],
            "outputs": [
                "t-448"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 540989,
                "end": 541000
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-387",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-449",
                "t-440"
            ],
            "outputs": [
                "t-450"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 541095,
                "end": 541106
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-388",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-450",
                "t-445",
                "t-445"
            ],
            "outputs": [
                "t-451"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 541207,
                "end": 541219
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-389",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-451"
            ],
            "outputs": [
                "t-452"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 541304,
                "end": 541319
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-390",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-452",
                "t-453"
            ],
            "outputs": [
                "t-454"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 541411,
                "end": 541426
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-391",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-454",
                "t-452"
            ],
            "outputs": [
                "t-455"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 541512,
                "end": 541523
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-392",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-26",
                "t-448",
                "t-455"
            ],
            "outputs": [
                "t-456"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 541616,
                "end": 541628
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-393",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-285",
                "t-29"
            ],
            "outputs": [
                "t-457"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 541735,
                "end": 541750
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-394",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-458",
                "t-452"
            ],
            "outputs": [
                "t-459"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 541853,
                "end": 541866
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-395",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-459",
                "t-457"
            ],
            "outputs": [
                "t-460"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 541965,
                "end": 541975
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-396",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-461",
                "t-452"
            ],
            "outputs": [
                "t-462"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 542077,
                "end": 542088
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-397",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-462",
                "t-457",
                "t-457"
            ],
            "outputs": [
                "t-463"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 542197,
                "end": 542209
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-398",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-463"
            ],
            "outputs": [
                "t-464"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 542304,
                "end": 542320
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-399",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-464",
                "t-465"
            ],
            "outputs": [
                "t-466"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 542421,
                "end": 542437
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-400",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-466",
                "t-464"
            ],
            "outputs": [
                "t-467"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 542552,
                "end": 542565
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-401",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-29",
                "t-460",
                "t-467"
            ],
            "outputs": [
                "t-468"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 542667,
                "end": 542680
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-402",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-284",
                "t-30"
            ],
            "outputs": [
                "t-469"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 542794,
                "end": 542810
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-403",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-470",
                "t-464"
            ],
            "outputs": [
                "t-471"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 542921,
                "end": 542934
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-404",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-471",
                "t-469"
            ],
            "outputs": [
                "t-472"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 543029,
                "end": 543040
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-405",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-473",
                "t-464"
            ],
            "outputs": [
                "t-474"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 543135,
                "end": 543146
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-406",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-474",
                "t-469",
                "t-469"
            ],
            "outputs": [
                "t-475"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 543236,
                "end": 543248
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-407",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-475"
            ],
            "outputs": [
                "t-476"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 543340,
                "end": 543355
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-408",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-476",
                "t-477"
            ],
            "outputs": [
                "t-478"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 543442,
                "end": 543461
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-409",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-478",
                "t-476"
            ],
            "outputs": [
                "t-479"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 543549,
                "end": 543561
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-410",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-30",
                "t-472",
                "t-479"
            ],
            "outputs": [
                "t-480"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 543661,
                "end": 543674
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-411",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-283",
                "t-33"
            ],
            "outputs": [
                "t-481"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 5120.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 543773,
                "end": 543788
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-412",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-482",
                "t-476"
            ],
            "outputs": [
                "t-483"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 543878,
                "end": 543891
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-413",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-483",
                "t-481"
            ],
            "outputs": [
                "t-484"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 543976,
                "end": 543987
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-414",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-485",
                "t-476"
            ],
            "outputs": [
                "t-486"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 544068,
                "end": 544079
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-415",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-486",
                "t-481",
                "t-481"
            ],
            "outputs": [
                "t-487"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 544166,
                "end": 544178
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-416",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-487"
            ],
            "outputs": [
                "t-488"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 544256,
                "end": 544270
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-417",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-488",
                "t-489"
            ],
            "outputs": [
                "t-490"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 544365,
                "end": 544380
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-418",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-490",
                "t-488"
            ],
            "outputs": [
                "t-491"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 544478,
                "end": 544490
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-419",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-33",
                "t-484",
                "t-491"
            ],
            "outputs": [
                "t-492"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 544591,
                "end": 544604
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-420",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-282",
                "t-34"
            ],
            "outputs": [
                "t-493"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 10.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 20,
                "start": 544711,
                "end": 544731
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-421",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-494",
                "t-488"
            ],
            "outputs": [
                "t-495"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 544829,
                "end": 544842
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-422",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-495",
                "t-493"
            ],
            "outputs": [
                "t-496"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 544941,
                "end": 544952
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-423",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-497",
                "t-488"
            ],
            "outputs": [
                "t-498"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 545049,
                "end": 545059
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-424",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-498",
                "t-493",
                "t-493"
            ],
            "outputs": [
                "t-499"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 545166,
                "end": 545178
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-425",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-499"
            ],
            "outputs": [
                "t-500"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 545279,
                "end": 545294
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-426",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-500",
                "t-501"
            ],
            "outputs": [
                "t-502"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 545396,
                "end": 545411
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-427",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-502",
                "t-500"
            ],
            "outputs": [
                "t-503"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 545501,
                "end": 545512
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-428",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-34",
                "t-496",
                "t-503"
            ],
            "outputs": [
                "t-504"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 545614,
                "end": 545626
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        }
    ],
    "tensors": {
        "t-1": {
            "name": "t-1",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-2": {
            "name": "t-2",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-4": {
            "name": "t-4",
            "dtype": "FP32",
            "shape": [
                256,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-3": {
            "name": "t-3",
            "dtype": "FP32",
            "shape": [
                256,
                1,
                28,
                28
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-7": {
            "name": "t-7",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-5": {
            "name": "t-5",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-6": {
            "name": "t-6",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-8": {
            "name": "t-8",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-11": {
            "name": "t-11",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-9": {
            "name": "t-9",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-10": {
            "name": "t-10",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-12": {
            "name": "t-12",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-15": {
            "name": "t-15",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-13": {
            "name": "t-13",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-14": {
            "name": "t-14",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-16": {
            "name": "t-16",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-19": {
            "name": "t-19",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-17": {
            "name": "t-17",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-18": {
            "name": "t-18",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-20": {
            "name": "t-20",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-23": {
            "name": "t-23",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-21": {
            "name": "t-21",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-22": {
            "name": "t-22",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-24": {
            "name": "t-24",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-27": {
            "name": "t-27",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-25": {
            "name": "t-25",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-26": {
            "name": "t-26",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-28": {
            "name": "t-28",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-31": {
            "name": "t-31",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-29": {
            "name": "t-29",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-30": {
            "name": "t-30",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-32": {
            "name": "t-32",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-35": {
            "name": "t-35",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-33": {
            "name": "t-33",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-34": {
            "name": "t-34",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-36": {
            "name": "t-36",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-38": {
            "name": "t-38",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-37": {
            "name": "t-37",
            "dtype": "INT64",
            "shape": [
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-39": {
            "name": "t-39",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-43": {
            "name": "t-43",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-40": {
            "name": "t-40",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-41": {
            "name": "t-41",
            "dtype": "BIN",
            "shape": [
                0
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-42": {
            "name": "t-42",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-44": {
            "name": "t-44",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-45": {
            "name": "t-45",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-46": {
            "name": "t-46",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-47": {
            "name": "t-47",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-48": {
            "name": "t-48",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-50": {
            "name": "t-50",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-47",
            "allocation": null
        },
        "t-49": {
            "name": "t-49",
            "dtype": "UINT8",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-51": {
            "name": "t-51",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-49",
            "allocation": null
        },
        "t-52": {
            "name": "t-52",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-54": {
            "name": "t-54",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-53": {
            "name": "t-53",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-55": {
            "name": "t-55",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-56": {
            "name": "t-56",
            "dtype": "FP32",
            "shape": [
                10,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-57": {
            "name": "t-57",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-58": {
            "name": "t-58",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-59": {
            "name": "t-59",
            "dtype": "FP32",
            "shape": [
                1,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-60": {
            "name": "t-60",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-61": {
            "name": "t-61",
            "dtype": "BIN",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-62": {
            "name": "t-62",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-63": {
            "name": "t-63",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-64": {
            "name": "t-64",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-62",
            "allocation": null
        },
        "t-65": {
            "name": "t-65",
            "dtype": "BIN",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-66": {
            "name": "t-66",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-64",
            "allocation": null
        },
        "t-68": {
            "name": "t-68",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-67",
            "allocation": null
        },
        "t-67": {
            "name": "t-67",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-70": {
            "name": "t-70",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-69",
            "allocation": null
        },
        "t-69": {
            "name": "t-69",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-71": {
            "name": "t-71",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-72": {
            "name": "t-72",
            "dtype": "BIN",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-73": {
            "name": "t-73",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-75": {
            "name": "t-75",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-74",
            "allocation": null
        },
        "t-74": {
            "name": "t-74",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-77": {
            "name": "t-77",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-76",
            "allocation": null
        },
        "t-76": {
            "name": "t-76",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-79": {
            "name": "t-79",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-78": {
            "name": "t-78",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-80": {
            "name": "t-80",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-78",
            "allocation": null
        },
        "t-81": {
            "name": "t-81",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-83": {
            "name": "t-83",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-82": {
            "name": "t-82",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-84": {
            "name": "t-84",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-85": {
            "name": "t-85",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-86": {
            "name": "t-86",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-87": {
            "name": "t-87",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-88": {
            "name": "t-88",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-89": {
            "name": "t-89",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-90": {
            "name": "t-90",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-91": {
            "name": "t-91",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-92": {
            "name": "t-92",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-93": {
            "name": "t-93",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-91",
            "allocation": null
        },
        "t-94": {
            "name": "t-94",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-95": {
            "name": "t-95",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-93",
            "allocation": null
        },
        "t-97": {
            "name": "t-97",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-96",
            "allocation": null
        },
        "t-96": {
            "name": "t-96",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-99": {
            "name": "t-99",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-98",
            "allocation": null
        },
        "t-98": {
            "name": "t-98",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-100": {
            "name": "t-100",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-101": {
            "name": "t-101",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-87",
            "allocation": null
        },
        "t-102": {
            "name": "t-102",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-104": {
            "name": "t-104",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-103",
            "allocation": null
        },
        "t-103": {
            "name": "t-103",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-106": {
            "name": "t-106",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-105",
            "allocation": null
        },
        "t-105": {
            "name": "t-105",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-107": {
            "name": "t-107",
            "dtype": "FP32",
            "shape": [
                267786
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-109": {
            "name": "t-109",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-108": {
            "name": "t-108",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-110": {
            "name": "t-110",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-108",
            "allocation": null
        },
        "t-111": {
            "name": "t-111",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-113": {
            "name": "t-113",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-112": {
            "name": "t-112",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-114": {
            "name": "t-114",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-115": {
            "name": "t-115",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-116": {
            "name": "t-116",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-86",
            "allocation": null
        },
        "t-117": {
            "name": "t-117",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-118": {
            "name": "t-118",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-119": {
            "name": "t-119",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-120": {
            "name": "t-120",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-121": {
            "name": "t-121",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-122": {
            "name": "t-122",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-123": {
            "name": "t-123",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-121",
            "allocation": null
        },
        "t-124": {
            "name": "t-124",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-125": {
            "name": "t-125",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-123",
            "allocation": null
        },
        "t-127": {
            "name": "t-127",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-126",
            "allocation": null
        },
        "t-126": {
            "name": "t-126",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-129": {
            "name": "t-129",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-128",
            "allocation": null
        },
        "t-128": {
            "name": "t-128",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-130": {
            "name": "t-130",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-131": {
            "name": "t-131",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-117",
            "allocation": null
        },
        "t-132": {
            "name": "t-132",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-134": {
            "name": "t-134",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-133",
            "allocation": null
        },
        "t-133": {
            "name": "t-133",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-136": {
            "name": "t-136",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-135",
            "allocation": null
        },
        "t-135": {
            "name": "t-135",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-138": {
            "name": "t-138",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-137": {
            "name": "t-137",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-139": {
            "name": "t-139",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-137",
            "allocation": null
        },
        "t-140": {
            "name": "t-140",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-142": {
            "name": "t-142",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-141": {
            "name": "t-141",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-143": {
            "name": "t-143",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-144": {
            "name": "t-144",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-145": {
            "name": "t-145",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-116",
            "allocation": null
        },
        "t-146": {
            "name": "t-146",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-131",
            "allocation": null
        },
        "t-147": {
            "name": "t-147",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-148": {
            "name": "t-148",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-149": {
            "name": "t-149",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-150": {
            "name": "t-150",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-151": {
            "name": "t-151",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-152": {
            "name": "t-152",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-150",
            "allocation": null
        },
        "t-153": {
            "name": "t-153",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-154": {
            "name": "t-154",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-152",
            "allocation": null
        },
        "t-156": {
            "name": "t-156",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-155",
            "allocation": null
        },
        "t-155": {
            "name": "t-155",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-158": {
            "name": "t-158",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-157",
            "allocation": null
        },
        "t-157": {
            "name": "t-157",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-159": {
            "name": "t-159",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-160": {
            "name": "t-160",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-146",
            "allocation": null
        },
        "t-161": {
            "name": "t-161",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-163": {
            "name": "t-163",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-162",
            "allocation": null
        },
        "t-162": {
            "name": "t-162",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-165": {
            "name": "t-165",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-164",
            "allocation": null
        },
        "t-164": {
            "name": "t-164",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-167": {
            "name": "t-167",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-166": {
            "name": "t-166",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-168": {
            "name": "t-168",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-166",
            "allocation": null
        },
        "t-169": {
            "name": "t-169",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-171": {
            "name": "t-171",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-170": {
            "name": "t-170",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-172": {
            "name": "t-172",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-173": {
            "name": "t-173",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-174": {
            "name": "t-174",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-145",
            "allocation": null
        },
        "t-175": {
            "name": "t-175",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-160",
            "allocation": null
        },
        "t-176": {
            "name": "t-176",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-177": {
            "name": "t-177",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-178": {
            "name": "t-178",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-179": {
            "name": "t-179",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-180": {
            "name": "t-180",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-181": {
            "name": "t-181",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-179",
            "allocation": null
        },
        "t-182": {
            "name": "t-182",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-183": {
            "name": "t-183",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-181",
            "allocation": null
        },
        "t-185": {
            "name": "t-185",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-184",
            "allocation": null
        },
        "t-184": {
            "name": "t-184",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-187": {
            "name": "t-187",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-186",
            "allocation": null
        },
        "t-186": {
            "name": "t-186",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-188": {
            "name": "t-188",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-189": {
            "name": "t-189",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-175",
            "allocation": null
        },
        "t-190": {
            "name": "t-190",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-192": {
            "name": "t-192",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-191",
            "allocation": null
        },
        "t-191": {
            "name": "t-191",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-194": {
            "name": "t-194",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-193",
            "allocation": null
        },
        "t-193": {
            "name": "t-193",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-196": {
            "name": "t-196",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-195": {
            "name": "t-195",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-197": {
            "name": "t-197",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-172",
            "allocation": null
        },
        "t-198": {
            "name": "t-198",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-200": {
            "name": "t-200",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-199": {
            "name": "t-199",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-201": {
            "name": "t-201",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-202": {
            "name": "t-202",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-203": {
            "name": "t-203",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-189",
            "allocation": null
        },
        "t-204": {
            "name": "t-204",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-182",
            "allocation": null
        },
        "t-205": {
            "name": "t-205",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-206": {
            "name": "t-206",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-207": {
            "name": "t-207",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-208": {
            "name": "t-208",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-209": {
            "name": "t-209",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-210": {
            "name": "t-210",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-208",
            "allocation": null
        },
        "t-211": {
            "name": "t-211",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-212": {
            "name": "t-212",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-210",
            "allocation": null
        },
        "t-214": {
            "name": "t-214",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-213",
            "allocation": null
        },
        "t-213": {
            "name": "t-213",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-216": {
            "name": "t-216",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-215",
            "allocation": null
        },
        "t-215": {
            "name": "t-215",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-217": {
            "name": "t-217",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-218": {
            "name": "t-218",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-204",
            "allocation": null
        },
        "t-219": {
            "name": "t-219",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-221": {
            "name": "t-221",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-220",
            "allocation": null
        },
        "t-220": {
            "name": "t-220",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-223": {
            "name": "t-223",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-222",
            "allocation": null
        },
        "t-222": {
            "name": "t-222",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-225": {
            "name": "t-225",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-224": {
            "name": "t-224",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-226": {
            "name": "t-226",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-201",
            "allocation": null
        },
        "t-227": {
            "name": "t-227",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-229": {
            "name": "t-229",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-228": {
            "name": "t-228",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-230": {
            "name": "t-230",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-231": {
            "name": "t-231",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-232": {
            "name": "t-232",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-218",
            "allocation": null
        },
        "t-233": {
            "name": "t-233",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-211",
            "allocation": null
        },
        "t-234": {
            "name": "t-234",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-235": {
            "name": "t-235",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-236": {
            "name": "t-236",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-237": {
            "name": "t-237",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-238": {
            "name": "t-238",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-239": {
            "name": "t-239",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-237",
            "allocation": null
        },
        "t-240": {
            "name": "t-240",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-241": {
            "name": "t-241",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-239",
            "allocation": null
        },
        "t-243": {
            "name": "t-243",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-242",
            "allocation": null
        },
        "t-242": {
            "name": "t-242",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-245": {
            "name": "t-245",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-244",
            "allocation": null
        },
        "t-244": {
            "name": "t-244",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-246": {
            "name": "t-246",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-247": {
            "name": "t-247",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-233",
            "allocation": null
        },
        "t-248": {
            "name": "t-248",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-250": {
            "name": "t-250",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-249",
            "allocation": null
        },
        "t-249": {
            "name": "t-249",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-252": {
            "name": "t-252",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-251",
            "allocation": null
        },
        "t-251": {
            "name": "t-251",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-254": {
            "name": "t-254",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-253": {
            "name": "t-253",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-255": {
            "name": "t-255",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-230",
            "allocation": null
        },
        "t-256": {
            "name": "t-256",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-257": {
            "name": "t-257",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-258": {
            "name": "t-258",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-259": {
            "name": "t-259",
            "dtype": "FP32",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-260": {
            "name": "t-260",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-261": {
            "name": "t-261",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-262": {
            "name": "t-262",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-263": {
            "name": "t-263",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-264": {
            "name": "t-264",
            "dtype": "BIN",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-265": {
            "name": "t-265",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-263",
            "allocation": null
        },
        "t-267": {
            "name": "t-267",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-266",
            "allocation": null
        },
        "t-266": {
            "name": "t-266",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-269": {
            "name": "t-269",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-268",
            "allocation": null
        },
        "t-268": {
            "name": "t-268",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-270": {
            "name": "t-270",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-271": {
            "name": "t-271",
            "dtype": "BIN",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-272": {
            "name": "t-272",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-274": {
            "name": "t-274",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-273",
            "allocation": null
        },
        "t-273": {
            "name": "t-273",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-276": {
            "name": "t-276",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-275",
            "allocation": null
        },
        "t-275": {
            "name": "t-275",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-277": {
            "name": "t-277",
            "dtype": "FP32",
            "shape": [
                1715200
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-278": {
            "name": "t-278",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-279": {
            "name": "t-279",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-280": {
            "name": "t-280",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-281": {
            "name": "t-281",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-282": {
            "name": "t-282",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-68",
            "allocation": null
        },
        "t-283": {
            "name": "t-283",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-75",
            "allocation": null
        },
        "t-284": {
            "name": "t-284",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-97",
            "allocation": null
        },
        "t-285": {
            "name": "t-285",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-104",
            "allocation": null
        },
        "t-286": {
            "name": "t-286",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-287": {
            "name": "t-287",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-288": {
            "name": "t-288",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-289": {
            "name": "t-289",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-290": {
            "name": "t-290",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-291": {
            "name": "t-291",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-292": {
            "name": "t-292",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-293": {
            "name": "t-293",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-294": {
            "name": "t-294",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-295": {
            "name": "t-295",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-296": {
            "name": "t-296",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-297": {
            "name": "t-297",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-298": {
            "name": "t-298",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-127",
            "allocation": null
        },
        "t-299": {
            "name": "t-299",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-134",
            "allocation": null
        },
        "t-300": {
            "name": "t-300",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-156",
            "allocation": null
        },
        "t-301": {
            "name": "t-301",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-163",
            "allocation": null
        },
        "t-302": {
            "name": "t-302",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-185",
            "allocation": null
        },
        "t-303": {
            "name": "t-303",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-192",
            "allocation": null
        },
        "t-304": {
            "name": "t-304",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-214",
            "allocation": null
        },
        "t-305": {
            "name": "t-305",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-221",
            "allocation": null
        },
        "t-306": {
            "name": "t-306",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-243",
            "allocation": null
        },
        "t-307": {
            "name": "t-307",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-250",
            "allocation": null
        },
        "t-308": {
            "name": "t-308",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-267",
            "allocation": null
        },
        "t-309": {
            "name": "t-309",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-274",
            "allocation": null
        },
        "t-310": {
            "name": "t-310",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-311": {
            "name": "t-311",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-312": {
            "name": "t-312",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-315": {
            "name": "t-315",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-313",
            "allocation": null
        },
        "t-313": {
            "name": "t-313",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-314": {
            "name": "t-314",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-316": {
            "name": "t-316",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-315",
            "allocation": null
        },
        "t-318": {
            "name": "t-318",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-317",
            "allocation": null
        },
        "t-317": {
            "name": "t-317",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-319": {
            "name": "t-319",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-318",
            "allocation": null
        },
        "t-320": {
            "name": "t-320",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-321": {
            "name": "t-321",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-322": {
            "name": "t-322",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-321",
            "allocation": null
        },
        "t-323": {
            "name": "t-323",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-5",
            "allocation": null
        },
        "t-324": {
            "name": "t-324",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-327": {
            "name": "t-327",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-325",
            "allocation": null
        },
        "t-325": {
            "name": "t-325",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-326": {
            "name": "t-326",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-328": {
            "name": "t-328",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-327",
            "allocation": null
        },
        "t-330": {
            "name": "t-330",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-329",
            "allocation": null
        },
        "t-329": {
            "name": "t-329",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-331": {
            "name": "t-331",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-330",
            "allocation": null
        },
        "t-332": {
            "name": "t-332",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-334": {
            "name": "t-334",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-333": {
            "name": "t-333",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-335": {
            "name": "t-335",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-334",
            "allocation": null
        },
        "t-336": {
            "name": "t-336",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-6",
            "allocation": null
        },
        "t-337": {
            "name": "t-337",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-339": {
            "name": "t-339",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-338",
            "allocation": null
        },
        "t-338": {
            "name": "t-338",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-340": {
            "name": "t-340",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-339",
            "allocation": null
        },
        "t-342": {
            "name": "t-342",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-341",
            "allocation": null
        },
        "t-341": {
            "name": "t-341",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-343": {
            "name": "t-343",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-342",
            "allocation": null
        },
        "t-344": {
            "name": "t-344",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-346": {
            "name": "t-346",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-345": {
            "name": "t-345",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-347": {
            "name": "t-347",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-346",
            "allocation": null
        },
        "t-348": {
            "name": "t-348",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-9",
            "allocation": null
        },
        "t-349": {
            "name": "t-349",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-351": {
            "name": "t-351",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-350",
            "allocation": null
        },
        "t-350": {
            "name": "t-350",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-352": {
            "name": "t-352",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-351",
            "allocation": null
        },
        "t-354": {
            "name": "t-354",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-353",
            "allocation": null
        },
        "t-353": {
            "name": "t-353",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-355": {
            "name": "t-355",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-354",
            "allocation": null
        },
        "t-356": {
            "name": "t-356",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-358": {
            "name": "t-358",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-357": {
            "name": "t-357",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-359": {
            "name": "t-359",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-358",
            "allocation": null
        },
        "t-360": {
            "name": "t-360",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-10",
            "allocation": null
        },
        "t-361": {
            "name": "t-361",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-363": {
            "name": "t-363",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-362",
            "allocation": null
        },
        "t-362": {
            "name": "t-362",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-364": {
            "name": "t-364",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-363",
            "allocation": null
        },
        "t-366": {
            "name": "t-366",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-365",
            "allocation": null
        },
        "t-365": {
            "name": "t-365",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-367": {
            "name": "t-367",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-366",
            "allocation": null
        },
        "t-368": {
            "name": "t-368",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-370": {
            "name": "t-370",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-369": {
            "name": "t-369",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-371": {
            "name": "t-371",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-370",
            "allocation": null
        },
        "t-372": {
            "name": "t-372",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-13",
            "allocation": null
        },
        "t-373": {
            "name": "t-373",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-375": {
            "name": "t-375",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-374",
            "allocation": null
        },
        "t-374": {
            "name": "t-374",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-376": {
            "name": "t-376",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-375",
            "allocation": null
        },
        "t-378": {
            "name": "t-378",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-377",
            "allocation": null
        },
        "t-377": {
            "name": "t-377",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-379": {
            "name": "t-379",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-378",
            "allocation": null
        },
        "t-380": {
            "name": "t-380",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-382": {
            "name": "t-382",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-381": {
            "name": "t-381",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-383": {
            "name": "t-383",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-382",
            "allocation": null
        },
        "t-384": {
            "name": "t-384",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-14",
            "allocation": null
        },
        "t-385": {
            "name": "t-385",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-387": {
            "name": "t-387",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-386",
            "allocation": null
        },
        "t-386": {
            "name": "t-386",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-388": {
            "name": "t-388",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-387",
            "allocation": null
        },
        "t-390": {
            "name": "t-390",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-389",
            "allocation": null
        },
        "t-389": {
            "name": "t-389",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-391": {
            "name": "t-391",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-390",
            "allocation": null
        },
        "t-392": {
            "name": "t-392",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-394": {
            "name": "t-394",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-393": {
            "name": "t-393",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-395": {
            "name": "t-395",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-394",
            "allocation": null
        },
        "t-396": {
            "name": "t-396",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-17",
            "allocation": null
        },
        "t-397": {
            "name": "t-397",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-399": {
            "name": "t-399",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-398",
            "allocation": null
        },
        "t-398": {
            "name": "t-398",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-400": {
            "name": "t-400",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-399",
            "allocation": null
        },
        "t-402": {
            "name": "t-402",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-401",
            "allocation": null
        },
        "t-401": {
            "name": "t-401",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-403": {
            "name": "t-403",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-402",
            "allocation": null
        },
        "t-404": {
            "name": "t-404",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-406": {
            "name": "t-406",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-405": {
            "name": "t-405",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-407": {
            "name": "t-407",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-406",
            "allocation": null
        },
        "t-408": {
            "name": "t-408",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-18",
            "allocation": null
        },
        "t-409": {
            "name": "t-409",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-411": {
            "name": "t-411",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-410",
            "allocation": null
        },
        "t-410": {
            "name": "t-410",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-412": {
            "name": "t-412",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-411",
            "allocation": null
        },
        "t-414": {
            "name": "t-414",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-413",
            "allocation": null
        },
        "t-413": {
            "name": "t-413",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-415": {
            "name": "t-415",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-414",
            "allocation": null
        },
        "t-416": {
            "name": "t-416",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-418": {
            "name": "t-418",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-417": {
            "name": "t-417",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-419": {
            "name": "t-419",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-418",
            "allocation": null
        },
        "t-420": {
            "name": "t-420",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-21",
            "allocation": null
        },
        "t-421": {
            "name": "t-421",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-423": {
            "name": "t-423",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-422",
            "allocation": null
        },
        "t-422": {
            "name": "t-422",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-424": {
            "name": "t-424",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-423",
            "allocation": null
        },
        "t-426": {
            "name": "t-426",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-425",
            "allocation": null
        },
        "t-425": {
            "name": "t-425",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-427": {
            "name": "t-427",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-426",
            "allocation": null
        },
        "t-428": {
            "name": "t-428",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-430": {
            "name": "t-430",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-429": {
            "name": "t-429",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-431": {
            "name": "t-431",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-430",
            "allocation": null
        },
        "t-432": {
            "name": "t-432",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-22",
            "allocation": null
        },
        "t-433": {
            "name": "t-433",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-435": {
            "name": "t-435",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-434",
            "allocation": null
        },
        "t-434": {
            "name": "t-434",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-436": {
            "name": "t-436",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-435",
            "allocation": null
        },
        "t-438": {
            "name": "t-438",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-437",
            "allocation": null
        },
        "t-437": {
            "name": "t-437",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-439": {
            "name": "t-439",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-438",
            "allocation": null
        },
        "t-440": {
            "name": "t-440",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-442": {
            "name": "t-442",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-441": {
            "name": "t-441",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-443": {
            "name": "t-443",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-442",
            "allocation": null
        },
        "t-444": {
            "name": "t-444",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-25",
            "allocation": null
        },
        "t-445": {
            "name": "t-445",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-447": {
            "name": "t-447",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-446",
            "allocation": null
        },
        "t-446": {
            "name": "t-446",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-448": {
            "name": "t-448",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-447",
            "allocation": null
        },
        "t-450": {
            "name": "t-450",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-449",
            "allocation": null
        },
        "t-449": {
            "name": "t-449",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-451": {
            "name": "t-451",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-450",
            "allocation": null
        },
        "t-452": {
            "name": "t-452",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-454": {
            "name": "t-454",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-453": {
            "name": "t-453",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-455": {
            "name": "t-455",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-454",
            "allocation": null
        },
        "t-456": {
            "name": "t-456",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-26",
            "allocation": null
        },
        "t-457": {
            "name": "t-457",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-459": {
            "name": "t-459",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-458",
            "allocation": null
        },
        "t-458": {
            "name": "t-458",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-460": {
            "name": "t-460",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-459",
            "allocation": null
        },
        "t-462": {
            "name": "t-462",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-461",
            "allocation": null
        },
        "t-461": {
            "name": "t-461",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-463": {
            "name": "t-463",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-462",
            "allocation": null
        },
        "t-464": {
            "name": "t-464",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-466": {
            "name": "t-466",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-465": {
            "name": "t-465",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-467": {
            "name": "t-467",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-466",
            "allocation": null
        },
        "t-468": {
            "name": "t-468",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-29",
            "allocation": null
        },
        "t-469": {
            "name": "t-469",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-471": {
            "name": "t-471",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-470",
            "allocation": null
        },
        "t-470": {
            "name": "t-470",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-472": {
            "name": "t-472",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-471",
            "allocation": null
        },
        "t-474": {
            "name": "t-474",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-473",
            "allocation": null
        },
        "t-473": {
            "name": "t-473",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-475": {
            "name": "t-475",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-474",
            "allocation": null
        },
        "t-476": {
            "name": "t-476",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-478": {
            "name": "t-478",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-477": {
            "name": "t-477",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-479": {
            "name": "t-479",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-478",
            "allocation": null
        },
        "t-480": {
            "name": "t-480",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-30",
            "allocation": null
        },
        "t-481": {
            "name": "t-481",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-483": {
            "name": "t-483",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-482",
            "allocation": null
        },
        "t-482": {
            "name": "t-482",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-484": {
            "name": "t-484",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-483",
            "allocation": null
        },
        "t-486": {
            "name": "t-486",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-485",
            "allocation": null
        },
        "t-485": {
            "name": "t-485",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-487": {
            "name": "t-487",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-486",
            "allocation": null
        },
        "t-488": {
            "name": "t-488",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-490": {
            "name": "t-490",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-489": {
            "name": "t-489",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-491": {
            "name": "t-491",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-490",
            "allocation": null
        },
        "t-492": {
            "name": "t-492",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-33",
            "allocation": null
        },
        "t-493": {
            "name": "t-493",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-495": {
            "name": "t-495",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-494",
            "allocation": null
        },
        "t-494": {
            "name": "t-494",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-496": {
            "name": "t-496",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-495",
            "allocation": null
        },
        "t-498": {
            "name": "t-498",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-497",
            "allocation": null
        },
        "t-497": {
            "name": "t-497",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-499": {
            "name": "t-499",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-498",
            "allocation": null
        },
        "t-500": {
            "name": "t-500",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-502": {
            "name": "t-502",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-501": {
            "name": "t-501",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-503": {
            "name": "t-503",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-502",
            "allocation": null
        },
        "t-504": {
            "name": "t-504",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-34",
            "allocation": null
        }
    },
    "inputs": [
        "t-3",
        "t-5",
        "t-6",
        "t-9",
        "t-10",
        "t-13",
        "t-14",
        "t-17",
        "t-18",
        "t-21",
        "t-22",
        "t-25",
        "t-26",
        "t-29",
        "t-30",
        "t-33",
        "t-34",
        "t-37",
        "t-40",
        "t-41",
        "t-42",
        "t-49",
        "t-53",
        "t-67",
        "t-69",
        "t-74",
        "t-76",
        "t-78",
        "t-82",
        "t-96",
        "t-98",
        "t-103",
        "t-105",
        "t-107",
        "t-108",
        "t-112",
        "t-126",
        "t-128",
        "t-133",
        "t-135",
        "t-137",
        "t-141",
        "t-155",
        "t-157",
        "t-162",
        "t-164",
        "t-166",
        "t-170",
        "t-184",
        "t-186",
        "t-191",
        "t-193",
        "t-195",
        "t-199",
        "t-213",
        "t-215",
        "t-220",
        "t-222",
        "t-224",
        "t-228",
        "t-242",
        "t-244",
        "t-249",
        "t-251",
        "t-253",
        "t-266",
        "t-268",
        "t-273",
        "t-275",
        "t-277",
        "t-313",
        "t-314",
        "t-317",
        "t-325",
        "t-326",
        "t-329",
        "t-333",
        "t-338",
        "t-341",
        "t-345",
        "t-350",
        "t-353",
        "t-357",
        "t-362",
        "t-365",
        "t-369",
        "t-374",
        "t-377",
        "t-381",
        "t-386",
        "t-389",
        "t-393",
        "t-398",
        "t-401",
        "t-405",
        "t-410",
        "t-413",
        "t-417",
        "t-422",
        "t-425",
        "t-429",
        "t-434",
        "t-437",
        "t-441",
        "t-446",
        "t-449",
        "t-453",
        "t-458",
        "t-461",
        "t-465",
        "t-470",
        "t-473",
        "t-477",
        "t-482",
        "t-485",
        "t-489",
        "t-494",
        "t-497",
        "t-501"
    ],
    "outputs": []
}