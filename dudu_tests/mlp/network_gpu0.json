{
    "name": "Some Default",
    "origin": "",
    "cpu_info": {
        "Architecture": "x86_64",
        "CPU op-mode(s)": "32-bit, 64-bit",
        "Byte Order": "Little Endian",
        "Address sizes": "46 bits physical, 48 bits virtual",
        "CPU(s)": "112",
        "On-line CPU(s) list": "0-111",
        "Thread(s) per core": "2",
        "Core(s) per socket": "28",
        "Socket(s)": "2",
        "NUMA node(s)": "2",
        "Vendor ID": "GenuineIntel",
        "CPU family": "6",
        "Model": "85",
        "Model name": "Intel(R) Xeon(R) Platinum 8180 CPU @ 2.50GHz",
        "Stepping": "4",
        "CPU MHz": "2500.055",
        "BogoMIPS": "5000.00",
        "Virtualization": "VT-x",
        "L1d cache": "1.8 MiB",
        "L1i cache": "1.8 MiB",
        "L2 cache": "56 MiB",
        "L3 cache": "77 MiB",
        "NUMA node0 CPU(s)": "0-27,56-83",
        "NUMA node1 CPU(s)": "28-55,84-111",
        "Vulnerability Itlb multihit": "KVM",
        "Vulnerability L1tf": "Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable",
        "Vulnerability Mds": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Vulnerability Meltdown": "Mitigation; PTI",
        "Vulnerability Spec store bypass": "Mitigation; Speculative Store Bypass disabled via prctl and seccomp",
        "Vulnerability Spectre v1": "Mitigation; usercopy/swapgs barriers and __user pointer sanitization",
        "Vulnerability Spectre v2": "Mitigation; Full generic retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling",
        "Vulnerability Srbds": "Not affected",
        "Vulnerability Tsx async abort": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Flags": "fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm arat pln pts pku ospke md_clear flush_l1d"
    },
    "layers": [
        {
            "name": "DistributedDataParallel/op-1",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-1"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 204,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 204,
                "start": 501098,
                "end": 501302
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/op-2",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-2"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 501440,
                "end": 501442
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/op-3",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-3"
            ],
            "outputs": [
                "t-4"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 6,
                "flops": 0.0
            },
            "args": [
                [
                    -1,
                    784
                ]
            ],
            "runtime": {
                "duration": 6,
                "start": 501639,
                "end": 501645
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 45, in forward\n    x = x.view(-1, 28 * 28)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-4",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-4",
                "t-5",
                "t-6"
            ],
            "outputs": [
                "t-7"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 840,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 840,
                "start": 501783,
                "end": 502623
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-5",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-7"
            ],
            "outputs": [
                "t-8"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 620,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 620,
                "start": 502778,
                "end": 503398
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-6",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-8",
                "t-9",
                "t-10"
            ],
            "outputs": [
                "t-11"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 779,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 779,
                "start": 503529,
                "end": 504308
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-7",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-11"
            ],
            "outputs": [
                "t-12"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 606,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 606,
                "start": 504438,
                "end": 505044
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-8",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-12",
                "t-13",
                "t-14"
            ],
            "outputs": [
                "t-15"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 823,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 823,
                "start": 505173,
                "end": 505996
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-9",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-15"
            ],
            "outputs": [
                "t-16"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 602,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 602,
                "start": 506128,
                "end": 506730
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-10",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-16",
                "t-17",
                "t-18"
            ],
            "outputs": [
                "t-19"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 763,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 763,
                "start": 506854,
                "end": 507617
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-11",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-19"
            ],
            "outputs": [
                "t-20"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 600,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 600,
                "start": 507743,
                "end": 508343
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-12",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-20",
                "t-21",
                "t-22"
            ],
            "outputs": [
                "t-23"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 806,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 806,
                "start": 508461,
                "end": 509267
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-13",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-23"
            ],
            "outputs": [
                "t-24"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 564,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 564,
                "start": 509396,
                "end": 509960
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-14",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-24",
                "t-25",
                "t-26"
            ],
            "outputs": [
                "t-27"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 766,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 766,
                "start": 510083,
                "end": 510849
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-15",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-27"
            ],
            "outputs": [
                "t-28"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 589,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 589,
                "start": 510976,
                "end": 511565
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-16",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-28",
                "t-29",
                "t-30"
            ],
            "outputs": [
                "t-31"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 777,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 777,
                "start": 511692,
                "end": 512469
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-17",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-31"
            ],
            "outputs": [
                "t-32"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 578,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 578,
                "start": 512591,
                "end": 513169
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-18",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-32",
                "t-33",
                "t-34"
            ],
            "outputs": [
                "t-35"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 760,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 760,
                "start": 513289,
                "end": 514049
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-19",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-35"
            ],
            "outputs": [
                "t-36"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 563,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 563,
                "start": 514176,
                "end": 514739
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "CrossEntropyLoss/op-20",
            "optype": "aten::cross_entropy_loss",
            "params": {},
            "inputs": [
                "t-36",
                "t-37"
            ],
            "outputs": [
                "t-38"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 785,
                "flops": 0.0
            },
            "args": [
                1,
                -100,
                0.0
            ],
            "runtime": {
                "duration": 785,
                "start": 514915,
                "end": 515700
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    loss = loss_model(output, target)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 1150, in forward\n    return F.cross_entropy(input, target, weight=self.weight,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 2846, in cross_entropy\n    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n"
            ]
        },
        {
            "name": "op-21",
            "optype": "aten::ones_like",
            "params": {},
            "inputs": [
                "t-38"
            ],
            "outputs": [
                "t-39"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 247,
                "flops": 0.0
            },
            "args": [
                6,
                0,
                false,
                1
            ],
            "runtime": {
                "duration": 247,
                "start": 516169,
                "end": 516416
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 172, in train_and_test\n    loss.backward()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 150, in backward\n    grad_tensors_ = _make_grads(tensors, grad_tensors_)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 52, in _make_grads\n    new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/NllLossBackward0/op-22",
            "optype": "aten::nll_loss_backward",
            "params": {},
            "inputs": [
                "t-39",
                "t-40",
                "t-37",
                "t-41",
                "t-42"
            ],
            "outputs": [
                "t-43"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 94,
                "flops": 0.0
            },
            "args": [
                1,
                -100
            ],
            "runtime": {
                "duration": 94,
                "start": 516877,
                "end": 516971
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-23",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-43"
            ],
            "outputs": [
                "t-44"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 517028,
                "end": 517082
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-24",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-44"
            ],
            "outputs": [
                "t-45"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 517117,
                "end": 517169
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-25",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-45"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 57,
                "start": 517201,
                "end": 517258
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/LogSoftmaxBackward0/op-26",
            "optype": "aten::_log_softmax_backward_data",
            "params": {},
            "inputs": [
                "t-43",
                "t-44",
                "t-36"
            ],
            "outputs": [
                "t-46"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 16,
                "start": 517353,
                "end": 517369
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-27",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-46"
            ],
            "outputs": [
                "t-47"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 517401,
                "end": 517438
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-28",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-47"
            ],
            "outputs": [
                "t-48"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 517462,
                "end": 517505
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-29",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-48"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 48,
                "start": 517529,
                "end": 517577
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-30",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-46",
                "t-49"
            ],
            "outputs": [
                "t-50"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 75,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 75,
                "start": 517661,
                "end": 517736
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-31",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-51"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 517766,
                "end": 517801
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-32",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-51"
            ],
            "outputs": [
                "t-52"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 517828,
                "end": 517875
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-33",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-52"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 517897,
                "end": 517943
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-34",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-53"
            ],
            "outputs": [
                "t-54"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 518021,
                "end": 518076
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-35",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    10
                ],
                "mat2_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-50",
                "t-54"
            ],
            "outputs": [
                "t-55"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 21,
                "start": 518121,
                "end": 518142
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-36",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-56"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 518168,
                "end": 518223
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-37",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    10,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-56",
                "t-32"
            ],
            "outputs": [
                "t-57"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 518250,
                "end": 518265
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-38",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-57"
            ],
            "outputs": [
                "t-58"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 518296,
                "end": 518347
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-39",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-59"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 22,
                "start": 518387,
                "end": 518409
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-40",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-59"
            ],
            "outputs": [
                "t-60"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 518436,
                "end": 518440
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-41",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-60"
            ],
            "outputs": [
                "t-61"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 518471,
                "end": 518513
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-42",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-61"
            ],
            "outputs": [
                "t-62"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 518537,
                "end": 518577
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-43",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-62"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 53,
                "start": 518600,
                "end": 518653
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-44",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-55"
            ],
            "outputs": [
                "t-63"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 518680,
                "end": 518716
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-45",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-63"
            ],
            "outputs": [
                "t-64"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 518739,
                "end": 518794
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-46",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-64"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 518821,
                "end": 518859
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-47",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-65"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 518884,
                "end": 518931
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-48",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-65"
            ],
            "outputs": [
                "t-66"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 518953,
                "end": 518999
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-49",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-66"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 519022,
                "end": 519059
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-50",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-67",
                "t-60"
            ],
            "outputs": [
                "t-68"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 16,
                "start": 519166,
                "end": 519182
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-51",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-68",
                "t-65",
                "t-69"
            ],
            "outputs": [
                "t-70"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 10.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 519235,
                "end": 519251
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-52",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-71"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 59,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 59,
                "start": 519332,
                "end": 519391
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-53",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-71"
            ],
            "outputs": [
                "t-72"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 519416,
                "end": 519454
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-54",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-72"
            ],
            "outputs": [
                "t-73"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 519476,
                "end": 519520
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-55",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-73"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 519542,
                "end": 519584
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-56",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-74",
                "t-71"
            ],
            "outputs": [
                "t-75"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 519671,
                "end": 519685
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-57",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-75",
                "t-72",
                "t-76"
            ],
            "outputs": [
                "t-77"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 5120.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 519728,
                "end": 519742
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-58",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-55",
                "t-78"
            ],
            "outputs": [
                "t-79"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 74,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 74,
                "start": 519823,
                "end": 519897
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-59",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-80"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 520041,
                "end": 520099
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-60",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-80"
            ],
            "outputs": [
                "t-81"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 60,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 60,
                "start": 520129,
                "end": 520189
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-61",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-81"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 81,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 81,
                "start": 520274,
                "end": 520355
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-62",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-82"
            ],
            "outputs": [
                "t-83"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 520544,
                "end": 520599
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-63",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-79",
                "t-83"
            ],
            "outputs": [
                "t-84"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 22,
                "start": 520787,
                "end": 520809
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-64",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-85"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 120,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 120,
                "start": 520844,
                "end": 520964
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-65",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-85",
                "t-28"
            ],
            "outputs": [
                "t-86"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 31,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 31,
                "start": 520992,
                "end": 521023
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-66",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-86"
            ],
            "outputs": [
                "t-87"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 521154,
                "end": 521209
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-67",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-88"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 23,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 23,
                "start": 521366,
                "end": 521389
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-68",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-88"
            ],
            "outputs": [
                "t-89"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 521435,
                "end": 521439
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-69",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-89"
            ],
            "outputs": [
                "t-90"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 521474,
                "end": 521516
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-70",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-90"
            ],
            "outputs": [
                "t-91"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 267,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 267,
                "start": 521539,
                "end": 521806
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-71",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-91"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 521835,
                "end": 521881
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-72",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-84"
            ],
            "outputs": [
                "t-92"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 521909,
                "end": 521954
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-73",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-92"
            ],
            "outputs": [
                "t-93"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 521976,
                "end": 522032
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-74",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-93"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 522057,
                "end": 522097
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-75",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-94"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 522123,
                "end": 522164
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-76",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-94"
            ],
            "outputs": [
                "t-95"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 522187,
                "end": 522236
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-77",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-95"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 522259,
                "end": 522302
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-78",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-96",
                "t-89"
            ],
            "outputs": [
                "t-97"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 522389,
                "end": 522403
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-79",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-97",
                "t-94",
                "t-98"
            ],
            "outputs": [
                "t-99"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 522450,
                "end": 522464
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-80",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-100"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 522540,
                "end": 522596
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-81",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-100"
            ],
            "outputs": [
                "t-101"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 522620,
                "end": 522662
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-82",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-101"
            ],
            "outputs": [
                "t-102"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 522685,
                "end": 522734
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-83",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-102"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 522758,
                "end": 522804
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-84",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-103",
                "t-100"
            ],
            "outputs": [
                "t-104"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 522883,
                "end": 522896
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-85",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-104",
                "t-101",
                "t-105"
            ],
            "outputs": [
                "t-106"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 522940,
                "end": 522954
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-86",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 523028,
                "end": 523078
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-87",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-84",
                "t-108"
            ],
            "outputs": [
                "t-109"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 78,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 78,
                "start": 523176,
                "end": 523254
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-88",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-110"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 523287,
                "end": 523324
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-89",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-110"
            ],
            "outputs": [
                "t-111"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 523352,
                "end": 523405
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-90",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-111"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 523429,
                "end": 523476
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-91",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-112"
            ],
            "outputs": [
                "t-113"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 523558,
                "end": 523613
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-92",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-109",
                "t-113"
            ],
            "outputs": [
                "t-114"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 523641,
                "end": 523661
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-93",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-115"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 523691,
                "end": 523743
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-94",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-115",
                "t-24"
            ],
            "outputs": [
                "t-116"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 523769,
                "end": 523787
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-95",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-116"
            ],
            "outputs": [
                "t-117"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 523816,
                "end": 523865
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-96",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-118"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 523894,
                "end": 523914
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-97",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-118"
            ],
            "outputs": [
                "t-119"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 523940,
                "end": 523944
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-98",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-119"
            ],
            "outputs": [
                "t-120"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 523974,
                "end": 524014
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-99",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-120"
            ],
            "outputs": [
                "t-121"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 524036,
                "end": 524077
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-100",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-121"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 48,
                "start": 524099,
                "end": 524147
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-101",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-114"
            ],
            "outputs": [
                "t-122"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 34,
                "start": 524172,
                "end": 524206
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-102",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-122"
            ],
            "outputs": [
                "t-123"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 524228,
                "end": 524282
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-103",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-123"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 524305,
                "end": 524349
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-104",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-124"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 524374,
                "end": 524418
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-105",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-124"
            ],
            "outputs": [
                "t-125"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 524440,
                "end": 524490
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-106",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-125"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 524514,
                "end": 524551
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-107",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-126",
                "t-119"
            ],
            "outputs": [
                "t-127"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 524642,
                "end": 524657
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-108",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-127",
                "t-124",
                "t-128"
            ],
            "outputs": [
                "t-129"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 524701,
                "end": 524715
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-109",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-130"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 524795,
                "end": 524850
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-110",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-130"
            ],
            "outputs": [
                "t-131"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 524878,
                "end": 524915
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-111",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-131"
            ],
            "outputs": [
                "t-132"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 524938,
                "end": 524993
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-112",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-132"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 525030,
                "end": 525074
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-113",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-133",
                "t-130"
            ],
            "outputs": [
                "t-134"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 525160,
                "end": 525174
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-114",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-134",
                "t-131",
                "t-135"
            ],
            "outputs": [
                "t-136"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 525214,
                "end": 525227
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-115",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-114",
                "t-137"
            ],
            "outputs": [
                "t-138"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 69,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 69,
                "start": 525305,
                "end": 525374
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-116",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-139"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 525406,
                "end": 525441
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-117",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-139"
            ],
            "outputs": [
                "t-140"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 525466,
                "end": 525519
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-118",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-140"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 525543,
                "end": 525583
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-119",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-141"
            ],
            "outputs": [
                "t-142"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 525664,
                "end": 525716
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-120",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-138",
                "t-142"
            ],
            "outputs": [
                "t-143"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 525744,
                "end": 525764
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-121",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-144"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 525788,
                "end": 525838
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-122",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-144",
                "t-20"
            ],
            "outputs": [
                "t-145"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 525865,
                "end": 525882
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-123",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-145"
            ],
            "outputs": [
                "t-146"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 525906,
                "end": 525963
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-124",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-147"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 525989,
                "end": 526008
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-125",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-147"
            ],
            "outputs": [
                "t-148"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 526039,
                "end": 526043
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-126",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-148"
            ],
            "outputs": [
                "t-149"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 526073,
                "end": 526110
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-127",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-149"
            ],
            "outputs": [
                "t-150"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 526131,
                "end": 526175
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-128",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-150"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 526201,
                "end": 526243
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-129",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-143"
            ],
            "outputs": [
                "t-151"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 526268,
                "end": 526313
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-130",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-151"
            ],
            "outputs": [
                "t-152"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 526336,
                "end": 526383
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-131",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-152"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 526412,
                "end": 526450
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-132",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-153"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 526474,
                "end": 526515
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-133",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-153"
            ],
            "outputs": [
                "t-154"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 526539,
                "end": 526587
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-134",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-154"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 526611,
                "end": 526653
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-135",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-155",
                "t-148"
            ],
            "outputs": [
                "t-156"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 526738,
                "end": 526752
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-136",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-156",
                "t-153",
                "t-157"
            ],
            "outputs": [
                "t-158"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 526797,
                "end": 526811
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-137",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-159"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 526885,
                "end": 526940
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-138",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-159"
            ],
            "outputs": [
                "t-160"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 526966,
                "end": 527007
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-139",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-160"
            ],
            "outputs": [
                "t-161"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 527030,
                "end": 527079
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-140",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-161"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 527103,
                "end": 527148
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-141",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-162",
                "t-159"
            ],
            "outputs": [
                "t-163"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 527228,
                "end": 527242
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-142",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-163",
                "t-160",
                "t-164"
            ],
            "outputs": [
                "t-165"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 527289,
                "end": 527302
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-143",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-143",
                "t-166"
            ],
            "outputs": [
                "t-167"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 69,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 69,
                "start": 527377,
                "end": 527446
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-144",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-168"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 527475,
                "end": 527516
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-145",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-168"
            ],
            "outputs": [
                "t-169"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 527539,
                "end": 527587
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-146",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-169"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 527611,
                "end": 527657
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-147",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-170"
            ],
            "outputs": [
                "t-171"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 527735,
                "end": 527793
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-148",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-167",
                "t-171"
            ],
            "outputs": [
                "t-172"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 527823,
                "end": 527843
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-149",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-173"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 527874,
                "end": 527926
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-150",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-173",
                "t-16"
            ],
            "outputs": [
                "t-174"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 527954,
                "end": 527971
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-151",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-174"
            ],
            "outputs": [
                "t-175"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 527996,
                "end": 528046
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-152",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-176"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 528073,
                "end": 528092
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-153",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-176"
            ],
            "outputs": [
                "t-177"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 528118,
                "end": 528122
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-154",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-177"
            ],
            "outputs": [
                "t-178"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 528151,
                "end": 528193
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-155",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-178"
            ],
            "outputs": [
                "t-179"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 528216,
                "end": 528255
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-156",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-179"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 48,
                "start": 528278,
                "end": 528326
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-157",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-172"
            ],
            "outputs": [
                "t-180"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 528351,
                "end": 528386
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-158",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-180"
            ],
            "outputs": [
                "t-181"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 528413,
                "end": 528460
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-159",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-181"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 528486,
                "end": 528532
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-160",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-182"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 528557,
                "end": 528593
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-161",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-182"
            ],
            "outputs": [
                "t-183"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 528615,
                "end": 528664
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-162",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-183"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 528687,
                "end": 528725
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-163",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-184",
                "t-177"
            ],
            "outputs": [
                "t-185"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 528815,
                "end": 528829
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-164",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-185",
                "t-182",
                "t-186"
            ],
            "outputs": [
                "t-187"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 528868,
                "end": 528882
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-165",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-188"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 61,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 61,
                "start": 528965,
                "end": 529026
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-166",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-188"
            ],
            "outputs": [
                "t-189"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 529051,
                "end": 529088
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-167",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-189"
            ],
            "outputs": [
                "t-190"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 529110,
                "end": 529164
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-168",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-190"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 529189,
                "end": 529228
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-169",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-191",
                "t-188"
            ],
            "outputs": [
                "t-192"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 529321,
                "end": 529334
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-170",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-192",
                "t-189",
                "t-193"
            ],
            "outputs": [
                "t-194"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 529372,
                "end": 529386
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-171",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-172",
                "t-195"
            ],
            "outputs": [
                "t-196"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 68,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 68,
                "start": 529467,
                "end": 529535
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-172",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-197"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 34,
                "start": 529565,
                "end": 529599
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-173",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-197"
            ],
            "outputs": [
                "t-198"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 529621,
                "end": 529675
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-174",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-198"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 135,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 135,
                "start": 529699,
                "end": 529834
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-175",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-199"
            ],
            "outputs": [
                "t-200"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 529934,
                "end": 529990
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-176",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-196",
                "t-200"
            ],
            "outputs": [
                "t-201"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 22,
                "start": 530020,
                "end": 530042
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-177",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-202"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 530069,
                "end": 530127
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-178",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-202",
                "t-12"
            ],
            "outputs": [
                "t-203"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 530154,
                "end": 530171
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-179",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-203"
            ],
            "outputs": [
                "t-204"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 530201,
                "end": 530250
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-180",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-205"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 21,
                "start": 530275,
                "end": 530296
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-181",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-205"
            ],
            "outputs": [
                "t-206"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 530327,
                "end": 530331
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-182",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-206"
            ],
            "outputs": [
                "t-207"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 530362,
                "end": 530399
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-183",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-207"
            ],
            "outputs": [
                "t-208"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 530426,
                "end": 530469
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-184",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-208"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 530493,
                "end": 530536
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-185",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-201"
            ],
            "outputs": [
                "t-209"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 530566,
                "end": 530604
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-186",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-209"
            ],
            "outputs": [
                "t-210"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 530625,
                "end": 530676
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-187",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-210"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 530701,
                "end": 530738
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-188",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-211"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 530765,
                "end": 530807
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-189",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-211"
            ],
            "outputs": [
                "t-212"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 530834,
                "end": 530881
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-190",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-212"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 530908,
                "end": 530951
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-191",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-213",
                "t-206"
            ],
            "outputs": [
                "t-214"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 531042,
                "end": 531057
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-192",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-214",
                "t-211",
                "t-215"
            ],
            "outputs": [
                "t-216"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 531095,
                "end": 531109
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-193",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-217"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 531188,
                "end": 531241
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-194",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-217"
            ],
            "outputs": [
                "t-218"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 531266,
                "end": 531303
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-195",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-218"
            ],
            "outputs": [
                "t-219"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 531325,
                "end": 531379
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-196",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-219"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 531404,
                "end": 531443
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-197",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-220",
                "t-217"
            ],
            "outputs": [
                "t-221"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 531530,
                "end": 531544
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-198",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-221",
                "t-218",
                "t-222"
            ],
            "outputs": [
                "t-223"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 531583,
                "end": 531596
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-199",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-201",
                "t-224"
            ],
            "outputs": [
                "t-225"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 71,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 71,
                "start": 531682,
                "end": 531753
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-200",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-226"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 531784,
                "end": 531820
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-201",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-226"
            ],
            "outputs": [
                "t-227"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 531842,
                "end": 531897
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-202",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-227"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 531921,
                "end": 531962
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-203",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-228"
            ],
            "outputs": [
                "t-229"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 532048,
                "end": 532101
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-204",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-225",
                "t-229"
            ],
            "outputs": [
                "t-230"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 532129,
                "end": 532148
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-205",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-231"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 532174,
                "end": 532223
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-206",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-231",
                "t-8"
            ],
            "outputs": [
                "t-232"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 532249,
                "end": 532265
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-207",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-232"
            ],
            "outputs": [
                "t-233"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 532293,
                "end": 532345
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-208",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-234"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 18,
                "start": 532374,
                "end": 532392
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-209",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-234"
            ],
            "outputs": [
                "t-235"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 532426,
                "end": 532430
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-210",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-235"
            ],
            "outputs": [
                "t-236"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 532459,
                "end": 532495
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-211",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-236"
            ],
            "outputs": [
                "t-237"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 532517,
                "end": 532563
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-212",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-237"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 532586,
                "end": 532627
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-213",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-230"
            ],
            "outputs": [
                "t-238"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 532651,
                "end": 532693
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-214",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-238"
            ],
            "outputs": [
                "t-239"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 532716,
                "end": 532763
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-215",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-239"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 532791,
                "end": 532832
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-216",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-240"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 532855,
                "end": 532896
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-217",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-240"
            ],
            "outputs": [
                "t-241"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 532919,
                "end": 532964
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-218",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-241"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 52,
                "start": 532986,
                "end": 533038
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-219",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-242",
                "t-235"
            ],
            "outputs": [
                "t-243"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 533124,
                "end": 533139
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-220",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-243",
                "t-240",
                "t-244"
            ],
            "outputs": [
                "t-245"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 533184,
                "end": 533198
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-221",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-246"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 533283,
                "end": 533339
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-222",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-246"
            ],
            "outputs": [
                "t-247"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 533363,
                "end": 533406
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-223",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-247"
            ],
            "outputs": [
                "t-248"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 533429,
                "end": 533478
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-224",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-248"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 49,
                "start": 533501,
                "end": 533550
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-225",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-249",
                "t-246"
            ],
            "outputs": [
                "t-250"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 533630,
                "end": 533643
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-226",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-250",
                "t-247",
                "t-251"
            ],
            "outputs": [
                "t-252"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 533687,
                "end": 533701
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-227",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-230",
                "t-253"
            ],
            "outputs": [
                "t-254"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 72,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 72,
                "start": 533774,
                "end": 533846
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-228",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-255"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 533877,
                "end": 533918
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-229",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-255"
            ],
            "outputs": [
                "t-256"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 533940,
                "end": 533993
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-230",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-256"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 534018,
                "end": 534065
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-231",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-257"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 534141,
                "end": 534196
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-232",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    784
                ]
            },
            "inputs": [
                "t-257",
                "t-4"
            ],
            "outputs": [
                "t-258"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 205520896.0
            },
            "args": [],
            "runtime": {
                "duration": 22,
                "start": 534224,
                "end": 534246
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-233",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-258"
            ],
            "outputs": [
                "t-259"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 534277,
                "end": 534327
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-234",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-260"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 534353,
                "end": 534372
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-235",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-260"
            ],
            "outputs": [
                "t-261"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 534398,
                "end": 534402
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-236",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-261"
            ],
            "outputs": [
                "t-262"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 534429,
                "end": 534469
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-237",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-262"
            ],
            "outputs": [
                "t-263"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 534492,
                "end": 534532
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-238",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-263"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 534556,
                "end": 534602
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-239",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-264"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 534627,
                "end": 534663
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-240",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-264"
            ],
            "outputs": [
                "t-265"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 534686,
                "end": 534742
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-241",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-265"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 534767,
                "end": 534807
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-242",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-266",
                "t-261"
            ],
            "outputs": [
                "t-267"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 534897,
                "end": 534911
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-243",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-267",
                "t-264",
                "t-268"
            ],
            "outputs": [
                "t-269"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 534950,
                "end": 534963
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-244",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-270"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 535042,
                "end": 535098
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-245",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-270"
            ],
            "outputs": [
                "t-271"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 535121,
                "end": 535156
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-246",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-271"
            ],
            "outputs": [
                "t-272"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 535182,
                "end": 535231
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-247",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-272"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 535255,
                "end": 535302
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-248",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-273",
                "t-270"
            ],
            "outputs": [
                "t-274"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 535383,
                "end": 535396
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-249",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-274",
                "t-271",
                "t-275"
            ],
            "outputs": [
                "t-276"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 401408.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 535441,
                "end": 535455
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-250",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 535522,
                "end": 535560
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-251",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-278"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 5,
                "start": 535625,
                "end": 535630
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-252",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-279"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    10,
                    512
                ],
                [
                    512,
                    1
                ],
                10
            ],
            "runtime": {
                "duration": 2,
                "start": 535654,
                "end": 535656
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-253",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-280"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                5130
            ],
            "runtime": {
                "duration": 2,
                "start": 535677,
                "end": 535679
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-254",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-281"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                5642
            ],
            "runtime": {
                "duration": 1,
                "start": 535700,
                "end": 535701
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-255",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-68",
                "t-278"
            ],
            "outputs": [
                "t-282"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 22,
                "start": 535744,
                "end": 535766
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-256",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-75",
                "t-279"
            ],
            "outputs": [
                "t-283"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 535791,
                "end": 535802
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-257",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-97",
                "t-280"
            ],
            "outputs": [
                "t-284"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 535826,
                "end": 535835
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-258",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-104",
                "t-281"
            ],
            "outputs": [
                "t-285"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 535859,
                "end": 535869
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-259",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-286"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 3,
                "start": 535906,
                "end": 535909
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-260",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-287"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                512
            ],
            "runtime": {
                "duration": 1,
                "start": 535931,
                "end": 535932
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-261",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-288"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                262656
            ],
            "runtime": {
                "duration": 1,
                "start": 535954,
                "end": 535955
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-262",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-289"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                263168
            ],
            "runtime": {
                "duration": 2,
                "start": 535977,
                "end": 535979
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-263",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-290"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                525312
            ],
            "runtime": {
                "duration": 2,
                "start": 535999,
                "end": 536001
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-264",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-291"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                525824
            ],
            "runtime": {
                "duration": 1,
                "start": 536022,
                "end": 536023
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-265",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-292"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                787968
            ],
            "runtime": {
                "duration": 2,
                "start": 536050,
                "end": 536052
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-266",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-293"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                788480
            ],
            "runtime": {
                "duration": 1,
                "start": 536073,
                "end": 536074
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-267",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-294"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1050624
            ],
            "runtime": {
                "duration": 5,
                "start": 536096,
                "end": 536101
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-268",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-295"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                1051136
            ],
            "runtime": {
                "duration": 1,
                "start": 536123,
                "end": 536124
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-269",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-296"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1313280
            ],
            "runtime": {
                "duration": 2,
                "start": 536145,
                "end": 536147
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-270",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-297"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    784
                ],
                [
                    784,
                    1
                ],
                1313792
            ],
            "runtime": {
                "duration": 2,
                "start": 536177,
                "end": 536179
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-271",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-127",
                "t-286"
            ],
            "outputs": [
                "t-298"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 13,
                "start": 536204,
                "end": 536217
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-272",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-134",
                "t-287"
            ],
            "outputs": [
                "t-299"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 536241,
                "end": 536252
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-273",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-156",
                "t-288"
            ],
            "outputs": [
                "t-300"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 536275,
                "end": 536285
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-274",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-163",
                "t-289"
            ],
            "outputs": [
                "t-301"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 536319,
                "end": 536330
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-275",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-185",
                "t-290"
            ],
            "outputs": [
                "t-302"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536355,
                "end": 536364
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-276",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-192",
                "t-291"
            ],
            "outputs": [
                "t-303"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536387,
                "end": 536396
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-277",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-214",
                "t-292"
            ],
            "outputs": [
                "t-304"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 536423,
                "end": 536433
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-278",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-221",
                "t-293"
            ],
            "outputs": [
                "t-305"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536458,
                "end": 536467
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-279",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-243",
                "t-294"
            ],
            "outputs": [
                "t-306"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536490,
                "end": 536499
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-280",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-250",
                "t-295"
            ],
            "outputs": [
                "t-307"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536522,
                "end": 536531
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-281",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-267",
                "t-296"
            ],
            "outputs": [
                "t-308"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536560,
                "end": 536569
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-282",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-274",
                "t-297"
            ],
            "outputs": [
                "t-309"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536592,
                "end": 536601
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-283",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-310"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 154,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 154,
                "start": 536958,
                "end": 537112
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-284",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-311"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 537238,
                "end": 537240
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-285",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-309",
                "t-5"
            ],
            "outputs": [
                "t-312"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 33,
                "flops": 401408.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 33,
                "start": 537721,
                "end": 537754
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-286",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-313",
                "t-314"
            ],
            "outputs": [
                "t-315"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 537867,
                "end": 537887
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-287",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-315",
                "t-312"
            ],
            "outputs": [
                "t-316"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 12,
                "start": 537979,
                "end": 537991
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-288",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-317",
                "t-314"
            ],
            "outputs": [
                "t-318"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 538083,
                "end": 538094
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-289",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-318",
                "t-312",
                "t-312"
            ],
            "outputs": [
                "t-319"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 16,
                "start": 538212,
                "end": 538228
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-290",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-319"
            ],
            "outputs": [
                "t-320"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 538327,
                "end": 538344
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-291",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-320",
                "t-321"
            ],
            "outputs": [
                "t-322"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 538449,
                "end": 538467
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-292",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-322",
                "t-320"
            ],
            "outputs": [
                "t-323"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 538561,
                "end": 538574
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-293",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-5",
                "t-316",
                "t-323"
            ],
            "outputs": [
                "t-324"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 15,
                "start": 538683,
                "end": 538698
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-294",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-308",
                "t-6"
            ],
            "outputs": [
                "t-325"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 17,
                "start": 538789,
                "end": 538806
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-295",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-326",
                "t-327"
            ],
            "outputs": [
                "t-328"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 538903,
                "end": 538919
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-296",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-328",
                "t-325"
            ],
            "outputs": [
                "t-329"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 12,
                "start": 539013,
                "end": 539025
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-297",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-330",
                "t-327"
            ],
            "outputs": [
                "t-331"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 539109,
                "end": 539120
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-298",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-331",
                "t-325",
                "t-325"
            ],
            "outputs": [
                "t-332"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 13,
                "start": 539207,
                "end": 539220
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-299",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-332"
            ],
            "outputs": [
                "t-333"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 539297,
                "end": 539313
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-300",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-333",
                "t-334"
            ],
            "outputs": [
                "t-335"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 539402,
                "end": 539417
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-301",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-335",
                "t-333"
            ],
            "outputs": [
                "t-336"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 539505,
                "end": 539517
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-302",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-6",
                "t-329",
                "t-336"
            ],
            "outputs": [
                "t-337"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 14,
                "start": 539605,
                "end": 539619
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-303",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-307",
                "t-9"
            ],
            "outputs": [
                "t-338"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 539712,
                "end": 539727
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-304",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-339",
                "t-333"
            ],
            "outputs": [
                "t-340"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 539809,
                "end": 539821
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-305",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-340",
                "t-338"
            ],
            "outputs": [
                "t-341"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 539906,
                "end": 539916
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-306",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-342",
                "t-333"
            ],
            "outputs": [
                "t-343"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 540001,
                "end": 540012
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-307",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-343",
                "t-338",
                "t-338"
            ],
            "outputs": [
                "t-344"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 540101,
                "end": 540113
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-308",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-344"
            ],
            "outputs": [
                "t-345"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 540195,
                "end": 540209
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-309",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-345",
                "t-346"
            ],
            "outputs": [
                "t-347"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 540292,
                "end": 540306
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-310",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-347",
                "t-345"
            ],
            "outputs": [
                "t-348"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 540391,
                "end": 540403
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-311",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-9",
                "t-341",
                "t-348"
            ],
            "outputs": [
                "t-349"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 540491,
                "end": 540504
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-312",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-306",
                "t-10"
            ],
            "outputs": [
                "t-350"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 540599,
                "end": 540615
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-313",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-351",
                "t-345"
            ],
            "outputs": [
                "t-352"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 540697,
                "end": 540709
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-314",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-352",
                "t-350"
            ],
            "outputs": [
                "t-353"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 540787,
                "end": 540797
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-315",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-354",
                "t-345"
            ],
            "outputs": [
                "t-355"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 540881,
                "end": 540891
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-316",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-355",
                "t-350",
                "t-350"
            ],
            "outputs": [
                "t-356"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 540978,
                "end": 540990
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-317",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-356"
            ],
            "outputs": [
                "t-357"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 541243,
                "end": 541260
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-318",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-357",
                "t-358"
            ],
            "outputs": [
                "t-359"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 541570,
                "end": 541587
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-319",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-359",
                "t-357"
            ],
            "outputs": [
                "t-360"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 541894,
                "end": 541908
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-320",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-10",
                "t-353",
                "t-360"
            ],
            "outputs": [
                "t-361"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 684,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 684,
                "start": 542223,
                "end": 542907
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-321",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-305",
                "t-13"
            ],
            "outputs": [
                "t-362"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 17,
                "start": 543012,
                "end": 543029
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-322",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-363",
                "t-357"
            ],
            "outputs": [
                "t-364"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 543144,
                "end": 543159
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-323",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-364",
                "t-362"
            ],
            "outputs": [
                "t-365"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 14,
                "start": 543432,
                "end": 543446
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-324",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-366",
                "t-357"
            ],
            "outputs": [
                "t-367"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 543528,
                "end": 543539
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-325",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-367",
                "t-362",
                "t-362"
            ],
            "outputs": [
                "t-368"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 543633,
                "end": 543645
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-326",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-368"
            ],
            "outputs": [
                "t-369"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 543732,
                "end": 543748
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-327",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-369",
                "t-370"
            ],
            "outputs": [
                "t-371"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 543841,
                "end": 543857
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-328",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-371",
                "t-369"
            ],
            "outputs": [
                "t-372"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 543958,
                "end": 543970
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-329",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-13",
                "t-365",
                "t-372"
            ],
            "outputs": [
                "t-373"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 544059,
                "end": 544072
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-330",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-304",
                "t-14"
            ],
            "outputs": [
                "t-374"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 544175,
                "end": 544190
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-331",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-375",
                "t-369"
            ],
            "outputs": [
                "t-376"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 544279,
                "end": 544291
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-332",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-376",
                "t-374"
            ],
            "outputs": [
                "t-377"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 544371,
                "end": 544381
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-333",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-378",
                "t-369"
            ],
            "outputs": [
                "t-379"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 544461,
                "end": 544471
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-334",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-379",
                "t-374",
                "t-374"
            ],
            "outputs": [
                "t-380"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 544553,
                "end": 544564
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-335",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-380"
            ],
            "outputs": [
                "t-381"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 544641,
                "end": 544656
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-336",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-381",
                "t-382"
            ],
            "outputs": [
                "t-383"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 544737,
                "end": 544751
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-337",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-383",
                "t-381"
            ],
            "outputs": [
                "t-384"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 544837,
                "end": 544848
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-338",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-14",
                "t-377",
                "t-384"
            ],
            "outputs": [
                "t-385"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 11,
                "start": 544933,
                "end": 544944
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-339",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-303",
                "t-17"
            ],
            "outputs": [
                "t-386"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 545046,
                "end": 545061
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-340",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-387",
                "t-381"
            ],
            "outputs": [
                "t-388"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 545146,
                "end": 545158
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-341",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-388",
                "t-386"
            ],
            "outputs": [
                "t-389"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 9,
                "start": 545236,
                "end": 545245
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-342",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-390",
                "t-381"
            ],
            "outputs": [
                "t-391"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 545349,
                "end": 545363
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-343",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-391",
                "t-386",
                "t-386"
            ],
            "outputs": [
                "t-392"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 14,
                "start": 545454,
                "end": 545468
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-344",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-392"
            ],
            "outputs": [
                "t-393"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 545548,
                "end": 545564
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-345",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-393",
                "t-394"
            ],
            "outputs": [
                "t-395"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 545650,
                "end": 545666
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-346",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-395",
                "t-393"
            ],
            "outputs": [
                "t-396"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 545755,
                "end": 545767
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-347",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-17",
                "t-389",
                "t-396"
            ],
            "outputs": [
                "t-397"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 545850,
                "end": 545863
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-348",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-302",
                "t-18"
            ],
            "outputs": [
                "t-398"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 545964,
                "end": 545980
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-349",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-399",
                "t-393"
            ],
            "outputs": [
                "t-400"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 546075,
                "end": 546088
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-350",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-400",
                "t-398"
            ],
            "outputs": [
                "t-401"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 546173,
                "end": 546184
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-351",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-402",
                "t-393"
            ],
            "outputs": [
                "t-403"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 546263,
                "end": 546273
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-352",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-403",
                "t-398",
                "t-398"
            ],
            "outputs": [
                "t-404"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 546354,
                "end": 546366
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-353",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-404"
            ],
            "outputs": [
                "t-405"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 546439,
                "end": 546452
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-354",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-405",
                "t-406"
            ],
            "outputs": [
                "t-407"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 546535,
                "end": 546550
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-355",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-407",
                "t-405"
            ],
            "outputs": [
                "t-408"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 546638,
                "end": 546650
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-356",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-18",
                "t-401",
                "t-408"
            ],
            "outputs": [
                "t-409"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 546743,
                "end": 546755
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-357",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-301",
                "t-21"
            ],
            "outputs": [
                "t-410"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 546851,
                "end": 546867
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-358",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-411",
                "t-405"
            ],
            "outputs": [
                "t-412"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 546950,
                "end": 546962
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-359",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-412",
                "t-410"
            ],
            "outputs": [
                "t-413"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 547049,
                "end": 547060
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-360",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-414",
                "t-405"
            ],
            "outputs": [
                "t-415"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 547146,
                "end": 547157
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-361",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-415",
                "t-410",
                "t-410"
            ],
            "outputs": [
                "t-416"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 547246,
                "end": 547258
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-362",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-416"
            ],
            "outputs": [
                "t-417"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 547338,
                "end": 547352
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-363",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-417",
                "t-418"
            ],
            "outputs": [
                "t-419"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 547440,
                "end": 547455
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-364",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-419",
                "t-417"
            ],
            "outputs": [
                "t-420"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 547542,
                "end": 547554
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-365",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-21",
                "t-413",
                "t-420"
            ],
            "outputs": [
                "t-421"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 547661,
                "end": 547674
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-366",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-300",
                "t-22"
            ],
            "outputs": [
                "t-422"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 547775,
                "end": 547790
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-367",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-423",
                "t-417"
            ],
            "outputs": [
                "t-424"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 547884,
                "end": 547896
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-368",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-424",
                "t-422"
            ],
            "outputs": [
                "t-425"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 547981,
                "end": 547992
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-369",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-426",
                "t-417"
            ],
            "outputs": [
                "t-427"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 548084,
                "end": 548094
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-370",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-427",
                "t-422",
                "t-422"
            ],
            "outputs": [
                "t-428"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 548182,
                "end": 548194
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-371",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-428"
            ],
            "outputs": [
                "t-429"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 548278,
                "end": 548292
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-372",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-429",
                "t-430"
            ],
            "outputs": [
                "t-431"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 548377,
                "end": 548392
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-373",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-431",
                "t-429"
            ],
            "outputs": [
                "t-432"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 548473,
                "end": 548484
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-374",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-22",
                "t-425",
                "t-432"
            ],
            "outputs": [
                "t-433"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 548569,
                "end": 548581
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-375",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-299",
                "t-25"
            ],
            "outputs": [
                "t-434"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 18,
                "start": 548723,
                "end": 548741
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-376",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-435",
                "t-429"
            ],
            "outputs": [
                "t-436"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 548848,
                "end": 548862
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-377",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-436",
                "t-434"
            ],
            "outputs": [
                "t-437"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 15,
                "start": 548959,
                "end": 548974
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-378",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-438",
                "t-429"
            ],
            "outputs": [
                "t-439"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 549074,
                "end": 549088
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-379",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-439",
                "t-434",
                "t-434"
            ],
            "outputs": [
                "t-440"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 13,
                "start": 549170,
                "end": 549183
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-380",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-440"
            ],
            "outputs": [
                "t-441"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 549262,
                "end": 549278
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-381",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-441",
                "t-442"
            ],
            "outputs": [
                "t-443"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 549362,
                "end": 549378
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-382",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-443",
                "t-441"
            ],
            "outputs": [
                "t-444"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 549458,
                "end": 549470
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-383",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-25",
                "t-437",
                "t-444"
            ],
            "outputs": [
                "t-445"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 549554,
                "end": 549567
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-384",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-298",
                "t-26"
            ],
            "outputs": [
                "t-446"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 549661,
                "end": 549677
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-385",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-447",
                "t-441"
            ],
            "outputs": [
                "t-448"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 549763,
                "end": 549775
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-386",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-448",
                "t-446"
            ],
            "outputs": [
                "t-449"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 549855,
                "end": 549865
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-387",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-450",
                "t-441"
            ],
            "outputs": [
                "t-451"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 549945,
                "end": 549955
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-388",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-451",
                "t-446",
                "t-446"
            ],
            "outputs": [
                "t-452"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 550038,
                "end": 550049
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-389",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-452"
            ],
            "outputs": [
                "t-453"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 550125,
                "end": 550139
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-390",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-453",
                "t-454"
            ],
            "outputs": [
                "t-455"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 550222,
                "end": 550237
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-391",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-455",
                "t-453"
            ],
            "outputs": [
                "t-456"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 550322,
                "end": 550333
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-392",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-26",
                "t-449",
                "t-456"
            ],
            "outputs": [
                "t-457"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 550420,
                "end": 550432
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-393",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-285",
                "t-29"
            ],
            "outputs": [
                "t-458"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 550528,
                "end": 550543
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-394",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-459",
                "t-453"
            ],
            "outputs": [
                "t-460"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 550631,
                "end": 550644
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-395",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-460",
                "t-458"
            ],
            "outputs": [
                "t-461"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 550721,
                "end": 550731
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-396",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-462",
                "t-453"
            ],
            "outputs": [
                "t-463"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 550810,
                "end": 550820
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-397",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-463",
                "t-458",
                "t-458"
            ],
            "outputs": [
                "t-464"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 550897,
                "end": 550908
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-398",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-464"
            ],
            "outputs": [
                "t-465"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 550984,
                "end": 550998
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-399",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-465",
                "t-466"
            ],
            "outputs": [
                "t-467"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 551080,
                "end": 551095
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-400",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-467",
                "t-465"
            ],
            "outputs": [
                "t-468"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 551181,
                "end": 551192
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-401",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-29",
                "t-461",
                "t-468"
            ],
            "outputs": [
                "t-469"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 551278,
                "end": 551290
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-402",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-284",
                "t-30"
            ],
            "outputs": [
                "t-470"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 551379,
                "end": 551394
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-403",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-471",
                "t-465"
            ],
            "outputs": [
                "t-472"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 551483,
                "end": 551495
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-404",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-472",
                "t-470"
            ],
            "outputs": [
                "t-473"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 551575,
                "end": 551585
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-405",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-474",
                "t-465"
            ],
            "outputs": [
                "t-475"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 551666,
                "end": 551677
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-406",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-475",
                "t-470",
                "t-470"
            ],
            "outputs": [
                "t-476"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 551756,
                "end": 551767
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-407",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-476"
            ],
            "outputs": [
                "t-477"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 551849,
                "end": 551863
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-408",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-477",
                "t-478"
            ],
            "outputs": [
                "t-479"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 551947,
                "end": 551962
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-409",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-479",
                "t-477"
            ],
            "outputs": [
                "t-480"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 552042,
                "end": 552053
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-410",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-30",
                "t-473",
                "t-480"
            ],
            "outputs": [
                "t-481"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 552136,
                "end": 552148
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-411",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-283",
                "t-33"
            ],
            "outputs": [
                "t-482"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 5120.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 552238,
                "end": 552254
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-412",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-483",
                "t-477"
            ],
            "outputs": [
                "t-484"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 552347,
                "end": 552359
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-413",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-484",
                "t-482"
            ],
            "outputs": [
                "t-485"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 552438,
                "end": 552448
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-414",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-486",
                "t-477"
            ],
            "outputs": [
                "t-487"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 552526,
                "end": 552537
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-415",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-487",
                "t-482",
                "t-482"
            ],
            "outputs": [
                "t-488"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 552617,
                "end": 552629
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-416",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-488"
            ],
            "outputs": [
                "t-489"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 552700,
                "end": 552715
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-417",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-489",
                "t-490"
            ],
            "outputs": [
                "t-491"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 552796,
                "end": 552811
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-418",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-491",
                "t-489"
            ],
            "outputs": [
                "t-492"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 552894,
                "end": 552906
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-419",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-33",
                "t-485",
                "t-492"
            ],
            "outputs": [
                "t-493"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 552988,
                "end": 553000
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-420",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-282",
                "t-34"
            ],
            "outputs": [
                "t-494"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 10.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 553101,
                "end": 553117
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-421",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-495",
                "t-489"
            ],
            "outputs": [
                "t-496"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 553200,
                "end": 553212
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-422",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-496",
                "t-494"
            ],
            "outputs": [
                "t-497"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 553293,
                "end": 553303
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-423",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-498",
                "t-489"
            ],
            "outputs": [
                "t-499"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 553379,
                "end": 553389
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-424",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-499",
                "t-494",
                "t-494"
            ],
            "outputs": [
                "t-500"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 553473,
                "end": 553484
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-425",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-500"
            ],
            "outputs": [
                "t-501"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 553564,
                "end": 553579
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-426",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-501",
                "t-502"
            ],
            "outputs": [
                "t-503"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 553669,
                "end": 553684
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-427",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-503",
                "t-501"
            ],
            "outputs": [
                "t-504"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 553773,
                "end": 553784
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-428",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-34",
                "t-497",
                "t-504"
            ],
            "outputs": [
                "t-505"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 553865,
                "end": 553877
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        }
    ],
    "tensors": {
        "t-1": {
            "name": "t-1",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-2": {
            "name": "t-2",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-4": {
            "name": "t-4",
            "dtype": "FP32",
            "shape": [
                256,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-3": {
            "name": "t-3",
            "dtype": "FP32",
            "shape": [
                256,
                1,
                28,
                28
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-7": {
            "name": "t-7",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-5": {
            "name": "t-5",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-6": {
            "name": "t-6",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-8": {
            "name": "t-8",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-11": {
            "name": "t-11",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-9": {
            "name": "t-9",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-10": {
            "name": "t-10",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-12": {
            "name": "t-12",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-15": {
            "name": "t-15",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-13": {
            "name": "t-13",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-14": {
            "name": "t-14",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-16": {
            "name": "t-16",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-19": {
            "name": "t-19",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-17": {
            "name": "t-17",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-18": {
            "name": "t-18",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-20": {
            "name": "t-20",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-23": {
            "name": "t-23",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-21": {
            "name": "t-21",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-22": {
            "name": "t-22",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-24": {
            "name": "t-24",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-27": {
            "name": "t-27",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-25": {
            "name": "t-25",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-26": {
            "name": "t-26",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-28": {
            "name": "t-28",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-31": {
            "name": "t-31",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-29": {
            "name": "t-29",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-30": {
            "name": "t-30",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-32": {
            "name": "t-32",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-35": {
            "name": "t-35",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-33": {
            "name": "t-33",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-34": {
            "name": "t-34",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-36": {
            "name": "t-36",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-38": {
            "name": "t-38",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-37": {
            "name": "t-37",
            "dtype": "INT64",
            "shape": [
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-39": {
            "name": "t-39",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-43": {
            "name": "t-43",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-40": {
            "name": "t-40",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-41": {
            "name": "t-41",
            "dtype": "BIN",
            "shape": [
                0
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-42": {
            "name": "t-42",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-44": {
            "name": "t-44",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-45": {
            "name": "t-45",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-46": {
            "name": "t-46",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-47": {
            "name": "t-47",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-48": {
            "name": "t-48",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-50": {
            "name": "t-50",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-47",
            "allocation": null
        },
        "t-49": {
            "name": "t-49",
            "dtype": "UINT8",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-51": {
            "name": "t-51",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-49",
            "allocation": null
        },
        "t-52": {
            "name": "t-52",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-54": {
            "name": "t-54",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-53": {
            "name": "t-53",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-55": {
            "name": "t-55",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-56": {
            "name": "t-56",
            "dtype": "FP32",
            "shape": [
                10,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-57": {
            "name": "t-57",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-58": {
            "name": "t-58",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-59": {
            "name": "t-59",
            "dtype": "FP32",
            "shape": [
                1,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-60": {
            "name": "t-60",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-61": {
            "name": "t-61",
            "dtype": "BIN",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-62": {
            "name": "t-62",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-63": {
            "name": "t-63",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-64": {
            "name": "t-64",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-62",
            "allocation": null
        },
        "t-65": {
            "name": "t-65",
            "dtype": "BIN",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-66": {
            "name": "t-66",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-64",
            "allocation": null
        },
        "t-68": {
            "name": "t-68",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-67",
            "allocation": null
        },
        "t-67": {
            "name": "t-67",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-70": {
            "name": "t-70",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-69",
            "allocation": null
        },
        "t-69": {
            "name": "t-69",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-71": {
            "name": "t-71",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-72": {
            "name": "t-72",
            "dtype": "BIN",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-73": {
            "name": "t-73",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-75": {
            "name": "t-75",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-74",
            "allocation": null
        },
        "t-74": {
            "name": "t-74",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-77": {
            "name": "t-77",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-76",
            "allocation": null
        },
        "t-76": {
            "name": "t-76",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-79": {
            "name": "t-79",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-78": {
            "name": "t-78",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-80": {
            "name": "t-80",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-78",
            "allocation": null
        },
        "t-81": {
            "name": "t-81",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-83": {
            "name": "t-83",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-82": {
            "name": "t-82",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-84": {
            "name": "t-84",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-85": {
            "name": "t-85",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-86": {
            "name": "t-86",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-87": {
            "name": "t-87",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-88": {
            "name": "t-88",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-89": {
            "name": "t-89",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-90": {
            "name": "t-90",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-91": {
            "name": "t-91",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-92": {
            "name": "t-92",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-93": {
            "name": "t-93",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-91",
            "allocation": null
        },
        "t-94": {
            "name": "t-94",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-95": {
            "name": "t-95",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-93",
            "allocation": null
        },
        "t-97": {
            "name": "t-97",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-96",
            "allocation": null
        },
        "t-96": {
            "name": "t-96",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-99": {
            "name": "t-99",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-98",
            "allocation": null
        },
        "t-98": {
            "name": "t-98",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-100": {
            "name": "t-100",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-101": {
            "name": "t-101",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-87",
            "allocation": null
        },
        "t-102": {
            "name": "t-102",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-104": {
            "name": "t-104",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-103",
            "allocation": null
        },
        "t-103": {
            "name": "t-103",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-106": {
            "name": "t-106",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-105",
            "allocation": null
        },
        "t-105": {
            "name": "t-105",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-107": {
            "name": "t-107",
            "dtype": "FP32",
            "shape": [
                267786
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-109": {
            "name": "t-109",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-108": {
            "name": "t-108",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-110": {
            "name": "t-110",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-108",
            "allocation": null
        },
        "t-111": {
            "name": "t-111",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-113": {
            "name": "t-113",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-112": {
            "name": "t-112",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-114": {
            "name": "t-114",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-115": {
            "name": "t-115",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-116": {
            "name": "t-116",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-86",
            "allocation": null
        },
        "t-117": {
            "name": "t-117",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-118": {
            "name": "t-118",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-119": {
            "name": "t-119",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-120": {
            "name": "t-120",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-121": {
            "name": "t-121",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-122": {
            "name": "t-122",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-123": {
            "name": "t-123",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-121",
            "allocation": null
        },
        "t-124": {
            "name": "t-124",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-125": {
            "name": "t-125",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-123",
            "allocation": null
        },
        "t-127": {
            "name": "t-127",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-126",
            "allocation": null
        },
        "t-126": {
            "name": "t-126",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-129": {
            "name": "t-129",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-128",
            "allocation": null
        },
        "t-128": {
            "name": "t-128",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-130": {
            "name": "t-130",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-131": {
            "name": "t-131",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-117",
            "allocation": null
        },
        "t-132": {
            "name": "t-132",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-134": {
            "name": "t-134",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-133",
            "allocation": null
        },
        "t-133": {
            "name": "t-133",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-136": {
            "name": "t-136",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-135",
            "allocation": null
        },
        "t-135": {
            "name": "t-135",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-138": {
            "name": "t-138",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-137": {
            "name": "t-137",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-139": {
            "name": "t-139",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-137",
            "allocation": null
        },
        "t-140": {
            "name": "t-140",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-142": {
            "name": "t-142",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-141": {
            "name": "t-141",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-143": {
            "name": "t-143",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-144": {
            "name": "t-144",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-145": {
            "name": "t-145",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-116",
            "allocation": null
        },
        "t-146": {
            "name": "t-146",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-131",
            "allocation": null
        },
        "t-147": {
            "name": "t-147",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-148": {
            "name": "t-148",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-149": {
            "name": "t-149",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-150": {
            "name": "t-150",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-151": {
            "name": "t-151",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-152": {
            "name": "t-152",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-150",
            "allocation": null
        },
        "t-153": {
            "name": "t-153",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-154": {
            "name": "t-154",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-152",
            "allocation": null
        },
        "t-156": {
            "name": "t-156",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-155",
            "allocation": null
        },
        "t-155": {
            "name": "t-155",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-158": {
            "name": "t-158",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-157",
            "allocation": null
        },
        "t-157": {
            "name": "t-157",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-159": {
            "name": "t-159",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-160": {
            "name": "t-160",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-146",
            "allocation": null
        },
        "t-161": {
            "name": "t-161",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-163": {
            "name": "t-163",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-162",
            "allocation": null
        },
        "t-162": {
            "name": "t-162",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-165": {
            "name": "t-165",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-164",
            "allocation": null
        },
        "t-164": {
            "name": "t-164",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-167": {
            "name": "t-167",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-166": {
            "name": "t-166",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-168": {
            "name": "t-168",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-166",
            "allocation": null
        },
        "t-169": {
            "name": "t-169",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-171": {
            "name": "t-171",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-170": {
            "name": "t-170",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-172": {
            "name": "t-172",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-173": {
            "name": "t-173",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-174": {
            "name": "t-174",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-145",
            "allocation": null
        },
        "t-175": {
            "name": "t-175",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-160",
            "allocation": null
        },
        "t-176": {
            "name": "t-176",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-177": {
            "name": "t-177",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-178": {
            "name": "t-178",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-179": {
            "name": "t-179",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-180": {
            "name": "t-180",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-181": {
            "name": "t-181",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-179",
            "allocation": null
        },
        "t-182": {
            "name": "t-182",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-183": {
            "name": "t-183",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-181",
            "allocation": null
        },
        "t-185": {
            "name": "t-185",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-184",
            "allocation": null
        },
        "t-184": {
            "name": "t-184",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-187": {
            "name": "t-187",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-186",
            "allocation": null
        },
        "t-186": {
            "name": "t-186",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-188": {
            "name": "t-188",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-189": {
            "name": "t-189",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-175",
            "allocation": null
        },
        "t-190": {
            "name": "t-190",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-192": {
            "name": "t-192",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-191",
            "allocation": null
        },
        "t-191": {
            "name": "t-191",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-194": {
            "name": "t-194",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-193",
            "allocation": null
        },
        "t-193": {
            "name": "t-193",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-196": {
            "name": "t-196",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-195": {
            "name": "t-195",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-197": {
            "name": "t-197",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-172",
            "allocation": null
        },
        "t-198": {
            "name": "t-198",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-200": {
            "name": "t-200",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-199": {
            "name": "t-199",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-201": {
            "name": "t-201",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-202": {
            "name": "t-202",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-203": {
            "name": "t-203",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-189",
            "allocation": null
        },
        "t-204": {
            "name": "t-204",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-182",
            "allocation": null
        },
        "t-205": {
            "name": "t-205",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-206": {
            "name": "t-206",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-207": {
            "name": "t-207",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-208": {
            "name": "t-208",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-209": {
            "name": "t-209",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-210": {
            "name": "t-210",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-208",
            "allocation": null
        },
        "t-211": {
            "name": "t-211",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-212": {
            "name": "t-212",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-210",
            "allocation": null
        },
        "t-214": {
            "name": "t-214",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-213",
            "allocation": null
        },
        "t-213": {
            "name": "t-213",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-216": {
            "name": "t-216",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-215",
            "allocation": null
        },
        "t-215": {
            "name": "t-215",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-217": {
            "name": "t-217",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-218": {
            "name": "t-218",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-204",
            "allocation": null
        },
        "t-219": {
            "name": "t-219",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-221": {
            "name": "t-221",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-220",
            "allocation": null
        },
        "t-220": {
            "name": "t-220",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-223": {
            "name": "t-223",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-222",
            "allocation": null
        },
        "t-222": {
            "name": "t-222",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-225": {
            "name": "t-225",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-224": {
            "name": "t-224",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-226": {
            "name": "t-226",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-201",
            "allocation": null
        },
        "t-227": {
            "name": "t-227",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-229": {
            "name": "t-229",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-228": {
            "name": "t-228",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-230": {
            "name": "t-230",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-231": {
            "name": "t-231",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-232": {
            "name": "t-232",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-218",
            "allocation": null
        },
        "t-233": {
            "name": "t-233",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-211",
            "allocation": null
        },
        "t-234": {
            "name": "t-234",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-235": {
            "name": "t-235",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-236": {
            "name": "t-236",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-237": {
            "name": "t-237",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-238": {
            "name": "t-238",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-239": {
            "name": "t-239",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-237",
            "allocation": null
        },
        "t-240": {
            "name": "t-240",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-241": {
            "name": "t-241",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-239",
            "allocation": null
        },
        "t-243": {
            "name": "t-243",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-242",
            "allocation": null
        },
        "t-242": {
            "name": "t-242",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-245": {
            "name": "t-245",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-244",
            "allocation": null
        },
        "t-244": {
            "name": "t-244",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-246": {
            "name": "t-246",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-247": {
            "name": "t-247",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-233",
            "allocation": null
        },
        "t-248": {
            "name": "t-248",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-250": {
            "name": "t-250",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-249",
            "allocation": null
        },
        "t-249": {
            "name": "t-249",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-252": {
            "name": "t-252",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-251",
            "allocation": null
        },
        "t-251": {
            "name": "t-251",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-254": {
            "name": "t-254",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-253": {
            "name": "t-253",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-255": {
            "name": "t-255",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-230",
            "allocation": null
        },
        "t-256": {
            "name": "t-256",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-257": {
            "name": "t-257",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-258": {
            "name": "t-258",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-259": {
            "name": "t-259",
            "dtype": "FP32",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-260": {
            "name": "t-260",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-261": {
            "name": "t-261",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-262": {
            "name": "t-262",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-263": {
            "name": "t-263",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-264": {
            "name": "t-264",
            "dtype": "BIN",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-265": {
            "name": "t-265",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-263",
            "allocation": null
        },
        "t-267": {
            "name": "t-267",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-266",
            "allocation": null
        },
        "t-266": {
            "name": "t-266",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-269": {
            "name": "t-269",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-268",
            "allocation": null
        },
        "t-268": {
            "name": "t-268",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-270": {
            "name": "t-270",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-271": {
            "name": "t-271",
            "dtype": "BIN",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-272": {
            "name": "t-272",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-274": {
            "name": "t-274",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-273",
            "allocation": null
        },
        "t-273": {
            "name": "t-273",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-276": {
            "name": "t-276",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-275",
            "allocation": null
        },
        "t-275": {
            "name": "t-275",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-277": {
            "name": "t-277",
            "dtype": "FP32",
            "shape": [
                1715200
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-278": {
            "name": "t-278",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-279": {
            "name": "t-279",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-280": {
            "name": "t-280",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-281": {
            "name": "t-281",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-282": {
            "name": "t-282",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-68",
            "allocation": null
        },
        "t-283": {
            "name": "t-283",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-75",
            "allocation": null
        },
        "t-284": {
            "name": "t-284",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-97",
            "allocation": null
        },
        "t-285": {
            "name": "t-285",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-104",
            "allocation": null
        },
        "t-286": {
            "name": "t-286",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-287": {
            "name": "t-287",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-288": {
            "name": "t-288",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-289": {
            "name": "t-289",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-290": {
            "name": "t-290",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-291": {
            "name": "t-291",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-292": {
            "name": "t-292",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-293": {
            "name": "t-293",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-294": {
            "name": "t-294",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-295": {
            "name": "t-295",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-296": {
            "name": "t-296",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-297": {
            "name": "t-297",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-298": {
            "name": "t-298",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-127",
            "allocation": null
        },
        "t-299": {
            "name": "t-299",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-134",
            "allocation": null
        },
        "t-300": {
            "name": "t-300",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-156",
            "allocation": null
        },
        "t-301": {
            "name": "t-301",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-163",
            "allocation": null
        },
        "t-302": {
            "name": "t-302",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-185",
            "allocation": null
        },
        "t-303": {
            "name": "t-303",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-192",
            "allocation": null
        },
        "t-304": {
            "name": "t-304",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-214",
            "allocation": null
        },
        "t-305": {
            "name": "t-305",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-221",
            "allocation": null
        },
        "t-306": {
            "name": "t-306",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-243",
            "allocation": null
        },
        "t-307": {
            "name": "t-307",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-250",
            "allocation": null
        },
        "t-308": {
            "name": "t-308",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-267",
            "allocation": null
        },
        "t-309": {
            "name": "t-309",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-274",
            "allocation": null
        },
        "t-310": {
            "name": "t-310",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-311": {
            "name": "t-311",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-312": {
            "name": "t-312",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-315": {
            "name": "t-315",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-313",
            "allocation": null
        },
        "t-313": {
            "name": "t-313",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-314": {
            "name": "t-314",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-316": {
            "name": "t-316",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-315",
            "allocation": null
        },
        "t-318": {
            "name": "t-318",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-317",
            "allocation": null
        },
        "t-317": {
            "name": "t-317",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-319": {
            "name": "t-319",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-318",
            "allocation": null
        },
        "t-320": {
            "name": "t-320",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-322": {
            "name": "t-322",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-321": {
            "name": "t-321",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-323": {
            "name": "t-323",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-322",
            "allocation": null
        },
        "t-324": {
            "name": "t-324",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-5",
            "allocation": null
        },
        "t-325": {
            "name": "t-325",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-328": {
            "name": "t-328",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-326",
            "allocation": null
        },
        "t-326": {
            "name": "t-326",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-327": {
            "name": "t-327",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-329": {
            "name": "t-329",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-328",
            "allocation": null
        },
        "t-331": {
            "name": "t-331",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-330",
            "allocation": null
        },
        "t-330": {
            "name": "t-330",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-332": {
            "name": "t-332",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-331",
            "allocation": null
        },
        "t-333": {
            "name": "t-333",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-335": {
            "name": "t-335",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-334": {
            "name": "t-334",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-336": {
            "name": "t-336",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-335",
            "allocation": null
        },
        "t-337": {
            "name": "t-337",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-6",
            "allocation": null
        },
        "t-338": {
            "name": "t-338",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-340": {
            "name": "t-340",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-339",
            "allocation": null
        },
        "t-339": {
            "name": "t-339",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-341": {
            "name": "t-341",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-340",
            "allocation": null
        },
        "t-343": {
            "name": "t-343",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-342",
            "allocation": null
        },
        "t-342": {
            "name": "t-342",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-344": {
            "name": "t-344",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-343",
            "allocation": null
        },
        "t-345": {
            "name": "t-345",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-347": {
            "name": "t-347",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-346": {
            "name": "t-346",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-348": {
            "name": "t-348",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-347",
            "allocation": null
        },
        "t-349": {
            "name": "t-349",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-9",
            "allocation": null
        },
        "t-350": {
            "name": "t-350",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-352": {
            "name": "t-352",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-351",
            "allocation": null
        },
        "t-351": {
            "name": "t-351",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-353": {
            "name": "t-353",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-352",
            "allocation": null
        },
        "t-355": {
            "name": "t-355",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-354",
            "allocation": null
        },
        "t-354": {
            "name": "t-354",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-356": {
            "name": "t-356",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-355",
            "allocation": null
        },
        "t-357": {
            "name": "t-357",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-359": {
            "name": "t-359",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-358": {
            "name": "t-358",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-360": {
            "name": "t-360",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-359",
            "allocation": null
        },
        "t-361": {
            "name": "t-361",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-10",
            "allocation": null
        },
        "t-362": {
            "name": "t-362",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-364": {
            "name": "t-364",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-363",
            "allocation": null
        },
        "t-363": {
            "name": "t-363",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-365": {
            "name": "t-365",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-364",
            "allocation": null
        },
        "t-367": {
            "name": "t-367",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-366",
            "allocation": null
        },
        "t-366": {
            "name": "t-366",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-368": {
            "name": "t-368",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-367",
            "allocation": null
        },
        "t-369": {
            "name": "t-369",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-371": {
            "name": "t-371",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-370": {
            "name": "t-370",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-372": {
            "name": "t-372",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-371",
            "allocation": null
        },
        "t-373": {
            "name": "t-373",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-13",
            "allocation": null
        },
        "t-374": {
            "name": "t-374",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-376": {
            "name": "t-376",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-375",
            "allocation": null
        },
        "t-375": {
            "name": "t-375",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-377": {
            "name": "t-377",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-376",
            "allocation": null
        },
        "t-379": {
            "name": "t-379",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-378",
            "allocation": null
        },
        "t-378": {
            "name": "t-378",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-380": {
            "name": "t-380",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-379",
            "allocation": null
        },
        "t-381": {
            "name": "t-381",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-383": {
            "name": "t-383",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-382": {
            "name": "t-382",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-384": {
            "name": "t-384",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-383",
            "allocation": null
        },
        "t-385": {
            "name": "t-385",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-14",
            "allocation": null
        },
        "t-386": {
            "name": "t-386",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-388": {
            "name": "t-388",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-387",
            "allocation": null
        },
        "t-387": {
            "name": "t-387",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-389": {
            "name": "t-389",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-388",
            "allocation": null
        },
        "t-391": {
            "name": "t-391",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-390",
            "allocation": null
        },
        "t-390": {
            "name": "t-390",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-392": {
            "name": "t-392",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-391",
            "allocation": null
        },
        "t-393": {
            "name": "t-393",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-395": {
            "name": "t-395",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-394": {
            "name": "t-394",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-396": {
            "name": "t-396",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-395",
            "allocation": null
        },
        "t-397": {
            "name": "t-397",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-17",
            "allocation": null
        },
        "t-398": {
            "name": "t-398",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-400": {
            "name": "t-400",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-399",
            "allocation": null
        },
        "t-399": {
            "name": "t-399",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-401": {
            "name": "t-401",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-400",
            "allocation": null
        },
        "t-403": {
            "name": "t-403",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-402",
            "allocation": null
        },
        "t-402": {
            "name": "t-402",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-404": {
            "name": "t-404",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-403",
            "allocation": null
        },
        "t-405": {
            "name": "t-405",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-407": {
            "name": "t-407",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-406": {
            "name": "t-406",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-408": {
            "name": "t-408",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-407",
            "allocation": null
        },
        "t-409": {
            "name": "t-409",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-18",
            "allocation": null
        },
        "t-410": {
            "name": "t-410",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-412": {
            "name": "t-412",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-411",
            "allocation": null
        },
        "t-411": {
            "name": "t-411",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-413": {
            "name": "t-413",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-412",
            "allocation": null
        },
        "t-415": {
            "name": "t-415",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-414",
            "allocation": null
        },
        "t-414": {
            "name": "t-414",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-416": {
            "name": "t-416",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-415",
            "allocation": null
        },
        "t-417": {
            "name": "t-417",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-419": {
            "name": "t-419",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-418": {
            "name": "t-418",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-420": {
            "name": "t-420",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-419",
            "allocation": null
        },
        "t-421": {
            "name": "t-421",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-21",
            "allocation": null
        },
        "t-422": {
            "name": "t-422",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-424": {
            "name": "t-424",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-423",
            "allocation": null
        },
        "t-423": {
            "name": "t-423",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-425": {
            "name": "t-425",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-424",
            "allocation": null
        },
        "t-427": {
            "name": "t-427",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-426",
            "allocation": null
        },
        "t-426": {
            "name": "t-426",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-428": {
            "name": "t-428",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-427",
            "allocation": null
        },
        "t-429": {
            "name": "t-429",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-431": {
            "name": "t-431",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-430": {
            "name": "t-430",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-432": {
            "name": "t-432",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-431",
            "allocation": null
        },
        "t-433": {
            "name": "t-433",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-22",
            "allocation": null
        },
        "t-434": {
            "name": "t-434",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-436": {
            "name": "t-436",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-435",
            "allocation": null
        },
        "t-435": {
            "name": "t-435",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-437": {
            "name": "t-437",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-436",
            "allocation": null
        },
        "t-439": {
            "name": "t-439",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-438",
            "allocation": null
        },
        "t-438": {
            "name": "t-438",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-440": {
            "name": "t-440",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-439",
            "allocation": null
        },
        "t-441": {
            "name": "t-441",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-443": {
            "name": "t-443",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-442": {
            "name": "t-442",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-444": {
            "name": "t-444",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-443",
            "allocation": null
        },
        "t-445": {
            "name": "t-445",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-25",
            "allocation": null
        },
        "t-446": {
            "name": "t-446",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-448": {
            "name": "t-448",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-447",
            "allocation": null
        },
        "t-447": {
            "name": "t-447",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-449": {
            "name": "t-449",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-448",
            "allocation": null
        },
        "t-451": {
            "name": "t-451",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-450",
            "allocation": null
        },
        "t-450": {
            "name": "t-450",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-452": {
            "name": "t-452",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-451",
            "allocation": null
        },
        "t-453": {
            "name": "t-453",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-455": {
            "name": "t-455",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-454": {
            "name": "t-454",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-456": {
            "name": "t-456",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-455",
            "allocation": null
        },
        "t-457": {
            "name": "t-457",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-26",
            "allocation": null
        },
        "t-458": {
            "name": "t-458",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-460": {
            "name": "t-460",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-459",
            "allocation": null
        },
        "t-459": {
            "name": "t-459",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-461": {
            "name": "t-461",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-460",
            "allocation": null
        },
        "t-463": {
            "name": "t-463",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-462",
            "allocation": null
        },
        "t-462": {
            "name": "t-462",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-464": {
            "name": "t-464",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-463",
            "allocation": null
        },
        "t-465": {
            "name": "t-465",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-467": {
            "name": "t-467",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-466": {
            "name": "t-466",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-468": {
            "name": "t-468",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-467",
            "allocation": null
        },
        "t-469": {
            "name": "t-469",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-29",
            "allocation": null
        },
        "t-470": {
            "name": "t-470",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-472": {
            "name": "t-472",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-471",
            "allocation": null
        },
        "t-471": {
            "name": "t-471",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-473": {
            "name": "t-473",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-472",
            "allocation": null
        },
        "t-475": {
            "name": "t-475",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-474",
            "allocation": null
        },
        "t-474": {
            "name": "t-474",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-476": {
            "name": "t-476",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-475",
            "allocation": null
        },
        "t-477": {
            "name": "t-477",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-479": {
            "name": "t-479",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-478": {
            "name": "t-478",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-480": {
            "name": "t-480",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-479",
            "allocation": null
        },
        "t-481": {
            "name": "t-481",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-30",
            "allocation": null
        },
        "t-482": {
            "name": "t-482",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-484": {
            "name": "t-484",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-483",
            "allocation": null
        },
        "t-483": {
            "name": "t-483",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-485": {
            "name": "t-485",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-484",
            "allocation": null
        },
        "t-487": {
            "name": "t-487",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-486",
            "allocation": null
        },
        "t-486": {
            "name": "t-486",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-488": {
            "name": "t-488",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-487",
            "allocation": null
        },
        "t-489": {
            "name": "t-489",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-491": {
            "name": "t-491",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-490": {
            "name": "t-490",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-492": {
            "name": "t-492",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-491",
            "allocation": null
        },
        "t-493": {
            "name": "t-493",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-33",
            "allocation": null
        },
        "t-494": {
            "name": "t-494",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-496": {
            "name": "t-496",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-495",
            "allocation": null
        },
        "t-495": {
            "name": "t-495",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-497": {
            "name": "t-497",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-496",
            "allocation": null
        },
        "t-499": {
            "name": "t-499",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-498",
            "allocation": null
        },
        "t-498": {
            "name": "t-498",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-500": {
            "name": "t-500",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-499",
            "allocation": null
        },
        "t-501": {
            "name": "t-501",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-503": {
            "name": "t-503",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-502": {
            "name": "t-502",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-504": {
            "name": "t-504",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-503",
            "allocation": null
        },
        "t-505": {
            "name": "t-505",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-34",
            "allocation": null
        }
    },
    "inputs": [
        "t-3",
        "t-5",
        "t-6",
        "t-9",
        "t-10",
        "t-13",
        "t-14",
        "t-17",
        "t-18",
        "t-21",
        "t-22",
        "t-25",
        "t-26",
        "t-29",
        "t-30",
        "t-33",
        "t-34",
        "t-37",
        "t-40",
        "t-41",
        "t-42",
        "t-49",
        "t-53",
        "t-67",
        "t-69",
        "t-74",
        "t-76",
        "t-78",
        "t-82",
        "t-96",
        "t-98",
        "t-103",
        "t-105",
        "t-107",
        "t-108",
        "t-112",
        "t-126",
        "t-128",
        "t-133",
        "t-135",
        "t-137",
        "t-141",
        "t-155",
        "t-157",
        "t-162",
        "t-164",
        "t-166",
        "t-170",
        "t-184",
        "t-186",
        "t-191",
        "t-193",
        "t-195",
        "t-199",
        "t-213",
        "t-215",
        "t-220",
        "t-222",
        "t-224",
        "t-228",
        "t-242",
        "t-244",
        "t-249",
        "t-251",
        "t-253",
        "t-266",
        "t-268",
        "t-273",
        "t-275",
        "t-277",
        "t-313",
        "t-314",
        "t-317",
        "t-321",
        "t-326",
        "t-327",
        "t-330",
        "t-334",
        "t-339",
        "t-342",
        "t-346",
        "t-351",
        "t-354",
        "t-358",
        "t-363",
        "t-366",
        "t-370",
        "t-375",
        "t-378",
        "t-382",
        "t-387",
        "t-390",
        "t-394",
        "t-399",
        "t-402",
        "t-406",
        "t-411",
        "t-414",
        "t-418",
        "t-423",
        "t-426",
        "t-430",
        "t-435",
        "t-438",
        "t-442",
        "t-447",
        "t-450",
        "t-454",
        "t-459",
        "t-462",
        "t-466",
        "t-471",
        "t-474",
        "t-478",
        "t-483",
        "t-486",
        "t-490",
        "t-495",
        "t-498",
        "t-502"
    ],
    "outputs": []
}