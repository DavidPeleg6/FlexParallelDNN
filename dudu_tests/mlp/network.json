{
    "name": "Some Default",
    "origin": "",
    "cpu_info": {
        "Architecture": "x86_64",
        "CPU op-mode(s)": "32-bit, 64-bit",
        "Byte Order": "Little Endian",
        "Address sizes": "46 bits physical, 48 bits virtual",
        "CPU(s)": "112",
        "On-line CPU(s) list": "0-111",
        "Thread(s) per core": "2",
        "Core(s) per socket": "28",
        "Socket(s)": "2",
        "NUMA node(s)": "2",
        "Vendor ID": "GenuineIntel",
        "CPU family": "6",
        "Model": "85",
        "Model name": "Intel(R) Xeon(R) Platinum 8180 CPU @ 2.50GHz",
        "Stepping": "4",
        "CPU MHz": "2500.068",
        "BogoMIPS": "5000.00",
        "Virtualization": "VT-x",
        "L1d cache": "1.8 MiB",
        "L1i cache": "1.8 MiB",
        "L2 cache": "56 MiB",
        "L3 cache": "77 MiB",
        "NUMA node0 CPU(s)": "0-27,56-83",
        "NUMA node1 CPU(s)": "28-55,84-111",
        "Vulnerability Itlb multihit": "KVM",
        "Vulnerability L1tf": "Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable",
        "Vulnerability Mds": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Vulnerability Meltdown": "Mitigation; PTI",
        "Vulnerability Spec store bypass": "Mitigation; Speculative Store Bypass disabled via prctl and seccomp",
        "Vulnerability Spectre v1": "Mitigation; usercopy/swapgs barriers and __user pointer sanitization",
        "Vulnerability Spectre v2": "Mitigation; Full generic retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling",
        "Vulnerability Srbds": "Not affected",
        "Vulnerability Tsx async abort": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Flags": "fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm arat pln pts pku ospke md_clear flush_l1d"
    },
    "layers": [
        {
            "name": "DistributedDataParallel/op-1",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-1"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 185,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 185,
                "start": 490197,
                "end": 490382
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/op-2",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-2"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 490516,
                "end": 490518
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/op-3",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-3"
            ],
            "outputs": [
                "t-4"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 7,
                "flops": 0.0
            },
            "args": [
                [
                    -1,
                    784
                ]
            ],
            "runtime": {
                "duration": 7,
                "start": 490704,
                "end": 490711
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 45, in forward\n    x = x.view(-1, 28 * 28)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-4",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-4",
                "t-5",
                "t-6"
            ],
            "outputs": [
                "t-7"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 778,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 778,
                "start": 490834,
                "end": 491612
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-5",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-7"
            ],
            "outputs": [
                "t-8"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 592,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 592,
                "start": 491760,
                "end": 492352
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-6",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-8",
                "t-9",
                "t-10"
            ],
            "outputs": [
                "t-11"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 741,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 741,
                "start": 492478,
                "end": 493219
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-7",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-11"
            ],
            "outputs": [
                "t-12"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 545,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 545,
                "start": 493342,
                "end": 493887
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-8",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-12",
                "t-13",
                "t-14"
            ],
            "outputs": [
                "t-15"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 741,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 741,
                "start": 494007,
                "end": 494748
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-9",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-15"
            ],
            "outputs": [
                "t-16"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 544,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 544,
                "start": 494869,
                "end": 495413
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-10",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-16",
                "t-17",
                "t-18"
            ],
            "outputs": [
                "t-19"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 702,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 702,
                "start": 495533,
                "end": 496235
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-11",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-19"
            ],
            "outputs": [
                "t-20"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 538,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 538,
                "start": 496355,
                "end": 496893
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-12",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-20",
                "t-21",
                "t-22"
            ],
            "outputs": [
                "t-23"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 715,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 715,
                "start": 497009,
                "end": 497724
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-13",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-23"
            ],
            "outputs": [
                "t-24"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 525,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 525,
                "start": 497849,
                "end": 498374
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-14",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-24",
                "t-25",
                "t-26"
            ],
            "outputs": [
                "t-27"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 710,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 710,
                "start": 498490,
                "end": 499200
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-15",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-27"
            ],
            "outputs": [
                "t-28"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 528,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 528,
                "start": 499318,
                "end": 499846
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-16",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-28",
                "t-29",
                "t-30"
            ],
            "outputs": [
                "t-31"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 705,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 705,
                "start": 499964,
                "end": 500669
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-17",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-31"
            ],
            "outputs": [
                "t-32"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 526,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 526,
                "start": 500787,
                "end": 501313
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-18",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-32",
                "t-33",
                "t-34"
            ],
            "outputs": [
                "t-35"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 722,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 722,
                "start": 501428,
                "end": 502150
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-19",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-35"
            ],
            "outputs": [
                "t-36"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 535,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 535,
                "start": 502275,
                "end": 502810
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "CrossEntropyLoss/op-20",
            "optype": "aten::cross_entropy_loss",
            "params": {},
            "inputs": [
                "t-36",
                "t-37"
            ],
            "outputs": [
                "t-38"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 776,
                "flops": 0.0
            },
            "args": [
                1,
                -100,
                0.0
            ],
            "runtime": {
                "duration": 776,
                "start": 502979,
                "end": 503755
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 172, in train_and_test\n    loss = loss_model(output, target)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 1150, in forward\n    return F.cross_entropy(input, target, weight=self.weight,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 2846, in cross_entropy\n    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n"
            ]
        },
        {
            "name": "op-21",
            "optype": "aten::ones_like",
            "params": {},
            "inputs": [
                "t-38"
            ],
            "outputs": [
                "t-39"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 242,
                "flops": 0.0
            },
            "args": [
                6,
                0,
                false,
                1
            ],
            "runtime": {
                "duration": 242,
                "start": 504205,
                "end": 504447
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    loss.backward()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 150, in backward\n    grad_tensors_ = _make_grads(tensors, grad_tensors_)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 52, in _make_grads\n    new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/NllLossBackward0/op-22",
            "optype": "aten::nll_loss_backward",
            "params": {},
            "inputs": [
                "t-39",
                "t-40",
                "t-37",
                "t-41",
                "t-42"
            ],
            "outputs": [
                "t-43"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 95,
                "flops": 0.0
            },
            "args": [
                1,
                -100
            ],
            "runtime": {
                "duration": 95,
                "start": 505253,
                "end": 505348
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-23",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-43"
            ],
            "outputs": [
                "t-44"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 70,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 70,
                "start": 505492,
                "end": 505562
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-24",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-44"
            ],
            "outputs": [
                "t-45"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 505597,
                "end": 505653
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-25",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-45"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 88,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 88,
                "start": 505702,
                "end": 505790
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/LogSoftmaxBackward0/op-26",
            "optype": "aten::_log_softmax_backward_data",
            "params": {},
            "inputs": [
                "t-43",
                "t-44",
                "t-36"
            ],
            "outputs": [
                "t-46"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 17,
                "start": 505949,
                "end": 505966
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-27",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-46"
            ],
            "outputs": [
                "t-47"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 506124,
                "end": 506168
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-28",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-47"
            ],
            "outputs": [
                "t-48"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 506191,
                "end": 506236
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-29",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-48"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 241,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 241,
                "start": 506258,
                "end": 506499
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-30",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-46",
                "t-49"
            ],
            "outputs": [
                "t-50"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 76,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 76,
                "start": 506604,
                "end": 506680
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-31",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-51"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 506711,
                "end": 506747
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-32",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-51"
            ],
            "outputs": [
                "t-52"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 506768,
                "end": 506815
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-33",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-52"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 506837,
                "end": 506876
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-34",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-53"
            ],
            "outputs": [
                "t-54"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 506956,
                "end": 507010
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-35",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    10
                ],
                "mat2_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-50",
                "t-54"
            ],
            "outputs": [
                "t-55"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 507051,
                "end": 507071
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-36",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-56"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 507096,
                "end": 507149
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-37",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    10,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-56",
                "t-32"
            ],
            "outputs": [
                "t-57"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 507174,
                "end": 507189
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-38",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-57"
            ],
            "outputs": [
                "t-58"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 507216,
                "end": 507263
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-39",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-59"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 507294,
                "end": 507313
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-40",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-59"
            ],
            "outputs": [
                "t-60"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ]
            ],
            "runtime": {
                "duration": 5,
                "start": 507344,
                "end": 507349
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-41",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-60"
            ],
            "outputs": [
                "t-61"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 507377,
                "end": 507413
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-42",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-61"
            ],
            "outputs": [
                "t-62"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 507440,
                "end": 507486
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-43",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-62"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 507508,
                "end": 507552
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-44",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-55"
            ],
            "outputs": [
                "t-63"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 507577,
                "end": 507612
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-45",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-63"
            ],
            "outputs": [
                "t-64"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 507633,
                "end": 507685
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-46",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-64"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 35,
                "start": 507709,
                "end": 507744
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-47",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-65"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 507767,
                "end": 507812
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-48",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-65"
            ],
            "outputs": [
                "t-66"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 507834,
                "end": 507873
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-49",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-66"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 507899,
                "end": 507936
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-50",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-67",
                "t-60"
            ],
            "outputs": [
                "t-68"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 16,
                "start": 508027,
                "end": 508043
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-51",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-68",
                "t-65",
                "t-69"
            ],
            "outputs": [
                "t-70"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 10.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 508093,
                "end": 508108
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-52",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-71"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 508180,
                "end": 508233
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-53",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-71"
            ],
            "outputs": [
                "t-72"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 508262,
                "end": 508299
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-54",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-72"
            ],
            "outputs": [
                "t-73"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 508321,
                "end": 508365
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-55",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-73"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 508387,
                "end": 508426
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-56",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-74",
                "t-71"
            ],
            "outputs": [
                "t-75"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 508508,
                "end": 508522
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-57",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-75",
                "t-72",
                "t-76"
            ],
            "outputs": [
                "t-77"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 5120.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 508562,
                "end": 508576
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-58",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-55",
                "t-78"
            ],
            "outputs": [
                "t-79"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 69,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 69,
                "start": 508654,
                "end": 508723
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-59",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-80"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 34,
                "start": 508753,
                "end": 508787
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-60",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-80"
            ],
            "outputs": [
                "t-81"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 508809,
                "end": 508862
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-61",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-81"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 508886,
                "end": 508924
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-62",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-82"
            ],
            "outputs": [
                "t-83"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 509002,
                "end": 509057
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-63",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-79",
                "t-83"
            ],
            "outputs": [
                "t-84"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 509084,
                "end": 509103
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-64",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-85"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 509128,
                "end": 509179
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-65",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-85",
                "t-28"
            ],
            "outputs": [
                "t-86"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 509204,
                "end": 509222
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-66",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-86"
            ],
            "outputs": [
                "t-87"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 509245,
                "end": 509298
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-67",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-88"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 509322,
                "end": 509341
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-68",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-88"
            ],
            "outputs": [
                "t-89"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 509370,
                "end": 509374
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-69",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-89"
            ],
            "outputs": [
                "t-90"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 509404,
                "end": 509439
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-70",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-90"
            ],
            "outputs": [
                "t-91"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 509460,
                "end": 509504
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-71",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-91"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 509526,
                "end": 509566
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-72",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-84"
            ],
            "outputs": [
                "t-92"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 509589,
                "end": 509639
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-73",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-92"
            ],
            "outputs": [
                "t-93"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 509662,
                "end": 509709
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-74",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-93"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 509737,
                "end": 509774
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-75",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-94"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 509797,
                "end": 509839
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-76",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-94"
            ],
            "outputs": [
                "t-95"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 509860,
                "end": 509905
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-77",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-95"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 509928,
                "end": 509968
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-78",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-96",
                "t-89"
            ],
            "outputs": [
                "t-97"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 510053,
                "end": 510067
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-79",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-97",
                "t-94",
                "t-98"
            ],
            "outputs": [
                "t-99"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 510111,
                "end": 510125
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-80",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-100"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 510197,
                "end": 510249
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-81",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-100"
            ],
            "outputs": [
                "t-101"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 510272,
                "end": 510314
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-82",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-101"
            ],
            "outputs": [
                "t-102"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 510337,
                "end": 510388
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-83",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-102"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 510411,
                "end": 510457
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-84",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-103",
                "t-100"
            ],
            "outputs": [
                "t-104"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 510534,
                "end": 510548
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-85",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-104",
                "t-101",
                "t-105"
            ],
            "outputs": [
                "t-106"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 510592,
                "end": 510605
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-86",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 510676,
                "end": 510721
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-87",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-84",
                "t-108"
            ],
            "outputs": [
                "t-109"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 75,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 75,
                "start": 510809,
                "end": 510884
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-88",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-110"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 510914,
                "end": 510950
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-89",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-110"
            ],
            "outputs": [
                "t-111"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 510971,
                "end": 511027
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-90",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-111"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 511051,
                "end": 511091
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-91",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-112"
            ],
            "outputs": [
                "t-113"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 511172,
                "end": 511225
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-92",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-109",
                "t-113"
            ],
            "outputs": [
                "t-114"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 511252,
                "end": 511271
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-93",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-115"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 511296,
                "end": 511347
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-94",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-115",
                "t-24"
            ],
            "outputs": [
                "t-116"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 511372,
                "end": 511389
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-95",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-116"
            ],
            "outputs": [
                "t-117"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 511418,
                "end": 511467
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-96",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-118"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 511493,
                "end": 511513
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-97",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-118"
            ],
            "outputs": [
                "t-119"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 511538,
                "end": 511542
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-98",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-119"
            ],
            "outputs": [
                "t-120"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 511574,
                "end": 511616
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-99",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-120"
            ],
            "outputs": [
                "t-121"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 511638,
                "end": 511678
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-100",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-121"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 511700,
                "end": 511744
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-101",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-114"
            ],
            "outputs": [
                "t-122"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 34,
                "start": 511769,
                "end": 511803
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-102",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-122"
            ],
            "outputs": [
                "t-123"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 511828,
                "end": 511879
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-103",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-123"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 35,
                "start": 511903,
                "end": 511938
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-104",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-124"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 511962,
                "end": 512003
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-105",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-124"
            ],
            "outputs": [
                "t-125"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 512025,
                "end": 512069
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-106",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-125"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 36,
                "start": 512096,
                "end": 512132
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-107",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-126",
                "t-119"
            ],
            "outputs": [
                "t-127"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 512213,
                "end": 512227
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-108",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-127",
                "t-124",
                "t-128"
            ],
            "outputs": [
                "t-129"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 512270,
                "end": 512284
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-109",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-130"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 512359,
                "end": 512414
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-110",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-130"
            ],
            "outputs": [
                "t-131"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 512442,
                "end": 512478
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-111",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-131"
            ],
            "outputs": [
                "t-132"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 512498,
                "end": 512549
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-112",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-132"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 512572,
                "end": 512610
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-113",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-133",
                "t-130"
            ],
            "outputs": [
                "t-134"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 512691,
                "end": 512704
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-114",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-134",
                "t-131",
                "t-135"
            ],
            "outputs": [
                "t-136"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 512742,
                "end": 512756
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-115",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-114",
                "t-137"
            ],
            "outputs": [
                "t-138"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 67,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 67,
                "start": 512832,
                "end": 512899
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-116",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-139"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 34,
                "start": 512932,
                "end": 512966
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-117",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-139"
            ],
            "outputs": [
                "t-140"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 512986,
                "end": 513040
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-118",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-140"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 513066,
                "end": 513106
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-119",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-141"
            ],
            "outputs": [
                "t-142"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 513182,
                "end": 513231
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-120",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-138",
                "t-142"
            ],
            "outputs": [
                "t-143"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 513263,
                "end": 513282
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-121",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-144"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 513309,
                "end": 513360
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-122",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-144",
                "t-20"
            ],
            "outputs": [
                "t-145"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 513385,
                "end": 513402
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-123",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-145"
            ],
            "outputs": [
                "t-146"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 513424,
                "end": 513473
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-124",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-147"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 18,
                "start": 513498,
                "end": 513516
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-125",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-147"
            ],
            "outputs": [
                "t-148"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 8,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 8,
                "start": 513541,
                "end": 513549
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-126",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-148"
            ],
            "outputs": [
                "t-149"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 513579,
                "end": 513614
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-127",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-149"
            ],
            "outputs": [
                "t-150"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 513643,
                "end": 513688
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-128",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-150"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 513711,
                "end": 513750
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-129",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-143"
            ],
            "outputs": [
                "t-151"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 513778,
                "end": 513818
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-130",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-151"
            ],
            "outputs": [
                "t-152"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 513839,
                "end": 513885
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-131",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-152"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 36,
                "start": 513913,
                "end": 513949
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-132",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-153"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 513973,
                "end": 514008
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-133",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-153"
            ],
            "outputs": [
                "t-154"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 514035,
                "end": 514081
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-134",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-154"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 514103,
                "end": 514142
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-135",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-155",
                "t-148"
            ],
            "outputs": [
                "t-156"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 514223,
                "end": 514237
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-136",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-156",
                "t-153",
                "t-157"
            ],
            "outputs": [
                "t-158"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 514282,
                "end": 514296
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-137",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-159"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 514369,
                "end": 514421
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-138",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-159"
            ],
            "outputs": [
                "t-160"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 514444,
                "end": 514484
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-139",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-160"
            ],
            "outputs": [
                "t-161"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 514509,
                "end": 514557
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-140",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-161"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 514580,
                "end": 514623
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-141",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-162",
                "t-159"
            ],
            "outputs": [
                "t-163"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 514703,
                "end": 514717
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-142",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-163",
                "t-160",
                "t-164"
            ],
            "outputs": [
                "t-165"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 514760,
                "end": 514774
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-143",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-143",
                "t-166"
            ],
            "outputs": [
                "t-167"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 69,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 69,
                "start": 514848,
                "end": 514917
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-144",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-168"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 514945,
                "end": 514983
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-145",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-168"
            ],
            "outputs": [
                "t-169"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 515005,
                "end": 515052
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-146",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-169"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 515075,
                "end": 515119
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-147",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-170"
            ],
            "outputs": [
                "t-171"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 515191,
                "end": 515248
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-148",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-167",
                "t-171"
            ],
            "outputs": [
                "t-172"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 515275,
                "end": 515295
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-149",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-173"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 515323,
                "end": 515370
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-150",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-173",
                "t-16"
            ],
            "outputs": [
                "t-174"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 515400,
                "end": 515417
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-151",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-174"
            ],
            "outputs": [
                "t-175"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 515440,
                "end": 515490
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-152",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-176"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 18,
                "start": 515515,
                "end": 515533
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-153",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-176"
            ],
            "outputs": [
                "t-177"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 515558,
                "end": 515562
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-154",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-177"
            ],
            "outputs": [
                "t-178"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 515590,
                "end": 515629
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-155",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-178"
            ],
            "outputs": [
                "t-179"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 515651,
                "end": 515690
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-156",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-179"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 515711,
                "end": 515755
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-157",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-172"
            ],
            "outputs": [
                "t-180"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 34,
                "start": 515780,
                "end": 515814
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-158",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-180"
            ],
            "outputs": [
                "t-181"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 515835,
                "end": 515886
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-159",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-181"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 515909,
                "end": 515948
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-160",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-182"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 515974,
                "end": 516010
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-161",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-182"
            ],
            "outputs": [
                "t-183"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 516031,
                "end": 516081
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-162",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-183"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 35,
                "start": 516104,
                "end": 516139
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-163",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-184",
                "t-177"
            ],
            "outputs": [
                "t-185"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 516224,
                "end": 516239
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-164",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-185",
                "t-182",
                "t-186"
            ],
            "outputs": [
                "t-187"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 516277,
                "end": 516290
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-165",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-188"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 516366,
                "end": 516417
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-166",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-188"
            ],
            "outputs": [
                "t-189"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 516441,
                "end": 516476
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-167",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-189"
            ],
            "outputs": [
                "t-190"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 516497,
                "end": 516547
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-168",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-190"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 516570,
                "end": 516607
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-169",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-191",
                "t-188"
            ],
            "outputs": [
                "t-192"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 516692,
                "end": 516706
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-170",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-192",
                "t-189",
                "t-193"
            ],
            "outputs": [
                "t-194"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 516744,
                "end": 516757
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-171",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-172",
                "t-195"
            ],
            "outputs": [
                "t-196"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 67,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 67,
                "start": 516836,
                "end": 516903
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-172",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-197"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 34,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 34,
                "start": 516932,
                "end": 516966
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-173",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-197"
            ],
            "outputs": [
                "t-198"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 150,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 150,
                "start": 516987,
                "end": 517137
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-174",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-198"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 517168,
                "end": 517210
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-175",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-199"
            ],
            "outputs": [
                "t-200"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 517294,
                "end": 517347
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-176",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-196",
                "t-200"
            ],
            "outputs": [
                "t-201"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 21,
                "start": 517374,
                "end": 517395
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-177",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-202"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 517419,
                "end": 517469
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-178",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-202",
                "t-12"
            ],
            "outputs": [
                "t-203"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 517493,
                "end": 517510
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-179",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-203"
            ],
            "outputs": [
                "t-204"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 517539,
                "end": 517589
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-180",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-205"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 30,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 30,
                "start": 517613,
                "end": 517643
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-181",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-205"
            ],
            "outputs": [
                "t-206"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 517675,
                "end": 517679
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-182",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-206"
            ],
            "outputs": [
                "t-207"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 517709,
                "end": 517746
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-183",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-207"
            ],
            "outputs": [
                "t-208"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 517767,
                "end": 517812
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-184",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-208"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 517833,
                "end": 517873
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-185",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-201"
            ],
            "outputs": [
                "t-209"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 517897,
                "end": 517937
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-186",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-209"
            ],
            "outputs": [
                "t-210"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 517958,
                "end": 518009
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-187",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-210"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 36,
                "start": 518032,
                "end": 518068
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-188",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-211"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 518091,
                "end": 518132
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-189",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-211"
            ],
            "outputs": [
                "t-212"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 518153,
                "end": 518205
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-190",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-212"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 518227,
                "end": 518267
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-191",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-213",
                "t-206"
            ],
            "outputs": [
                "t-214"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 518355,
                "end": 518369
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-192",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-214",
                "t-211",
                "t-215"
            ],
            "outputs": [
                "t-216"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 518407,
                "end": 518421
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-193",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-217"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 518495,
                "end": 518547
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-194",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-217"
            ],
            "outputs": [
                "t-218"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 518571,
                "end": 518607
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-195",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-218"
            ],
            "outputs": [
                "t-219"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 518627,
                "end": 518678
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-196",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-219"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 518701,
                "end": 518740
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-197",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-220",
                "t-217"
            ],
            "outputs": [
                "t-221"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 518820,
                "end": 518834
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-198",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-221",
                "t-218",
                "t-222"
            ],
            "outputs": [
                "t-223"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 518871,
                "end": 518885
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-199",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-201",
                "t-224"
            ],
            "outputs": [
                "t-225"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 69,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 69,
                "start": 518961,
                "end": 519030
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-200",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-226"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 519063,
                "end": 519098
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-201",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-226"
            ],
            "outputs": [
                "t-227"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 519119,
                "end": 519170
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-202",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-227"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 519194,
                "end": 519233
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-203",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-228"
            ],
            "outputs": [
                "t-229"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 519309,
                "end": 519360
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-204",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-225",
                "t-229"
            ],
            "outputs": [
                "t-230"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 519386,
                "end": 519406
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-205",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-231"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 519429,
                "end": 519477
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-206",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-231",
                "t-8"
            ],
            "outputs": [
                "t-232"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 519502,
                "end": 519518
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-207",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-232"
            ],
            "outputs": [
                "t-233"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 519540,
                "end": 519589
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-208",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-234"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 18,
                "start": 519613,
                "end": 519631
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-209",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-234"
            ],
            "outputs": [
                "t-235"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 519661,
                "end": 519665
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-210",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-235"
            ],
            "outputs": [
                "t-236"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 519694,
                "end": 519737
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-211",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-236"
            ],
            "outputs": [
                "t-237"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 519760,
                "end": 519803
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-212",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-237"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 519826,
                "end": 519865
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-213",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-230"
            ],
            "outputs": [
                "t-238"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 519889,
                "end": 519929
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-214",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-238"
            ],
            "outputs": [
                "t-239"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 519950,
                "end": 519995
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-215",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-239"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 36,
                "start": 520022,
                "end": 520058
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-216",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-240"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 39,
                "start": 520082,
                "end": 520121
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-217",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-240"
            ],
            "outputs": [
                "t-241"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 520143,
                "end": 520187
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-218",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-241"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 520209,
                "end": 520247
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-219",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-242",
                "t-235"
            ],
            "outputs": [
                "t-243"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 520326,
                "end": 520340
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-220",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-243",
                "t-240",
                "t-244"
            ],
            "outputs": [
                "t-245"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 520386,
                "end": 520400
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-221",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-246"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 520475,
                "end": 520528
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-222",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-246"
            ],
            "outputs": [
                "t-247"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 520550,
                "end": 520592
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-223",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-247"
            ],
            "outputs": [
                "t-248"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 520614,
                "end": 520662
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-224",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-248"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 520684,
                "end": 520727
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-225",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-249",
                "t-246"
            ],
            "outputs": [
                "t-250"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 520801,
                "end": 520815
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-226",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-250",
                "t-247",
                "t-251"
            ],
            "outputs": [
                "t-252"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 520859,
                "end": 520872
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-227",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-230",
                "t-253"
            ],
            "outputs": [
                "t-254"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 69,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 69,
                "start": 520944,
                "end": 521013
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-228",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-255"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 521041,
                "end": 521078
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-229",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-255"
            ],
            "outputs": [
                "t-256"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 521100,
                "end": 521148
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-230",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-256"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 521170,
                "end": 521217
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-231",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-257"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 521288,
                "end": 521340
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-232",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    784
                ]
            },
            "inputs": [
                "t-257",
                "t-4"
            ],
            "outputs": [
                "t-258"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 205520896.0
            },
            "args": [],
            "runtime": {
                "duration": 21,
                "start": 521365,
                "end": 521386
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-233",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-258"
            ],
            "outputs": [
                "t-259"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 521415,
                "end": 521464
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-234",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-260"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 521489,
                "end": 521508
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-235",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-260"
            ],
            "outputs": [
                "t-261"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 3,
                "start": 521533,
                "end": 521536
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-236",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-261"
            ],
            "outputs": [
                "t-262"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 521563,
                "end": 521601
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-237",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-262"
            ],
            "outputs": [
                "t-263"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 521623,
                "end": 521671
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-238",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-263"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 521692,
                "end": 521734
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-239",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-264"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 521759,
                "end": 521799
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-240",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-264"
            ],
            "outputs": [
                "t-265"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 521820,
                "end": 521871
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-241",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-265"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 521894,
                "end": 521934
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-242",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-266",
                "t-261"
            ],
            "outputs": [
                "t-267"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 522019,
                "end": 522033
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-243",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-267",
                "t-264",
                "t-268"
            ],
            "outputs": [
                "t-269"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 522071,
                "end": 522085
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-244",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-270"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 522161,
                "end": 522212
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-245",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-270"
            ],
            "outputs": [
                "t-271"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 522236,
                "end": 522271
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-246",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-271"
            ],
            "outputs": [
                "t-272"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 522292,
                "end": 522344
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-247",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-272"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 522367,
                "end": 522405
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-248",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-273",
                "t-270"
            ],
            "outputs": [
                "t-274"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 522486,
                "end": 522499
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-249",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-274",
                "t-271",
                "t-275"
            ],
            "outputs": [
                "t-276"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 401408.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 522536,
                "end": 522549
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-250",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 522614,
                "end": 522651
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-251",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-278"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 5,
                "start": 522710,
                "end": 522715
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-252",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-279"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    10,
                    512
                ],
                [
                    512,
                    1
                ],
                10
            ],
            "runtime": {
                "duration": 2,
                "start": 522746,
                "end": 522748
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-253",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-280"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                5130
            ],
            "runtime": {
                "duration": 1,
                "start": 522770,
                "end": 522771
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-254",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-281"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                5642
            ],
            "runtime": {
                "duration": 2,
                "start": 522792,
                "end": 522794
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-255",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-68",
                "t-278"
            ],
            "outputs": [
                "t-282"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 20,
                "start": 522822,
                "end": 522842
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-256",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-75",
                "t-279"
            ],
            "outputs": [
                "t-283"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 12,
                "start": 522871,
                "end": 522883
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-257",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-97",
                "t-280"
            ],
            "outputs": [
                "t-284"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 522906,
                "end": 522916
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-258",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-104",
                "t-281"
            ],
            "outputs": [
                "t-285"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 522939,
                "end": 522949
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-259",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-286"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 522980,
                "end": 522982
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-260",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-287"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                512
            ],
            "runtime": {
                "duration": 2,
                "start": 523004,
                "end": 523006
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-261",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-288"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                262656
            ],
            "runtime": {
                "duration": 2,
                "start": 523027,
                "end": 523029
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-262",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-289"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                263168
            ],
            "runtime": {
                "duration": 2,
                "start": 523054,
                "end": 523056
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-263",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-290"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                525312
            ],
            "runtime": {
                "duration": 2,
                "start": 523080,
                "end": 523082
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-264",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-291"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                525824
            ],
            "runtime": {
                "duration": 1,
                "start": 523103,
                "end": 523104
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-265",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-292"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                787968
            ],
            "runtime": {
                "duration": 2,
                "start": 523130,
                "end": 523132
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-266",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-293"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                788480
            ],
            "runtime": {
                "duration": 2,
                "start": 523153,
                "end": 523155
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-267",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-294"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1050624
            ],
            "runtime": {
                "duration": 5,
                "start": 523175,
                "end": 523180
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-268",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-295"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                1051136
            ],
            "runtime": {
                "duration": 2,
                "start": 523201,
                "end": 523203
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-269",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-296"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1313280
            ],
            "runtime": {
                "duration": 2,
                "start": 523223,
                "end": 523225
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-270",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-297"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    784
                ],
                [
                    784,
                    1
                ],
                1313792
            ],
            "runtime": {
                "duration": 2,
                "start": 523252,
                "end": 523254
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-271",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-127",
                "t-286"
            ],
            "outputs": [
                "t-298"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 14,
                "start": 523278,
                "end": 523292
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-272",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-134",
                "t-287"
            ],
            "outputs": [
                "t-299"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 523316,
                "end": 523327
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-273",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-156",
                "t-288"
            ],
            "outputs": [
                "t-300"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 523350,
                "end": 523360
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-274",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-163",
                "t-289"
            ],
            "outputs": [
                "t-301"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 523383,
                "end": 523392
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-275",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-185",
                "t-290"
            ],
            "outputs": [
                "t-302"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 523421,
                "end": 523431
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-276",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-192",
                "t-291"
            ],
            "outputs": [
                "t-303"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 523456,
                "end": 523466
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-277",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-214",
                "t-292"
            ],
            "outputs": [
                "t-304"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 523489,
                "end": 523498
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-278",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-221",
                "t-293"
            ],
            "outputs": [
                "t-305"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 523525,
                "end": 523535
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-279",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-243",
                "t-294"
            ],
            "outputs": [
                "t-306"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 523558,
                "end": 523567
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-280",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-250",
                "t-295"
            ],
            "outputs": [
                "t-307"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 523590,
                "end": 523599
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-281",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-267",
                "t-296"
            ],
            "outputs": [
                "t-308"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 523627,
                "end": 523636
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-282",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-274",
                "t-297"
            ],
            "outputs": [
                "t-309"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 523660,
                "end": 523669
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-283",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-310"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 138,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 138,
                "start": 524014,
                "end": 524152
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-284",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-311"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 3,
                "start": 524273,
                "end": 524276
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-285",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-309",
                "t-5"
            ],
            "outputs": [
                "t-312"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 401408.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 35,
                "start": 524752,
                "end": 524787
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-286",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-313",
                "t-314"
            ],
            "outputs": [
                "t-315"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 524899,
                "end": 524918
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-287",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-315",
                "t-312"
            ],
            "outputs": [
                "t-316"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 13,
                "start": 525005,
                "end": 525018
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-288",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-317",
                "t-314"
            ],
            "outputs": [
                "t-318"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 525105,
                "end": 525117
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-289",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-318",
                "t-312",
                "t-312"
            ],
            "outputs": [
                "t-319"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 13,
                "start": 525214,
                "end": 525227
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-290",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-319"
            ],
            "outputs": [
                "t-320"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 525311,
                "end": 525328
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-291",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-320",
                "t-321"
            ],
            "outputs": [
                "t-322"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 525416,
                "end": 525433
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-292",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-322",
                "t-320"
            ],
            "outputs": [
                "t-323"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 525522,
                "end": 525535
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-293",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-5",
                "t-316",
                "t-323"
            ],
            "outputs": [
                "t-324"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 17,
                "start": 525760,
                "end": 525777
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-294",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-308",
                "t-6"
            ],
            "outputs": [
                "t-325"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 20,
                "start": 526027,
                "end": 526047
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-295",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-326",
                "t-327"
            ],
            "outputs": [
                "t-328"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 526394,
                "end": 526409
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-296",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-328",
                "t-325"
            ],
            "outputs": [
                "t-329"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 12,
                "start": 526772,
                "end": 526784
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-297",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-330",
                "t-327"
            ],
            "outputs": [
                "t-331"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 526901,
                "end": 526914
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-298",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-331",
                "t-325",
                "t-325"
            ],
            "outputs": [
                "t-332"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 15,
                "start": 527029,
                "end": 527044
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-299",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-332"
            ],
            "outputs": [
                "t-333"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 527313,
                "end": 527332
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-300",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-333",
                "t-334"
            ],
            "outputs": [
                "t-335"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 527424,
                "end": 527440
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-301",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-335",
                "t-333"
            ],
            "outputs": [
                "t-336"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 527531,
                "end": 527545
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-302",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-6",
                "t-329",
                "t-336"
            ],
            "outputs": [
                "t-337"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 14,
                "start": 527628,
                "end": 527642
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-303",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-307",
                "t-9"
            ],
            "outputs": [
                "t-338"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 527735,
                "end": 527751
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-304",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-339",
                "t-333"
            ],
            "outputs": [
                "t-340"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 527831,
                "end": 527844
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-305",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-340",
                "t-338"
            ],
            "outputs": [
                "t-341"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 527922,
                "end": 527932
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-306",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-342",
                "t-333"
            ],
            "outputs": [
                "t-343"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 528012,
                "end": 528023
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-307",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-343",
                "t-338",
                "t-338"
            ],
            "outputs": [
                "t-344"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 528104,
                "end": 528115
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-308",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-344"
            ],
            "outputs": [
                "t-345"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 528192,
                "end": 528207
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-309",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-345",
                "t-346"
            ],
            "outputs": [
                "t-347"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 528289,
                "end": 528304
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-310",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-347",
                "t-345"
            ],
            "outputs": [
                "t-348"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 528394,
                "end": 528406
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-311",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-9",
                "t-341",
                "t-348"
            ],
            "outputs": [
                "t-349"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 528489,
                "end": 528501
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-312",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-306",
                "t-10"
            ],
            "outputs": [
                "t-350"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 528592,
                "end": 528608
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-313",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-351",
                "t-345"
            ],
            "outputs": [
                "t-352"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 528689,
                "end": 528701
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-314",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-352",
                "t-350"
            ],
            "outputs": [
                "t-353"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 528778,
                "end": 528788
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-315",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-354",
                "t-345"
            ],
            "outputs": [
                "t-355"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 528863,
                "end": 528873
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-316",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-355",
                "t-350",
                "t-350"
            ],
            "outputs": [
                "t-356"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 528952,
                "end": 528963
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-317",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-356"
            ],
            "outputs": [
                "t-357"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 529036,
                "end": 529049
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-318",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-357",
                "t-358"
            ],
            "outputs": [
                "t-359"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 529125,
                "end": 529140
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-319",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-359",
                "t-357"
            ],
            "outputs": [
                "t-360"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 529221,
                "end": 529232
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-320",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-10",
                "t-353",
                "t-360"
            ],
            "outputs": [
                "t-361"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 529312,
                "end": 529324
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-321",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-305",
                "t-13"
            ],
            "outputs": [
                "t-362"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 529411,
                "end": 529426
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-322",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-363",
                "t-357"
            ],
            "outputs": [
                "t-364"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 529504,
                "end": 529516
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-323",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-364",
                "t-362"
            ],
            "outputs": [
                "t-365"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 529598,
                "end": 529608
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-324",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-366",
                "t-357"
            ],
            "outputs": [
                "t-367"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 529696,
                "end": 529708
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-325",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-367",
                "t-362",
                "t-362"
            ],
            "outputs": [
                "t-368"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 529794,
                "end": 529806
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-326",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-368"
            ],
            "outputs": [
                "t-369"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 529879,
                "end": 529893
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-327",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-369",
                "t-370"
            ],
            "outputs": [
                "t-371"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 529976,
                "end": 529991
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-328",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-371",
                "t-369"
            ],
            "outputs": [
                "t-372"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 530075,
                "end": 530088
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-329",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-13",
                "t-365",
                "t-372"
            ],
            "outputs": [
                "t-373"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 530169,
                "end": 530181
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-330",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-304",
                "t-14"
            ],
            "outputs": [
                "t-374"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 530268,
                "end": 530284
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-331",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-375",
                "t-369"
            ],
            "outputs": [
                "t-376"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 530362,
                "end": 530374
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-332",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-376",
                "t-374"
            ],
            "outputs": [
                "t-377"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 530451,
                "end": 530461
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-333",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-378",
                "t-369"
            ],
            "outputs": [
                "t-379"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 530537,
                "end": 530547
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-334",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-379",
                "t-374",
                "t-374"
            ],
            "outputs": [
                "t-380"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 530624,
                "end": 530635
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-335",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-380"
            ],
            "outputs": [
                "t-381"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 530710,
                "end": 530724
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-336",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-381",
                "t-382"
            ],
            "outputs": [
                "t-383"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 530805,
                "end": 530820
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-337",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-383",
                "t-381"
            ],
            "outputs": [
                "t-384"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 530901,
                "end": 530913
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-338",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-14",
                "t-377",
                "t-384"
            ],
            "outputs": [
                "t-385"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 530992,
                "end": 531004
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-339",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-303",
                "t-17"
            ],
            "outputs": [
                "t-386"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 14,
                "start": 531091,
                "end": 531105
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-340",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-387",
                "t-381"
            ],
            "outputs": [
                "t-388"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 531189,
                "end": 531201
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-341",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-388",
                "t-386"
            ],
            "outputs": [
                "t-389"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 531286,
                "end": 531296
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-342",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-390",
                "t-381"
            ],
            "outputs": [
                "t-391"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 531372,
                "end": 531383
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-343",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-391",
                "t-386",
                "t-386"
            ],
            "outputs": [
                "t-392"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 531464,
                "end": 531475
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-344",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-392"
            ],
            "outputs": [
                "t-393"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 531547,
                "end": 531561
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-345",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-393",
                "t-394"
            ],
            "outputs": [
                "t-395"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 531642,
                "end": 531657
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-346",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-395",
                "t-393"
            ],
            "outputs": [
                "t-396"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 531747,
                "end": 531759
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-347",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-17",
                "t-389",
                "t-396"
            ],
            "outputs": [
                "t-397"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 11,
                "start": 531842,
                "end": 531853
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-348",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-302",
                "t-18"
            ],
            "outputs": [
                "t-398"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 531948,
                "end": 531964
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-349",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-399",
                "t-393"
            ],
            "outputs": [
                "t-400"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 532048,
                "end": 532060
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-350",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-400",
                "t-398"
            ],
            "outputs": [
                "t-401"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 532140,
                "end": 532150
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-351",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-402",
                "t-393"
            ],
            "outputs": [
                "t-403"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 532230,
                "end": 532241
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-352",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-403",
                "t-398",
                "t-398"
            ],
            "outputs": [
                "t-404"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 532318,
                "end": 532329
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-353",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-404"
            ],
            "outputs": [
                "t-405"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 532404,
                "end": 532418
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-354",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-405",
                "t-406"
            ],
            "outputs": [
                "t-407"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 532499,
                "end": 532514
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-355",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-407",
                "t-405"
            ],
            "outputs": [
                "t-408"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 532595,
                "end": 532607
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-356",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-18",
                "t-401",
                "t-408"
            ],
            "outputs": [
                "t-409"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 532691,
                "end": 532703
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-357",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-301",
                "t-21"
            ],
            "outputs": [
                "t-410"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 532792,
                "end": 532807
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-358",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-411",
                "t-405"
            ],
            "outputs": [
                "t-412"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 532891,
                "end": 532904
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-359",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-412",
                "t-410"
            ],
            "outputs": [
                "t-413"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 532981,
                "end": 532991
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-360",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-414",
                "t-405"
            ],
            "outputs": [
                "t-415"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 533071,
                "end": 533082
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-361",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-415",
                "t-410",
                "t-410"
            ],
            "outputs": [
                "t-416"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 533158,
                "end": 533169
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-362",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-416"
            ],
            "outputs": [
                "t-417"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 533246,
                "end": 533261
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-363",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-417",
                "t-418"
            ],
            "outputs": [
                "t-419"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 533341,
                "end": 533356
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-364",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-419",
                "t-417"
            ],
            "outputs": [
                "t-420"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 533437,
                "end": 533449
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-365",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-21",
                "t-413",
                "t-420"
            ],
            "outputs": [
                "t-421"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 533537,
                "end": 533549
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-366",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-300",
                "t-22"
            ],
            "outputs": [
                "t-422"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 18,
                "start": 533649,
                "end": 533667
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-367",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-423",
                "t-417"
            ],
            "outputs": [
                "t-424"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 533749,
                "end": 533762
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-368",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-424",
                "t-422"
            ],
            "outputs": [
                "t-425"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 533839,
                "end": 533849
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-369",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-426",
                "t-417"
            ],
            "outputs": [
                "t-427"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 533933,
                "end": 533944
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-370",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-427",
                "t-422",
                "t-422"
            ],
            "outputs": [
                "t-428"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 534021,
                "end": 534033
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-371",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-428"
            ],
            "outputs": [
                "t-429"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 534119,
                "end": 534134
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-372",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-429",
                "t-430"
            ],
            "outputs": [
                "t-431"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 534212,
                "end": 534231
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-373",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-431",
                "t-429"
            ],
            "outputs": [
                "t-432"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 534312,
                "end": 534324
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-374",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-22",
                "t-425",
                "t-432"
            ],
            "outputs": [
                "t-433"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 534407,
                "end": 534419
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-375",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-299",
                "t-25"
            ],
            "outputs": [
                "t-434"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 534512,
                "end": 534527
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-376",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-435",
                "t-429"
            ],
            "outputs": [
                "t-436"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 534610,
                "end": 534622
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-377",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-436",
                "t-434"
            ],
            "outputs": [
                "t-437"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 534699,
                "end": 534709
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-378",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-438",
                "t-429"
            ],
            "outputs": [
                "t-439"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 534791,
                "end": 534802
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-379",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-439",
                "t-434",
                "t-434"
            ],
            "outputs": [
                "t-440"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 534878,
                "end": 534890
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-380",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-440"
            ],
            "outputs": [
                "t-441"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 534965,
                "end": 534980
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-381",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-441",
                "t-442"
            ],
            "outputs": [
                "t-443"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 535062,
                "end": 535077
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-382",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-443",
                "t-441"
            ],
            "outputs": [
                "t-444"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 535162,
                "end": 535174
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-383",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-25",
                "t-437",
                "t-444"
            ],
            "outputs": [
                "t-445"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 11,
                "start": 535255,
                "end": 535266
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-384",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-298",
                "t-26"
            ],
            "outputs": [
                "t-446"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 535361,
                "end": 535377
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-385",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-447",
                "t-441"
            ],
            "outputs": [
                "t-448"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 535460,
                "end": 535473
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-386",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-448",
                "t-446"
            ],
            "outputs": [
                "t-449"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 535550,
                "end": 535560
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-387",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-450",
                "t-441"
            ],
            "outputs": [
                "t-451"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 535642,
                "end": 535652
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-388",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-451",
                "t-446",
                "t-446"
            ],
            "outputs": [
                "t-452"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 535730,
                "end": 535741
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-389",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-452"
            ],
            "outputs": [
                "t-453"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 535816,
                "end": 535829
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-390",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-453",
                "t-454"
            ],
            "outputs": [
                "t-455"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 535907,
                "end": 535924
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-391",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-455",
                "t-453"
            ],
            "outputs": [
                "t-456"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 536006,
                "end": 536017
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-392",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-26",
                "t-449",
                "t-456"
            ],
            "outputs": [
                "t-457"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 536100,
                "end": 536112
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-393",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-285",
                "t-29"
            ],
            "outputs": [
                "t-458"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 536203,
                "end": 536219
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-394",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-459",
                "t-453"
            ],
            "outputs": [
                "t-460"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 536303,
                "end": 536315
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-395",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-460",
                "t-458"
            ],
            "outputs": [
                "t-461"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 536392,
                "end": 536402
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-396",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-462",
                "t-453"
            ],
            "outputs": [
                "t-463"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 536485,
                "end": 536495
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-397",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-463",
                "t-458",
                "t-458"
            ],
            "outputs": [
                "t-464"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 536573,
                "end": 536585
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-398",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-464"
            ],
            "outputs": [
                "t-465"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 536660,
                "end": 536673
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-399",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-465",
                "t-466"
            ],
            "outputs": [
                "t-467"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 536752,
                "end": 536766
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-400",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-467",
                "t-465"
            ],
            "outputs": [
                "t-468"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 536853,
                "end": 536866
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-401",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-29",
                "t-461",
                "t-468"
            ],
            "outputs": [
                "t-469"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 11,
                "start": 536947,
                "end": 536958
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-402",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-284",
                "t-30"
            ],
            "outputs": [
                "t-470"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 537049,
                "end": 537064
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-403",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-471",
                "t-465"
            ],
            "outputs": [
                "t-472"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 537154,
                "end": 537167
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-404",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-472",
                "t-470"
            ],
            "outputs": [
                "t-473"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 537247,
                "end": 537258
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-405",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-474",
                "t-465"
            ],
            "outputs": [
                "t-475"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 537337,
                "end": 537347
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-406",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-475",
                "t-470",
                "t-470"
            ],
            "outputs": [
                "t-476"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 537425,
                "end": 537436
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-407",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-476"
            ],
            "outputs": [
                "t-477"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 537510,
                "end": 537524
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-408",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-477",
                "t-478"
            ],
            "outputs": [
                "t-479"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 537602,
                "end": 537616
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-409",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-479",
                "t-477"
            ],
            "outputs": [
                "t-480"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 537709,
                "end": 537722
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-410",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-30",
                "t-473",
                "t-480"
            ],
            "outputs": [
                "t-481"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 537802,
                "end": 537814
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-411",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-283",
                "t-33"
            ],
            "outputs": [
                "t-482"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 5120.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 537905,
                "end": 537921
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-412",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-483",
                "t-477"
            ],
            "outputs": [
                "t-484"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 538005,
                "end": 538018
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-413",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-484",
                "t-482"
            ],
            "outputs": [
                "t-485"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 538095,
                "end": 538105
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-414",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-486",
                "t-477"
            ],
            "outputs": [
                "t-487"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 538187,
                "end": 538198
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-415",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-487",
                "t-482",
                "t-482"
            ],
            "outputs": [
                "t-488"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 538280,
                "end": 538292
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-416",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-488"
            ],
            "outputs": [
                "t-489"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 538364,
                "end": 538379
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-417",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-489",
                "t-490"
            ],
            "outputs": [
                "t-491"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 538460,
                "end": 538475
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-418",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-491",
                "t-489"
            ],
            "outputs": [
                "t-492"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 538558,
                "end": 538570
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-419",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-33",
                "t-485",
                "t-492"
            ],
            "outputs": [
                "t-493"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 538653,
                "end": 538665
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-420",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-282",
                "t-34"
            ],
            "outputs": [
                "t-494"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 10.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 538752,
                "end": 538768
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-421",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-495",
                "t-489"
            ],
            "outputs": [
                "t-496"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 538853,
                "end": 538866
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-422",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-496",
                "t-494"
            ],
            "outputs": [
                "t-497"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 538942,
                "end": 538952
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-423",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-498",
                "t-489"
            ],
            "outputs": [
                "t-499"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 539031,
                "end": 539041
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-424",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-499",
                "t-494",
                "t-494"
            ],
            "outputs": [
                "t-500"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 539119,
                "end": 539130
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-425",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-500"
            ],
            "outputs": [
                "t-501"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 539212,
                "end": 539225
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-426",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-501",
                "t-502"
            ],
            "outputs": [
                "t-503"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 539309,
                "end": 539324
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-427",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-503",
                "t-501"
            ],
            "outputs": [
                "t-504"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 539409,
                "end": 539421
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-428",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-34",
                "t-497",
                "t-504"
            ],
            "outputs": [
                "t-505"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 539503,
                "end": 539515
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 267, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 174, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        }
    ],
    "tensors": {
        "t-1": {
            "name": "t-1",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-2": {
            "name": "t-2",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-4": {
            "name": "t-4",
            "dtype": "FP32",
            "shape": [
                256,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-3": {
            "name": "t-3",
            "dtype": "FP32",
            "shape": [
                256,
                1,
                28,
                28
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-7": {
            "name": "t-7",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-5": {
            "name": "t-5",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-6": {
            "name": "t-6",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-8": {
            "name": "t-8",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-11": {
            "name": "t-11",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-9": {
            "name": "t-9",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-10": {
            "name": "t-10",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-12": {
            "name": "t-12",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-15": {
            "name": "t-15",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-13": {
            "name": "t-13",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-14": {
            "name": "t-14",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-16": {
            "name": "t-16",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-19": {
            "name": "t-19",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-17": {
            "name": "t-17",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-18": {
            "name": "t-18",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-20": {
            "name": "t-20",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-23": {
            "name": "t-23",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-21": {
            "name": "t-21",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-22": {
            "name": "t-22",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-24": {
            "name": "t-24",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-27": {
            "name": "t-27",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-25": {
            "name": "t-25",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-26": {
            "name": "t-26",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-28": {
            "name": "t-28",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-31": {
            "name": "t-31",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-29": {
            "name": "t-29",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-30": {
            "name": "t-30",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-32": {
            "name": "t-32",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-35": {
            "name": "t-35",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-33": {
            "name": "t-33",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-34": {
            "name": "t-34",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-36": {
            "name": "t-36",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-38": {
            "name": "t-38",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-37": {
            "name": "t-37",
            "dtype": "INT64",
            "shape": [
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-39": {
            "name": "t-39",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-43": {
            "name": "t-43",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-40": {
            "name": "t-40",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-41": {
            "name": "t-41",
            "dtype": "BIN",
            "shape": [
                0
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-42": {
            "name": "t-42",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-44": {
            "name": "t-44",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-45": {
            "name": "t-45",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-46": {
            "name": "t-46",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-47": {
            "name": "t-47",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-48": {
            "name": "t-48",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-50": {
            "name": "t-50",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-47",
            "allocation": null
        },
        "t-49": {
            "name": "t-49",
            "dtype": "UINT8",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-51": {
            "name": "t-51",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-49",
            "allocation": null
        },
        "t-52": {
            "name": "t-52",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-54": {
            "name": "t-54",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-53": {
            "name": "t-53",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-55": {
            "name": "t-55",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-56": {
            "name": "t-56",
            "dtype": "FP32",
            "shape": [
                10,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-57": {
            "name": "t-57",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-58": {
            "name": "t-58",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-59": {
            "name": "t-59",
            "dtype": "FP32",
            "shape": [
                1,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-60": {
            "name": "t-60",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-61": {
            "name": "t-61",
            "dtype": "BIN",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-62": {
            "name": "t-62",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-63": {
            "name": "t-63",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-64": {
            "name": "t-64",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-62",
            "allocation": null
        },
        "t-65": {
            "name": "t-65",
            "dtype": "BIN",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-66": {
            "name": "t-66",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-64",
            "allocation": null
        },
        "t-68": {
            "name": "t-68",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-67",
            "allocation": null
        },
        "t-67": {
            "name": "t-67",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-70": {
            "name": "t-70",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-69",
            "allocation": null
        },
        "t-69": {
            "name": "t-69",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-71": {
            "name": "t-71",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-72": {
            "name": "t-72",
            "dtype": "BIN",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-73": {
            "name": "t-73",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-75": {
            "name": "t-75",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-74",
            "allocation": null
        },
        "t-74": {
            "name": "t-74",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-77": {
            "name": "t-77",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-76",
            "allocation": null
        },
        "t-76": {
            "name": "t-76",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-79": {
            "name": "t-79",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-78": {
            "name": "t-78",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-80": {
            "name": "t-80",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-78",
            "allocation": null
        },
        "t-81": {
            "name": "t-81",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-83": {
            "name": "t-83",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-82": {
            "name": "t-82",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-84": {
            "name": "t-84",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-85": {
            "name": "t-85",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-86": {
            "name": "t-86",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-87": {
            "name": "t-87",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-88": {
            "name": "t-88",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-89": {
            "name": "t-89",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-90": {
            "name": "t-90",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-91": {
            "name": "t-91",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-92": {
            "name": "t-92",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-93": {
            "name": "t-93",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-91",
            "allocation": null
        },
        "t-94": {
            "name": "t-94",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-95": {
            "name": "t-95",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-93",
            "allocation": null
        },
        "t-97": {
            "name": "t-97",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-96",
            "allocation": null
        },
        "t-96": {
            "name": "t-96",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-99": {
            "name": "t-99",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-98",
            "allocation": null
        },
        "t-98": {
            "name": "t-98",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-100": {
            "name": "t-100",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-101": {
            "name": "t-101",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-87",
            "allocation": null
        },
        "t-102": {
            "name": "t-102",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-104": {
            "name": "t-104",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-103",
            "allocation": null
        },
        "t-103": {
            "name": "t-103",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-106": {
            "name": "t-106",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-105",
            "allocation": null
        },
        "t-105": {
            "name": "t-105",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-107": {
            "name": "t-107",
            "dtype": "FP32",
            "shape": [
                267786
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-109": {
            "name": "t-109",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-108": {
            "name": "t-108",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-110": {
            "name": "t-110",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-108",
            "allocation": null
        },
        "t-111": {
            "name": "t-111",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-113": {
            "name": "t-113",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-112": {
            "name": "t-112",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-114": {
            "name": "t-114",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-115": {
            "name": "t-115",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-116": {
            "name": "t-116",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-86",
            "allocation": null
        },
        "t-117": {
            "name": "t-117",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-118": {
            "name": "t-118",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-119": {
            "name": "t-119",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-120": {
            "name": "t-120",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-121": {
            "name": "t-121",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-122": {
            "name": "t-122",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-123": {
            "name": "t-123",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-121",
            "allocation": null
        },
        "t-124": {
            "name": "t-124",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-125": {
            "name": "t-125",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-123",
            "allocation": null
        },
        "t-127": {
            "name": "t-127",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-126",
            "allocation": null
        },
        "t-126": {
            "name": "t-126",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-129": {
            "name": "t-129",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-128",
            "allocation": null
        },
        "t-128": {
            "name": "t-128",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-130": {
            "name": "t-130",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-131": {
            "name": "t-131",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-117",
            "allocation": null
        },
        "t-132": {
            "name": "t-132",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-134": {
            "name": "t-134",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-133",
            "allocation": null
        },
        "t-133": {
            "name": "t-133",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-136": {
            "name": "t-136",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-135",
            "allocation": null
        },
        "t-135": {
            "name": "t-135",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-138": {
            "name": "t-138",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-137": {
            "name": "t-137",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-139": {
            "name": "t-139",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-137",
            "allocation": null
        },
        "t-140": {
            "name": "t-140",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-142": {
            "name": "t-142",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-141": {
            "name": "t-141",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-143": {
            "name": "t-143",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-144": {
            "name": "t-144",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-145": {
            "name": "t-145",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-116",
            "allocation": null
        },
        "t-146": {
            "name": "t-146",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-131",
            "allocation": null
        },
        "t-147": {
            "name": "t-147",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-148": {
            "name": "t-148",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-149": {
            "name": "t-149",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-150": {
            "name": "t-150",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-151": {
            "name": "t-151",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-152": {
            "name": "t-152",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-150",
            "allocation": null
        },
        "t-153": {
            "name": "t-153",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-154": {
            "name": "t-154",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-152",
            "allocation": null
        },
        "t-156": {
            "name": "t-156",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-155",
            "allocation": null
        },
        "t-155": {
            "name": "t-155",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-158": {
            "name": "t-158",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-157",
            "allocation": null
        },
        "t-157": {
            "name": "t-157",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-159": {
            "name": "t-159",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-160": {
            "name": "t-160",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-146",
            "allocation": null
        },
        "t-161": {
            "name": "t-161",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-163": {
            "name": "t-163",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-162",
            "allocation": null
        },
        "t-162": {
            "name": "t-162",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-165": {
            "name": "t-165",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-164",
            "allocation": null
        },
        "t-164": {
            "name": "t-164",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-167": {
            "name": "t-167",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-166": {
            "name": "t-166",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-168": {
            "name": "t-168",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-166",
            "allocation": null
        },
        "t-169": {
            "name": "t-169",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-171": {
            "name": "t-171",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-170": {
            "name": "t-170",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-172": {
            "name": "t-172",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-173": {
            "name": "t-173",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-174": {
            "name": "t-174",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-145",
            "allocation": null
        },
        "t-175": {
            "name": "t-175",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-160",
            "allocation": null
        },
        "t-176": {
            "name": "t-176",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-177": {
            "name": "t-177",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-178": {
            "name": "t-178",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-179": {
            "name": "t-179",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-180": {
            "name": "t-180",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-181": {
            "name": "t-181",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-179",
            "allocation": null
        },
        "t-182": {
            "name": "t-182",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-183": {
            "name": "t-183",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-181",
            "allocation": null
        },
        "t-185": {
            "name": "t-185",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-184",
            "allocation": null
        },
        "t-184": {
            "name": "t-184",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-187": {
            "name": "t-187",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-186",
            "allocation": null
        },
        "t-186": {
            "name": "t-186",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-188": {
            "name": "t-188",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-189": {
            "name": "t-189",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-175",
            "allocation": null
        },
        "t-190": {
            "name": "t-190",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-192": {
            "name": "t-192",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-191",
            "allocation": null
        },
        "t-191": {
            "name": "t-191",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-194": {
            "name": "t-194",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-193",
            "allocation": null
        },
        "t-193": {
            "name": "t-193",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-196": {
            "name": "t-196",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-195": {
            "name": "t-195",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-197": {
            "name": "t-197",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-172",
            "allocation": null
        },
        "t-198": {
            "name": "t-198",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-200": {
            "name": "t-200",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-199": {
            "name": "t-199",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-201": {
            "name": "t-201",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-202": {
            "name": "t-202",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-203": {
            "name": "t-203",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-189",
            "allocation": null
        },
        "t-204": {
            "name": "t-204",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-182",
            "allocation": null
        },
        "t-205": {
            "name": "t-205",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-206": {
            "name": "t-206",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-207": {
            "name": "t-207",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-208": {
            "name": "t-208",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-209": {
            "name": "t-209",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-210": {
            "name": "t-210",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-208",
            "allocation": null
        },
        "t-211": {
            "name": "t-211",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-212": {
            "name": "t-212",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-210",
            "allocation": null
        },
        "t-214": {
            "name": "t-214",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-213",
            "allocation": null
        },
        "t-213": {
            "name": "t-213",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-216": {
            "name": "t-216",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-215",
            "allocation": null
        },
        "t-215": {
            "name": "t-215",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-217": {
            "name": "t-217",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-218": {
            "name": "t-218",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-204",
            "allocation": null
        },
        "t-219": {
            "name": "t-219",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-221": {
            "name": "t-221",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-220",
            "allocation": null
        },
        "t-220": {
            "name": "t-220",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-223": {
            "name": "t-223",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-222",
            "allocation": null
        },
        "t-222": {
            "name": "t-222",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-225": {
            "name": "t-225",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-224": {
            "name": "t-224",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-226": {
            "name": "t-226",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-201",
            "allocation": null
        },
        "t-227": {
            "name": "t-227",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-229": {
            "name": "t-229",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-228": {
            "name": "t-228",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-230": {
            "name": "t-230",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-231": {
            "name": "t-231",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-232": {
            "name": "t-232",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-218",
            "allocation": null
        },
        "t-233": {
            "name": "t-233",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-211",
            "allocation": null
        },
        "t-234": {
            "name": "t-234",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-235": {
            "name": "t-235",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-236": {
            "name": "t-236",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-237": {
            "name": "t-237",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-238": {
            "name": "t-238",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-239": {
            "name": "t-239",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-237",
            "allocation": null
        },
        "t-240": {
            "name": "t-240",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-241": {
            "name": "t-241",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-239",
            "allocation": null
        },
        "t-243": {
            "name": "t-243",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-242",
            "allocation": null
        },
        "t-242": {
            "name": "t-242",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-245": {
            "name": "t-245",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-244",
            "allocation": null
        },
        "t-244": {
            "name": "t-244",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-246": {
            "name": "t-246",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-247": {
            "name": "t-247",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-233",
            "allocation": null
        },
        "t-248": {
            "name": "t-248",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-250": {
            "name": "t-250",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-249",
            "allocation": null
        },
        "t-249": {
            "name": "t-249",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-252": {
            "name": "t-252",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-251",
            "allocation": null
        },
        "t-251": {
            "name": "t-251",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-254": {
            "name": "t-254",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-253": {
            "name": "t-253",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-255": {
            "name": "t-255",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-230",
            "allocation": null
        },
        "t-256": {
            "name": "t-256",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-257": {
            "name": "t-257",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-258": {
            "name": "t-258",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-259": {
            "name": "t-259",
            "dtype": "FP32",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-260": {
            "name": "t-260",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-261": {
            "name": "t-261",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-262": {
            "name": "t-262",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-263": {
            "name": "t-263",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-264": {
            "name": "t-264",
            "dtype": "BIN",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-265": {
            "name": "t-265",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-263",
            "allocation": null
        },
        "t-267": {
            "name": "t-267",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-266",
            "allocation": null
        },
        "t-266": {
            "name": "t-266",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-269": {
            "name": "t-269",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-268",
            "allocation": null
        },
        "t-268": {
            "name": "t-268",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-270": {
            "name": "t-270",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-271": {
            "name": "t-271",
            "dtype": "BIN",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-272": {
            "name": "t-272",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-274": {
            "name": "t-274",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-273",
            "allocation": null
        },
        "t-273": {
            "name": "t-273",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-276": {
            "name": "t-276",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-275",
            "allocation": null
        },
        "t-275": {
            "name": "t-275",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-277": {
            "name": "t-277",
            "dtype": "FP32",
            "shape": [
                1715200
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-278": {
            "name": "t-278",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-279": {
            "name": "t-279",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-280": {
            "name": "t-280",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-281": {
            "name": "t-281",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-282": {
            "name": "t-282",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-68",
            "allocation": null
        },
        "t-283": {
            "name": "t-283",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-75",
            "allocation": null
        },
        "t-284": {
            "name": "t-284",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-97",
            "allocation": null
        },
        "t-285": {
            "name": "t-285",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-104",
            "allocation": null
        },
        "t-286": {
            "name": "t-286",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-287": {
            "name": "t-287",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-288": {
            "name": "t-288",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-289": {
            "name": "t-289",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-290": {
            "name": "t-290",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-291": {
            "name": "t-291",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-292": {
            "name": "t-292",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-293": {
            "name": "t-293",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-294": {
            "name": "t-294",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-295": {
            "name": "t-295",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-296": {
            "name": "t-296",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-297": {
            "name": "t-297",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-298": {
            "name": "t-298",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-127",
            "allocation": null
        },
        "t-299": {
            "name": "t-299",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-134",
            "allocation": null
        },
        "t-300": {
            "name": "t-300",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-156",
            "allocation": null
        },
        "t-301": {
            "name": "t-301",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-163",
            "allocation": null
        },
        "t-302": {
            "name": "t-302",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-185",
            "allocation": null
        },
        "t-303": {
            "name": "t-303",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-192",
            "allocation": null
        },
        "t-304": {
            "name": "t-304",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-214",
            "allocation": null
        },
        "t-305": {
            "name": "t-305",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-221",
            "allocation": null
        },
        "t-306": {
            "name": "t-306",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-243",
            "allocation": null
        },
        "t-307": {
            "name": "t-307",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-250",
            "allocation": null
        },
        "t-308": {
            "name": "t-308",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-267",
            "allocation": null
        },
        "t-309": {
            "name": "t-309",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-274",
            "allocation": null
        },
        "t-310": {
            "name": "t-310",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-311": {
            "name": "t-311",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-312": {
            "name": "t-312",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-315": {
            "name": "t-315",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-313",
            "allocation": null
        },
        "t-313": {
            "name": "t-313",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-314": {
            "name": "t-314",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-316": {
            "name": "t-316",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-315",
            "allocation": null
        },
        "t-318": {
            "name": "t-318",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-317",
            "allocation": null
        },
        "t-317": {
            "name": "t-317",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-319": {
            "name": "t-319",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-318",
            "allocation": null
        },
        "t-320": {
            "name": "t-320",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-322": {
            "name": "t-322",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-321": {
            "name": "t-321",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-323": {
            "name": "t-323",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-322",
            "allocation": null
        },
        "t-324": {
            "name": "t-324",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-5",
            "allocation": null
        },
        "t-325": {
            "name": "t-325",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-328": {
            "name": "t-328",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-326",
            "allocation": null
        },
        "t-326": {
            "name": "t-326",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-327": {
            "name": "t-327",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-329": {
            "name": "t-329",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-328",
            "allocation": null
        },
        "t-331": {
            "name": "t-331",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-330",
            "allocation": null
        },
        "t-330": {
            "name": "t-330",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-332": {
            "name": "t-332",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-331",
            "allocation": null
        },
        "t-333": {
            "name": "t-333",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-335": {
            "name": "t-335",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-334": {
            "name": "t-334",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-336": {
            "name": "t-336",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-335",
            "allocation": null
        },
        "t-337": {
            "name": "t-337",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-6",
            "allocation": null
        },
        "t-338": {
            "name": "t-338",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-340": {
            "name": "t-340",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-339",
            "allocation": null
        },
        "t-339": {
            "name": "t-339",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-341": {
            "name": "t-341",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-340",
            "allocation": null
        },
        "t-343": {
            "name": "t-343",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-342",
            "allocation": null
        },
        "t-342": {
            "name": "t-342",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-344": {
            "name": "t-344",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-343",
            "allocation": null
        },
        "t-345": {
            "name": "t-345",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-347": {
            "name": "t-347",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-346": {
            "name": "t-346",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-348": {
            "name": "t-348",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-347",
            "allocation": null
        },
        "t-349": {
            "name": "t-349",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-9",
            "allocation": null
        },
        "t-350": {
            "name": "t-350",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-352": {
            "name": "t-352",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-351",
            "allocation": null
        },
        "t-351": {
            "name": "t-351",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-353": {
            "name": "t-353",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-352",
            "allocation": null
        },
        "t-355": {
            "name": "t-355",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-354",
            "allocation": null
        },
        "t-354": {
            "name": "t-354",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-356": {
            "name": "t-356",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-355",
            "allocation": null
        },
        "t-357": {
            "name": "t-357",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-359": {
            "name": "t-359",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-358": {
            "name": "t-358",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-360": {
            "name": "t-360",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-359",
            "allocation": null
        },
        "t-361": {
            "name": "t-361",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-10",
            "allocation": null
        },
        "t-362": {
            "name": "t-362",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-364": {
            "name": "t-364",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-363",
            "allocation": null
        },
        "t-363": {
            "name": "t-363",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-365": {
            "name": "t-365",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-364",
            "allocation": null
        },
        "t-367": {
            "name": "t-367",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-366",
            "allocation": null
        },
        "t-366": {
            "name": "t-366",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-368": {
            "name": "t-368",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-367",
            "allocation": null
        },
        "t-369": {
            "name": "t-369",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-371": {
            "name": "t-371",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-370": {
            "name": "t-370",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-372": {
            "name": "t-372",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-371",
            "allocation": null
        },
        "t-373": {
            "name": "t-373",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-13",
            "allocation": null
        },
        "t-374": {
            "name": "t-374",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-376": {
            "name": "t-376",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-375",
            "allocation": null
        },
        "t-375": {
            "name": "t-375",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-377": {
            "name": "t-377",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-376",
            "allocation": null
        },
        "t-379": {
            "name": "t-379",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-378",
            "allocation": null
        },
        "t-378": {
            "name": "t-378",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-380": {
            "name": "t-380",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-379",
            "allocation": null
        },
        "t-381": {
            "name": "t-381",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-383": {
            "name": "t-383",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-382": {
            "name": "t-382",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-384": {
            "name": "t-384",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-383",
            "allocation": null
        },
        "t-385": {
            "name": "t-385",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-14",
            "allocation": null
        },
        "t-386": {
            "name": "t-386",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-388": {
            "name": "t-388",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-387",
            "allocation": null
        },
        "t-387": {
            "name": "t-387",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-389": {
            "name": "t-389",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-388",
            "allocation": null
        },
        "t-391": {
            "name": "t-391",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-390",
            "allocation": null
        },
        "t-390": {
            "name": "t-390",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-392": {
            "name": "t-392",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-391",
            "allocation": null
        },
        "t-393": {
            "name": "t-393",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-395": {
            "name": "t-395",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-394": {
            "name": "t-394",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-396": {
            "name": "t-396",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-395",
            "allocation": null
        },
        "t-397": {
            "name": "t-397",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-17",
            "allocation": null
        },
        "t-398": {
            "name": "t-398",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-400": {
            "name": "t-400",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-399",
            "allocation": null
        },
        "t-399": {
            "name": "t-399",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-401": {
            "name": "t-401",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-400",
            "allocation": null
        },
        "t-403": {
            "name": "t-403",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-402",
            "allocation": null
        },
        "t-402": {
            "name": "t-402",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-404": {
            "name": "t-404",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-403",
            "allocation": null
        },
        "t-405": {
            "name": "t-405",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-407": {
            "name": "t-407",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-406": {
            "name": "t-406",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-408": {
            "name": "t-408",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-407",
            "allocation": null
        },
        "t-409": {
            "name": "t-409",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-18",
            "allocation": null
        },
        "t-410": {
            "name": "t-410",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-412": {
            "name": "t-412",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-411",
            "allocation": null
        },
        "t-411": {
            "name": "t-411",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-413": {
            "name": "t-413",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-412",
            "allocation": null
        },
        "t-415": {
            "name": "t-415",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-414",
            "allocation": null
        },
        "t-414": {
            "name": "t-414",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-416": {
            "name": "t-416",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-415",
            "allocation": null
        },
        "t-417": {
            "name": "t-417",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-419": {
            "name": "t-419",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-418": {
            "name": "t-418",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-420": {
            "name": "t-420",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-419",
            "allocation": null
        },
        "t-421": {
            "name": "t-421",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-21",
            "allocation": null
        },
        "t-422": {
            "name": "t-422",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-424": {
            "name": "t-424",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-423",
            "allocation": null
        },
        "t-423": {
            "name": "t-423",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-425": {
            "name": "t-425",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-424",
            "allocation": null
        },
        "t-427": {
            "name": "t-427",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-426",
            "allocation": null
        },
        "t-426": {
            "name": "t-426",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-428": {
            "name": "t-428",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-427",
            "allocation": null
        },
        "t-429": {
            "name": "t-429",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-431": {
            "name": "t-431",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-430": {
            "name": "t-430",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-432": {
            "name": "t-432",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-431",
            "allocation": null
        },
        "t-433": {
            "name": "t-433",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-22",
            "allocation": null
        },
        "t-434": {
            "name": "t-434",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-436": {
            "name": "t-436",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-435",
            "allocation": null
        },
        "t-435": {
            "name": "t-435",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-437": {
            "name": "t-437",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-436",
            "allocation": null
        },
        "t-439": {
            "name": "t-439",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-438",
            "allocation": null
        },
        "t-438": {
            "name": "t-438",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-440": {
            "name": "t-440",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-439",
            "allocation": null
        },
        "t-441": {
            "name": "t-441",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-443": {
            "name": "t-443",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-442": {
            "name": "t-442",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-444": {
            "name": "t-444",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-443",
            "allocation": null
        },
        "t-445": {
            "name": "t-445",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-25",
            "allocation": null
        },
        "t-446": {
            "name": "t-446",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-448": {
            "name": "t-448",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-447",
            "allocation": null
        },
        "t-447": {
            "name": "t-447",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-449": {
            "name": "t-449",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-448",
            "allocation": null
        },
        "t-451": {
            "name": "t-451",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-450",
            "allocation": null
        },
        "t-450": {
            "name": "t-450",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-452": {
            "name": "t-452",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-451",
            "allocation": null
        },
        "t-453": {
            "name": "t-453",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-455": {
            "name": "t-455",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-454": {
            "name": "t-454",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-456": {
            "name": "t-456",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-455",
            "allocation": null
        },
        "t-457": {
            "name": "t-457",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-26",
            "allocation": null
        },
        "t-458": {
            "name": "t-458",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-460": {
            "name": "t-460",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-459",
            "allocation": null
        },
        "t-459": {
            "name": "t-459",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-461": {
            "name": "t-461",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-460",
            "allocation": null
        },
        "t-463": {
            "name": "t-463",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-462",
            "allocation": null
        },
        "t-462": {
            "name": "t-462",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-464": {
            "name": "t-464",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-463",
            "allocation": null
        },
        "t-465": {
            "name": "t-465",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-467": {
            "name": "t-467",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-466": {
            "name": "t-466",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-468": {
            "name": "t-468",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-467",
            "allocation": null
        },
        "t-469": {
            "name": "t-469",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-29",
            "allocation": null
        },
        "t-470": {
            "name": "t-470",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-472": {
            "name": "t-472",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-471",
            "allocation": null
        },
        "t-471": {
            "name": "t-471",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-473": {
            "name": "t-473",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-472",
            "allocation": null
        },
        "t-475": {
            "name": "t-475",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-474",
            "allocation": null
        },
        "t-474": {
            "name": "t-474",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-476": {
            "name": "t-476",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-475",
            "allocation": null
        },
        "t-477": {
            "name": "t-477",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-479": {
            "name": "t-479",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-478": {
            "name": "t-478",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-480": {
            "name": "t-480",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-479",
            "allocation": null
        },
        "t-481": {
            "name": "t-481",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-30",
            "allocation": null
        },
        "t-482": {
            "name": "t-482",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-484": {
            "name": "t-484",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-483",
            "allocation": null
        },
        "t-483": {
            "name": "t-483",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-485": {
            "name": "t-485",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-484",
            "allocation": null
        },
        "t-487": {
            "name": "t-487",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-486",
            "allocation": null
        },
        "t-486": {
            "name": "t-486",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-488": {
            "name": "t-488",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-487",
            "allocation": null
        },
        "t-489": {
            "name": "t-489",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-491": {
            "name": "t-491",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-490": {
            "name": "t-490",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-492": {
            "name": "t-492",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-491",
            "allocation": null
        },
        "t-493": {
            "name": "t-493",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-33",
            "allocation": null
        },
        "t-494": {
            "name": "t-494",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-496": {
            "name": "t-496",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-495",
            "allocation": null
        },
        "t-495": {
            "name": "t-495",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-497": {
            "name": "t-497",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-496",
            "allocation": null
        },
        "t-499": {
            "name": "t-499",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-498",
            "allocation": null
        },
        "t-498": {
            "name": "t-498",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-500": {
            "name": "t-500",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-499",
            "allocation": null
        },
        "t-501": {
            "name": "t-501",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-503": {
            "name": "t-503",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-502": {
            "name": "t-502",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-504": {
            "name": "t-504",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-503",
            "allocation": null
        },
        "t-505": {
            "name": "t-505",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-34",
            "allocation": null
        }
    },
    "inputs": [
        "t-3",
        "t-5",
        "t-6",
        "t-9",
        "t-10",
        "t-13",
        "t-14",
        "t-17",
        "t-18",
        "t-21",
        "t-22",
        "t-25",
        "t-26",
        "t-29",
        "t-30",
        "t-33",
        "t-34",
        "t-37",
        "t-40",
        "t-41",
        "t-42",
        "t-49",
        "t-53",
        "t-67",
        "t-69",
        "t-74",
        "t-76",
        "t-78",
        "t-82",
        "t-96",
        "t-98",
        "t-103",
        "t-105",
        "t-107",
        "t-108",
        "t-112",
        "t-126",
        "t-128",
        "t-133",
        "t-135",
        "t-137",
        "t-141",
        "t-155",
        "t-157",
        "t-162",
        "t-164",
        "t-166",
        "t-170",
        "t-184",
        "t-186",
        "t-191",
        "t-193",
        "t-195",
        "t-199",
        "t-213",
        "t-215",
        "t-220",
        "t-222",
        "t-224",
        "t-228",
        "t-242",
        "t-244",
        "t-249",
        "t-251",
        "t-253",
        "t-266",
        "t-268",
        "t-273",
        "t-275",
        "t-277",
        "t-313",
        "t-314",
        "t-317",
        "t-321",
        "t-326",
        "t-327",
        "t-330",
        "t-334",
        "t-339",
        "t-342",
        "t-346",
        "t-351",
        "t-354",
        "t-358",
        "t-363",
        "t-366",
        "t-370",
        "t-375",
        "t-378",
        "t-382",
        "t-387",
        "t-390",
        "t-394",
        "t-399",
        "t-402",
        "t-406",
        "t-411",
        "t-414",
        "t-418",
        "t-423",
        "t-426",
        "t-430",
        "t-435",
        "t-438",
        "t-442",
        "t-447",
        "t-450",
        "t-454",
        "t-459",
        "t-462",
        "t-466",
        "t-471",
        "t-474",
        "t-478",
        "t-483",
        "t-486",
        "t-490",
        "t-495",
        "t-498",
        "t-502"
    ],
    "outputs": []
}