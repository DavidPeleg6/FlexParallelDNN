{
    "name": "Some Default",
    "origin": "",
    "cpu_info": {
        "Architecture": "x86_64",
        "CPU op-mode(s)": "32-bit, 64-bit",
        "Byte Order": "Little Endian",
        "Address sizes": "46 bits physical, 48 bits virtual",
        "CPU(s)": "112",
        "On-line CPU(s) list": "0-111",
        "Thread(s) per core": "2",
        "Core(s) per socket": "28",
        "Socket(s)": "2",
        "NUMA node(s)": "2",
        "Vendor ID": "GenuineIntel",
        "CPU family": "6",
        "Model": "85",
        "Model name": "Intel(R) Xeon(R) Platinum 8180 CPU @ 2.50GHz",
        "Stepping": "4",
        "CPU MHz": "2500.055",
        "BogoMIPS": "5000.00",
        "Virtualization": "VT-x",
        "L1d cache": "1.8 MiB",
        "L1i cache": "1.8 MiB",
        "L2 cache": "56 MiB",
        "L3 cache": "77 MiB",
        "NUMA node0 CPU(s)": "0-27,56-83",
        "NUMA node1 CPU(s)": "28-55,84-111",
        "Vulnerability Itlb multihit": "KVM",
        "Vulnerability L1tf": "Mitigation; PTE Inversion; VMX conditional cache flushes, SMT vulnerable",
        "Vulnerability Mds": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Vulnerability Meltdown": "Mitigation; PTI",
        "Vulnerability Spec store bypass": "Mitigation; Speculative Store Bypass disabled via prctl and seccomp",
        "Vulnerability Spectre v1": "Mitigation; usercopy/swapgs barriers and __user pointer sanitization",
        "Vulnerability Spectre v2": "Mitigation; Full generic retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling",
        "Vulnerability Srbds": "Not affected",
        "Vulnerability Tsx async abort": "Mitigation; Clear CPU buffers; SMT vulnerable",
        "Flags": "fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti intel_ppin ssbd mba ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm arat pln pts pku ospke md_clear flush_l1d"
    },
    "layers": [
        {
            "name": "DistributedDataParallel/op-1",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-1"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 218,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 218,
                "start": 499486,
                "end": 499704
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/op-2",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-2"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 499854,
                "end": 499856
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 853, in forward\n    with torch.autograd.profiler.record_function(\"DistributedDataParallel.forward\"):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/op-3",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-3"
            ],
            "outputs": [
                "t-4"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 7,
                "flops": 0.0
            },
            "args": [
                [
                    -1,
                    784
                ]
            ],
            "runtime": {
                "duration": 7,
                "start": 500057,
                "end": 500064
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 45, in forward\n    x = x.view(-1, 28 * 28)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-4",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-4",
                "t-5",
                "t-6"
            ],
            "outputs": [
                "t-7"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 891,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 891,
                "start": 500203,
                "end": 501094
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-5",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-7"
            ],
            "outputs": [
                "t-8"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1173,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 1173,
                "start": 501261,
                "end": 502434
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-6",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-8",
                "t-9",
                "t-10"
            ],
            "outputs": [
                "t-11"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 765,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 765,
                "start": 502565,
                "end": 503330
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-7",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-11"
            ],
            "outputs": [
                "t-12"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 569,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 569,
                "start": 503463,
                "end": 504032
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-8",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-12",
                "t-13",
                "t-14"
            ],
            "outputs": [
                "t-15"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 779,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 779,
                "start": 504168,
                "end": 504947
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-9",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-15"
            ],
            "outputs": [
                "t-16"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 587,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 587,
                "start": 505071,
                "end": 505658
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-10",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-16",
                "t-17",
                "t-18"
            ],
            "outputs": [
                "t-19"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 830,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 830,
                "start": 505797,
                "end": 506627
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-11",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-19"
            ],
            "outputs": [
                "t-20"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 611,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 611,
                "start": 506748,
                "end": 507359
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-12",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-20",
                "t-21",
                "t-22"
            ],
            "outputs": [
                "t-23"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 779,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 779,
                "start": 507477,
                "end": 508256
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-13",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-23"
            ],
            "outputs": [
                "t-24"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 587,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 587,
                "start": 508381,
                "end": 508968
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-14",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-24",
                "t-25",
                "t-26"
            ],
            "outputs": [
                "t-27"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 777,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 777,
                "start": 509085,
                "end": 509862
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-15",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-27"
            ],
            "outputs": [
                "t-28"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 554,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 554,
                "start": 509985,
                "end": 510539
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-16",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-28",
                "t-29",
                "t-30"
            ],
            "outputs": [
                "t-31"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 738,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 738,
                "start": 510664,
                "end": 511402
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-17",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-31"
            ],
            "outputs": [
                "t-32"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 567,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 567,
                "start": 511536,
                "end": 512103
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Linear/op-18",
            "optype": "aten::linear",
            "params": {},
            "inputs": [
                "t-32",
                "t-33",
                "t-34"
            ],
            "outputs": [
                "t-35"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 775,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 775,
                "start": 512220,
                "end": 512995
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 47, in forward\n    x = layer(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\n"
            ]
        },
        {
            "name": "DistributedDataParallel/DistributedDataParallel.forward/Net/Dropout/op-19",
            "optype": "aten::dropout",
            "params": {},
            "inputs": [
                "t-35"
            ],
            "outputs": [
                "t-36"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 535,
                "flops": 0.0
            },
            "args": [
                0.1,
                true
            ],
            "runtime": {
                "duration": 535,
                "start": 513117,
                "end": 513652
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 170, in train_and_test\n    output = model(data)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 888, in forward\n    output = self.module(*inputs, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"ddp_mlp.py\", line 48, in forward\n    x = self.dropout(x)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/dropout.py\", line 58, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 1169, in dropout\n    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n"
            ]
        },
        {
            "name": "CrossEntropyLoss/op-20",
            "optype": "aten::cross_entropy_loss",
            "params": {},
            "inputs": [
                "t-36",
                "t-37"
            ],
            "outputs": [
                "t-38"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 813,
                "flops": 0.0
            },
            "args": [
                1,
                -100,
                0.0
            ],
            "runtime": {
                "duration": 813,
                "start": 513848,
                "end": 514661
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 171, in train_and_test\n    loss = loss_model(output, target)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n    result = forward_call(*input, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 1150, in forward\n    return F.cross_entropy(input, target, weight=self.weight,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 2846, in cross_entropy\n    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n"
            ]
        },
        {
            "name": "op-21",
            "optype": "aten::ones_like",
            "params": {},
            "inputs": [
                "t-38"
            ],
            "outputs": [
                "t-39"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 250,
                "flops": 0.0
            },
            "args": [
                6,
                0,
                false,
                1
            ],
            "runtime": {
                "duration": 250,
                "start": 515149,
                "end": 515399
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 172, in train_and_test\n    loss.backward()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 150, in backward\n    grad_tensors_ = _make_grads(tensors, grad_tensors_)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 52, in _make_grads\n    new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/NllLossBackward0/op-22",
            "optype": "aten::nll_loss_backward",
            "params": {},
            "inputs": [
                "t-39",
                "t-40",
                "t-37",
                "t-41",
                "t-42"
            ],
            "outputs": [
                "t-43"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 99,
                "flops": 0.0
            },
            "args": [
                1,
                -100
            ],
            "runtime": {
                "duration": 99,
                "start": 515883,
                "end": 515982
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-23",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-43"
            ],
            "outputs": [
                "t-44"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 516028,
                "end": 516074
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-24",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-44"
            ],
            "outputs": [
                "t-45"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 516107,
                "end": 516157
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: NllLossBackward0/op-25",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-45"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 54,
                "start": 516185,
                "end": 516239
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/LogSoftmaxBackward0/op-26",
            "optype": "aten::_log_softmax_backward_data",
            "params": {},
            "inputs": [
                "t-43",
                "t-44",
                "t-36"
            ],
            "outputs": [
                "t-46"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 516340,
                "end": 516355
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-27",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-46"
            ],
            "outputs": [
                "t-47"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 516389,
                "end": 516426
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-28",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-47"
            ],
            "outputs": [
                "t-48"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 516448,
                "end": 516492
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: LogSoftmaxBackward0/op-29",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-48"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 50,
                "start": 516515,
                "end": 516565
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-30",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-46",
                "t-49"
            ],
            "outputs": [
                "t-50"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 80,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 80,
                "start": 516651,
                "end": 516731
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-31",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-51"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 516763,
                "end": 516799
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-32",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-51"
            ],
            "outputs": [
                "t-52"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 516827,
                "end": 516870
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-33",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-52"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 516894,
                "end": 516938
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-34",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-53"
            ],
            "outputs": [
                "t-54"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 517017,
                "end": 517072
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-35",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    10
                ],
                "mat2_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-50",
                "t-54"
            ],
            "outputs": [
                "t-55"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 21,
                "start": 517112,
                "end": 517133
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-36",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-56"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 517160,
                "end": 517213
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-37",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    10,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-56",
                "t-32"
            ],
            "outputs": [
                "t-57"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 2621440.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 517239,
                "end": 517255
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-38",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-57"
            ],
            "outputs": [
                "t-58"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 517283,
                "end": 517334
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-39",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-50"
            ],
            "outputs": [
                "t-59"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 21,
                "start": 517368,
                "end": 517389
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-40",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-59"
            ],
            "outputs": [
                "t-60"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 517415,
                "end": 517419
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-41",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-60"
            ],
            "outputs": [
                "t-61"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 517451,
                "end": 517492
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-42",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-61"
            ],
            "outputs": [
                "t-62"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 517515,
                "end": 517560
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-43",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-62"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 48,
                "start": 517582,
                "end": 517630
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-44",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-55"
            ],
            "outputs": [
                "t-63"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 35,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 35,
                "start": 517657,
                "end": 517692
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-45",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-63"
            ],
            "outputs": [
                "t-64"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 70,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 70,
                "start": 517714,
                "end": 517784
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-46",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-64"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 70,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 70,
                "start": 517950,
                "end": 518020
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-47",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-65"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 122,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 122,
                "start": 518109,
                "end": 518231
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-48",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-65"
            ],
            "outputs": [
                "t-66"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 130,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 130,
                "start": 518261,
                "end": 518391
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-49",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-66"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 518415,
                "end": 518456
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-50",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-67",
                "t-60"
            ],
            "outputs": [
                "t-68"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 18,
                "start": 518795,
                "end": 518813
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-51",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-68",
                "t-65",
                "t-69"
            ],
            "outputs": [
                "t-70"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 10.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 518868,
                "end": 518884
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-52",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-58"
            ],
            "outputs": [
                "t-71"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 87,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 87,
                "start": 519013,
                "end": 519100
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-53",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-71"
            ],
            "outputs": [
                "t-72"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 519231,
                "end": 519279
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-54",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-72"
            ],
            "outputs": [
                "t-73"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 519304,
                "end": 519356
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-55",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-73"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 519380,
                "end": 519423
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-56",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-74",
                "t-71"
            ],
            "outputs": [
                "t-75"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 17,
                "start": 519716,
                "end": 519733
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-57",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-75",
                "t-72",
                "t-76"
            ],
            "outputs": [
                "t-77"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 5120.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 519776,
                "end": 519791
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-58",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-55",
                "t-78"
            ],
            "outputs": [
                "t-79"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 74,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 74,
                "start": 519884,
                "end": 519958
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-59",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-80"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 519992,
                "end": 520030
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-60",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-80"
            ],
            "outputs": [
                "t-81"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 61,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 61,
                "start": 520054,
                "end": 520115
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-61",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-81"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 64,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 64,
                "start": 520140,
                "end": 520204
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-62",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-82"
            ],
            "outputs": [
                "t-83"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 60,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 60,
                "start": 520294,
                "end": 520354
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-63",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-79",
                "t-83"
            ],
            "outputs": [
                "t-84"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 21,
                "start": 520383,
                "end": 520404
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-64",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-85"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 520430,
                "end": 520486
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-65",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-85",
                "t-28"
            ],
            "outputs": [
                "t-86"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 520517,
                "end": 520535
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-66",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-86"
            ],
            "outputs": [
                "t-87"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 520568,
                "end": 520623
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-67",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-79"
            ],
            "outputs": [
                "t-88"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 520649,
                "end": 520669
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-68",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-88"
            ],
            "outputs": [
                "t-89"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 520703,
                "end": 520707
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-69",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-89"
            ],
            "outputs": [
                "t-90"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 520739,
                "end": 520781
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-70",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-90"
            ],
            "outputs": [
                "t-91"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 520804,
                "end": 520851
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-71",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-91"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 520873,
                "end": 520916
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-72",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-84"
            ],
            "outputs": [
                "t-92"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 520946,
                "end": 520987
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-73",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-92"
            ],
            "outputs": [
                "t-93"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 521011,
                "end": 521064
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-74",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-93"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 521090,
                "end": 521128
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-75",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-94"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 521154,
                "end": 521197
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-76",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-94"
            ],
            "outputs": [
                "t-95"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 47,
                "start": 521222,
                "end": 521269
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-77",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-95"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 49,
                "start": 521292,
                "end": 521341
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-78",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-96",
                "t-89"
            ],
            "outputs": [
                "t-97"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 521426,
                "end": 521441
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-79",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-97",
                "t-94",
                "t-98"
            ],
            "outputs": [
                "t-99"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 521491,
                "end": 521506
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-80",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-87"
            ],
            "outputs": [
                "t-100"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 521585,
                "end": 521640
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-81",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-100"
            ],
            "outputs": [
                "t-101"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 521664,
                "end": 521708
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-82",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-101"
            ],
            "outputs": [
                "t-102"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 521742,
                "end": 521794
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-83",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-102"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 521820,
                "end": 521865
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-84",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-103",
                "t-100"
            ],
            "outputs": [
                "t-104"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 521946,
                "end": 521960
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-85",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-104",
                "t-101",
                "t-105"
            ],
            "outputs": [
                "t-106"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 522006,
                "end": 522021
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-86",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 522097,
                "end": 522138
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-87",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-84",
                "t-108"
            ],
            "outputs": [
                "t-109"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 79,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 79,
                "start": 522237,
                "end": 522316
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-88",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-110"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 522350,
                "end": 522386
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-89",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-110"
            ],
            "outputs": [
                "t-111"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 522414,
                "end": 522467
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-90",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-111"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 522492,
                "end": 522539
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-91",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-112"
            ],
            "outputs": [
                "t-113"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 522619,
                "end": 522676
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-92",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-109",
                "t-113"
            ],
            "outputs": [
                "t-114"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 522706,
                "end": 522726
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-93",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-115"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 522758,
                "end": 522808
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-94",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-115",
                "t-24"
            ],
            "outputs": [
                "t-116"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 522841,
                "end": 522859
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-95",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-116"
            ],
            "outputs": [
                "t-117"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 522885,
                "end": 522937
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-96",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-109"
            ],
            "outputs": [
                "t-118"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 21,
                "start": 522967,
                "end": 522988
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-97",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-118"
            ],
            "outputs": [
                "t-119"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 523015,
                "end": 523019
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-98",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-119"
            ],
            "outputs": [
                "t-120"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 523051,
                "end": 523093
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-99",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-120"
            ],
            "outputs": [
                "t-121"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 523116,
                "end": 523157
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-100",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-121"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 523179,
                "end": 523225
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-101",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-114"
            ],
            "outputs": [
                "t-122"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 523251,
                "end": 523287
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-102",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-122"
            ],
            "outputs": [
                "t-123"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 61,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 61,
                "start": 523310,
                "end": 523371
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-103",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-123"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 523395,
                "end": 523434
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-104",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-124"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 523465,
                "end": 523505
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-105",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-124"
            ],
            "outputs": [
                "t-125"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 523529,
                "end": 523581
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-106",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-125"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 523606,
                "end": 523643
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-107",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-126",
                "t-119"
            ],
            "outputs": [
                "t-127"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 16,
                "start": 523739,
                "end": 523755
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-108",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-127",
                "t-124",
                "t-128"
            ],
            "outputs": [
                "t-129"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 523799,
                "end": 523814
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-109",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-117"
            ],
            "outputs": [
                "t-130"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 523900,
                "end": 523956
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-110",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-130"
            ],
            "outputs": [
                "t-131"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 523982,
                "end": 524023
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-111",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-131"
            ],
            "outputs": [
                "t-132"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 524047,
                "end": 524102
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-112",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-132"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 41,
                "start": 524126,
                "end": 524167
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-113",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-133",
                "t-130"
            ],
            "outputs": [
                "t-134"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 524258,
                "end": 524272
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-114",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-134",
                "t-131",
                "t-135"
            ],
            "outputs": [
                "t-136"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 524311,
                "end": 524326
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-115",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-114",
                "t-137"
            ],
            "outputs": [
                "t-138"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 75,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 75,
                "start": 524409,
                "end": 524484
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-116",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-139"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 524515,
                "end": 524553
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-117",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-139"
            ],
            "outputs": [
                "t-140"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 524581,
                "end": 524635
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-118",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-140"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 524661,
                "end": 524701
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-119",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-141"
            ],
            "outputs": [
                "t-142"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 524786,
                "end": 524840
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-120",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-138",
                "t-142"
            ],
            "outputs": [
                "t-143"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 524870,
                "end": 524890
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-121",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-144"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 524916,
                "end": 524969
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-122",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-144",
                "t-20"
            ],
            "outputs": [
                "t-145"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 524996,
                "end": 525014
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-123",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-145"
            ],
            "outputs": [
                "t-146"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 525039,
                "end": 525094
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-124",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-138"
            ],
            "outputs": [
                "t-147"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 19,
                "start": 525121,
                "end": 525140
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-125",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-147"
            ],
            "outputs": [
                "t-148"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 525177,
                "end": 525181
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-126",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-148"
            ],
            "outputs": [
                "t-149"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 525217,
                "end": 525255
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-127",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-149"
            ],
            "outputs": [
                "t-150"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 525279,
                "end": 525327
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-128",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-150"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 525353,
                "end": 525395
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-129",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-143"
            ],
            "outputs": [
                "t-151"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 525422,
                "end": 525464
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-130",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-151"
            ],
            "outputs": [
                "t-152"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 525489,
                "end": 525540
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-131",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-152"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 37,
                "start": 525569,
                "end": 525606
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-132",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-153"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 525633,
                "end": 525677
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-133",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-153"
            ],
            "outputs": [
                "t-154"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 525701,
                "end": 525758
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-134",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-154"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 525783,
                "end": 525828
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-135",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-155",
                "t-148"
            ],
            "outputs": [
                "t-156"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 525914,
                "end": 525929
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-136",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-156",
                "t-153",
                "t-157"
            ],
            "outputs": [
                "t-158"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 525976,
                "end": 525991
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-137",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-146"
            ],
            "outputs": [
                "t-159"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 526070,
                "end": 526125
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-138",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-159"
            ],
            "outputs": [
                "t-160"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 44,
                "start": 526151,
                "end": 526195
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-139",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-160"
            ],
            "outputs": [
                "t-161"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 526218,
                "end": 526269
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-140",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-161"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 526294,
                "end": 526341
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-141",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-162",
                "t-159"
            ],
            "outputs": [
                "t-163"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 526428,
                "end": 526441
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-142",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-163",
                "t-160",
                "t-164"
            ],
            "outputs": [
                "t-165"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 526485,
                "end": 526499
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-143",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-143",
                "t-166"
            ],
            "outputs": [
                "t-167"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 71,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 71,
                "start": 526577,
                "end": 526648
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-144",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-168"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 526679,
                "end": 526722
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-145",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-168"
            ],
            "outputs": [
                "t-169"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 49,
                "start": 526744,
                "end": 526793
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-146",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-169"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 49,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 49,
                "start": 526818,
                "end": 526867
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-147",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-170"
            ],
            "outputs": [
                "t-171"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 526948,
                "end": 527005
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-148",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-167",
                "t-171"
            ],
            "outputs": [
                "t-172"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 527033,
                "end": 527052
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-149",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-173"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 527084,
                "end": 527136
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-150",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-173",
                "t-16"
            ],
            "outputs": [
                "t-174"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 527163,
                "end": 527181
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-151",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-174"
            ],
            "outputs": [
                "t-175"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 527206,
                "end": 527257
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-152",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-167"
            ],
            "outputs": [
                "t-176"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 527286,
                "end": 527306
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-153",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-176"
            ],
            "outputs": [
                "t-177"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 527334,
                "end": 527338
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-154",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-177"
            ],
            "outputs": [
                "t-178"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 527370,
                "end": 527412
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-155",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-178"
            ],
            "outputs": [
                "t-179"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 527438,
                "end": 527479
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-156",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-179"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 527506,
                "end": 527549
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-157",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-172"
            ],
            "outputs": [
                "t-180"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 527574,
                "end": 527614
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-158",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-180"
            ],
            "outputs": [
                "t-181"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 527638,
                "end": 527686
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-159",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-181"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 527714,
                "end": 527757
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-160",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-182"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 527784,
                "end": 527821
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-161",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-182"
            ],
            "outputs": [
                "t-183"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 527845,
                "end": 527899
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-162",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-183"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 38,
                "start": 527923,
                "end": 527961
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-163",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-184",
                "t-177"
            ],
            "outputs": [
                "t-185"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 16,
                "start": 528055,
                "end": 528071
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-164",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-185",
                "t-182",
                "t-186"
            ],
            "outputs": [
                "t-187"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 528110,
                "end": 528124
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-165",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-175"
            ],
            "outputs": [
                "t-188"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 528206,
                "end": 528263
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-166",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-188"
            ],
            "outputs": [
                "t-189"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 528290,
                "end": 528328
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-167",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-189"
            ],
            "outputs": [
                "t-190"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 528350,
                "end": 528408
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-168",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-190"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 528434,
                "end": 528476
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-169",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-191",
                "t-188"
            ],
            "outputs": [
                "t-192"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 528565,
                "end": 528579
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-170",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-192",
                "t-189",
                "t-193"
            ],
            "outputs": [
                "t-194"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 528619,
                "end": 528633
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-171",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-172",
                "t-195"
            ],
            "outputs": [
                "t-196"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 72,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 72,
                "start": 528716,
                "end": 528788
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-172",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-197"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 36,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 36,
                "start": 528822,
                "end": 528858
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-173",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-197"
            ],
            "outputs": [
                "t-198"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 528889,
                "end": 528941
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-174",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-198"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 45,
                "start": 528965,
                "end": 529010
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-175",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-199"
            ],
            "outputs": [
                "t-200"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 529093,
                "end": 529147
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-176",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-196",
                "t-200"
            ],
            "outputs": [
                "t-201"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 529176,
                "end": 529196
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-177",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-202"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 164,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 164,
                "start": 529225,
                "end": 529389
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-178",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-202",
                "t-12"
            ],
            "outputs": [
                "t-203"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 24,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 24,
                "start": 529424,
                "end": 529448
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-179",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-203"
            ],
            "outputs": [
                "t-204"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 529483,
                "end": 529535
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-180",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-196"
            ],
            "outputs": [
                "t-205"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 22,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 22,
                "start": 529564,
                "end": 529586
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-181",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-205"
            ],
            "outputs": [
                "t-206"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 529619,
                "end": 529623
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-182",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-206"
            ],
            "outputs": [
                "t-207"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 529656,
                "end": 529697
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-183",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-207"
            ],
            "outputs": [
                "t-208"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 46,
                "start": 529735,
                "end": 529781
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-184",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-208"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 529805,
                "end": 529852
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-185",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-201"
            ],
            "outputs": [
                "t-209"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 529883,
                "end": 529921
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-186",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-209"
            ],
            "outputs": [
                "t-210"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 58,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 58,
                "start": 529945,
                "end": 530003
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-187",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-210"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 39,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 39,
                "start": 530031,
                "end": 530070
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-188",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-211"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 45,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 45,
                "start": 530096,
                "end": 530141
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-189",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-211"
            ],
            "outputs": [
                "t-212"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 530168,
                "end": 530216
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-190",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-212"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 530249,
                "end": 530291
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-191",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-213",
                "t-206"
            ],
            "outputs": [
                "t-214"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 530387,
                "end": 530402
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-192",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-214",
                "t-211",
                "t-215"
            ],
            "outputs": [
                "t-216"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 530443,
                "end": 530458
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-193",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-204"
            ],
            "outputs": [
                "t-217"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 530544,
                "end": 530597
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-194",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-217"
            ],
            "outputs": [
                "t-218"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 40,
                "start": 530623,
                "end": 530663
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-195",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-218"
            ],
            "outputs": [
                "t-219"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 530686,
                "end": 530742
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-196",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-219"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 530766,
                "end": 530809
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-197",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-220",
                "t-217"
            ],
            "outputs": [
                "t-221"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 530899,
                "end": 530913
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-198",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-221",
                "t-218",
                "t-222"
            ],
            "outputs": [
                "t-223"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 530953,
                "end": 530967
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-199",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-201",
                "t-224"
            ],
            "outputs": [
                "t-225"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 74,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 74,
                "start": 531056,
                "end": 531130
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-200",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-226"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 531164,
                "end": 531201
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-201",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-226"
            ],
            "outputs": [
                "t-227"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 531225,
                "end": 531281
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-202",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-227"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 531308,
                "end": 531351
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-203",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-228"
            ],
            "outputs": [
                "t-229"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 55,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 55,
                "start": 531441,
                "end": 531496
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-204",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    256,
                    512
                ],
                "mat2_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-225",
                "t-229"
            ],
            "outputs": [
                "t-230"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 20,
                "start": 531527,
                "end": 531547
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-205",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-231"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 56,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 56,
                "start": 531578,
                "end": 531634
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-206",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    512
                ]
            },
            "inputs": [
                "t-231",
                "t-8"
            ],
            "outputs": [
                "t-232"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 134217728.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 531660,
                "end": 531678
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-207",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-232"
            ],
            "outputs": [
                "t-233"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 50,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 50,
                "start": 531707,
                "end": 531757
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-208",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-225"
            ],
            "outputs": [
                "t-234"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 531784,
                "end": 531804
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-209",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-234"
            ],
            "outputs": [
                "t-235"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 531839,
                "end": 531843
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-210",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-235"
            ],
            "outputs": [
                "t-236"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 531878,
                "end": 531920
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-211",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-236"
            ],
            "outputs": [
                "t-237"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 531943,
                "end": 531991
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-212",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-237"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 532014,
                "end": 532056
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-213",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-230"
            ],
            "outputs": [
                "t-238"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 532083,
                "end": 532126
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-214",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-238"
            ],
            "outputs": [
                "t-239"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 532150,
                "end": 532201
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-215",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-239"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 42,
                "start": 532227,
                "end": 532269
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-216",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-240"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 532295,
                "end": 532338
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-217",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-240"
            ],
            "outputs": [
                "t-241"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 48,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 48,
                "start": 532362,
                "end": 532410
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-218",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-241"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 44,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 44,
                "start": 532435,
                "end": 532479
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-219",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-242",
                "t-235"
            ],
            "outputs": [
                "t-243"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 532567,
                "end": 532581
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-220",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-243",
                "t-240",
                "t-244"
            ],
            "outputs": [
                "t-245"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 532629,
                "end": 532643
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-221",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-233"
            ],
            "outputs": [
                "t-246"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 60,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 60,
                "start": 532736,
                "end": 532796
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-222",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-246"
            ],
            "outputs": [
                "t-247"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 532822,
                "end": 532864
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-223",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-247"
            ],
            "outputs": [
                "t-248"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 51,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 51,
                "start": 532888,
                "end": 532939
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-224",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-248"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 532963,
                "end": 533009
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-225",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-249",
                "t-246"
            ],
            "outputs": [
                "t-250"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 533095,
                "end": 533109
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-226",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-250",
                "t-247",
                "t-251"
            ],
            "outputs": [
                "t-252"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 533155,
                "end": 533169
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/FusedDropoutBackward0/op-227",
            "optype": "aten::_masked_scale",
            "params": {},
            "inputs": [
                "t-230",
                "t-253"
            ],
            "outputs": [
                "t-254"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 73,
                "flops": 0.0
            },
            "args": [
                1.1111111111111112
            ],
            "runtime": {
                "duration": 73,
                "start": 533249,
                "end": 533322
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-228",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-255"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 43,
                "start": 533356,
                "end": 533399
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-229",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-255"
            ],
            "outputs": [
                "t-256"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 54,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 54,
                "start": 533422,
                "end": 533476
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: FusedDropoutBackward0/op-230",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-256"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 43,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 43,
                "start": 533507,
                "end": 533550
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-231",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-257"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 57,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 57,
                "start": 533629,
                "end": 533686
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-232",
            "optype": "aten::mm",
            "params": {
                "mat1_size": [
                    512,
                    256
                ],
                "mat2_size": [
                    256,
                    784
                ]
            },
            "inputs": [
                "t-257",
                "t-4"
            ],
            "outputs": [
                "t-258"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 31,
                "flops": 205520896.0
            },
            "args": [],
            "runtime": {
                "duration": 31,
                "start": 533719,
                "end": 533750
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/AddmmBackward0/op-233",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-258"
            ],
            "outputs": [
                "t-259"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 53,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 53,
                "start": 533778,
                "end": 533831
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-234",
            "optype": "aten::sum",
            "params": {},
            "inputs": [
                "t-254"
            ],
            "outputs": [
                "t-260"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 20,
                "flops": 0.0
            },
            "args": [
                [
                    0
                ],
                true
            ],
            "runtime": {
                "duration": 20,
                "start": 533858,
                "end": 533878
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-235",
            "optype": "aten::view",
            "params": {},
            "inputs": [
                "t-260"
            ],
            "outputs": [
                "t-261"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 4,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ]
            ],
            "runtime": {
                "duration": 4,
                "start": 533905,
                "end": 533909
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-236",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-261"
            ],
            "outputs": [
                "t-262"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 41,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 41,
                "start": 533939,
                "end": 533980
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-237",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-262"
            ],
            "outputs": [
                "t-263"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 42,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 42,
                "start": 534005,
                "end": 534047
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-238",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-263"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 47,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 47,
                "start": 534071,
                "end": 534118
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-239",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-264"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 534144,
                "end": 534182
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-240",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-264"
            ],
            "outputs": [
                "t-265"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 61,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 61,
                "start": 534205,
                "end": 534266
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: AddmmBackward0/op-241",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-265"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 40,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 40,
                "start": 534291,
                "end": 534331
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-242",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-266",
                "t-261"
            ],
            "outputs": [
                "t-267"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 15,
                "start": 534422,
                "end": 534437
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-243",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-267",
                "t-264",
                "t-268"
            ],
            "outputs": [
                "t-269"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 512.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 534478,
                "end": 534492
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/TBackward0/op-244",
            "optype": "aten::t",
            "params": {},
            "inputs": [
                "t-259"
            ],
            "outputs": [
                "t-270"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 62,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 62,
                "start": 534575,
                "end": 534637
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-245",
            "optype": "aten::isnan",
            "params": {},
            "inputs": [
                "t-270"
            ],
            "outputs": [
                "t-271"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 37,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 37,
                "start": 534663,
                "end": 534700
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-246",
            "optype": "aten::any",
            "params": {},
            "inputs": [
                "t-271"
            ],
            "outputs": [
                "t-272"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 52,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 52,
                "start": 534730,
                "end": 534782
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: TBackward0/op-247",
            "optype": "aten::item",
            "params": {},
            "inputs": [
                "t-272"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 46,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 46,
                "start": 534807,
                "end": 534853
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/torch::autograd::AccumulateGrad/op-248",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-273",
                "t-270"
            ],
            "outputs": [
                "t-274"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 534937,
                "end": 534951
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/op-249",
            "optype": "aten::mul",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-274",
                "t-271",
                "t-275"
            ],
            "outputs": [
                "t-276"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 401408.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 534993,
                "end": 535007
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "autograd::engine::evaluate_function: torch::autograd::AccumulateGrad/record_param_comms/op-250",
            "optype": "nccl:all_reduce",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 38,
                "start": 535079,
                "end": 535117
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-251",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-278"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 5,
                "flops": 0.0
            },
            "args": [
                [
                    10
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 5,
                "start": 535188,
                "end": 535193
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-252",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-279"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    10,
                    512
                ],
                [
                    512,
                    1
                ],
                10
            ],
            "runtime": {
                "duration": 2,
                "start": 535217,
                "end": 535219
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-253",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-280"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                5130
            ],
            "runtime": {
                "duration": 1,
                "start": 535242,
                "end": 535243
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-254",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-107"
            ],
            "outputs": [
                "t-281"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                5642
            ],
            "runtime": {
                "duration": 1,
                "start": 535267,
                "end": 535268
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-255",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-68",
                "t-278"
            ],
            "outputs": [
                "t-282"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 21,
                "start": 535302,
                "end": 535323
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-256",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-75",
                "t-279"
            ],
            "outputs": [
                "t-283"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 535350,
                "end": 535361
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-257",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-97",
                "t-280"
            ],
            "outputs": [
                "t-284"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 535387,
                "end": 535398
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-258",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-104",
                "t-281"
            ],
            "outputs": [
                "t-285"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 535423,
                "end": 535434
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-259",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-286"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                0
            ],
            "runtime": {
                "duration": 2,
                "start": 535476,
                "end": 535478
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-260",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-287"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                512
            ],
            "runtime": {
                "duration": 2,
                "start": 535504,
                "end": 535506
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-261",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-288"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                262656
            ],
            "runtime": {
                "duration": 1,
                "start": 535529,
                "end": 535530
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-262",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-289"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                263168
            ],
            "runtime": {
                "duration": 2,
                "start": 535553,
                "end": 535555
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-263",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-290"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 1,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                525312
            ],
            "runtime": {
                "duration": 1,
                "start": 535578,
                "end": 535579
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-264",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-291"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 6,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                525824
            ],
            "runtime": {
                "duration": 6,
                "start": 535602,
                "end": 535608
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-265",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-292"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                787968
            ],
            "runtime": {
                "duration": 2,
                "start": 535631,
                "end": 535633
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-266",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-293"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                788480
            ],
            "runtime": {
                "duration": 2,
                "start": 535655,
                "end": 535657
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-267",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-294"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 6,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1050624
            ],
            "runtime": {
                "duration": 6,
                "start": 535680,
                "end": 535686
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-268",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-295"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    512
                ],
                [
                    512,
                    1
                ],
                1051136
            ],
            "runtime": {
                "duration": 2,
                "start": 535711,
                "end": 535713
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-269",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-296"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "args": [
                [
                    512
                ],
                [
                    1
                ],
                1313280
            ],
            "runtime": {
                "duration": 3,
                "start": 535735,
                "end": 535738
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-270",
            "optype": "aten::as_strided",
            "params": {},
            "inputs": [
                "t-277"
            ],
            "outputs": [
                "t-297"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 2,
                "flops": 0.0
            },
            "args": [
                [
                    512,
                    784
                ],
                [
                    784,
                    1
                ],
                1313792
            ],
            "runtime": {
                "duration": 2,
                "start": 535767,
                "end": 535769
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-271",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-127",
                "t-286"
            ],
            "outputs": [
                "t-298"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 14,
                "start": 535795,
                "end": 535809
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-272",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-134",
                "t-287"
            ],
            "outputs": [
                "t-299"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 535834,
                "end": 535845
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-273",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-156",
                "t-288"
            ],
            "outputs": [
                "t-300"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 535870,
                "end": 535880
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-274",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-163",
                "t-289"
            ],
            "outputs": [
                "t-301"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 535913,
                "end": 535924
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-275",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-185",
                "t-290"
            ],
            "outputs": [
                "t-302"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 535949,
                "end": 535959
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-276",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-192",
                "t-291"
            ],
            "outputs": [
                "t-303"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 535984,
                "end": 535994
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-277",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-214",
                "t-292"
            ],
            "outputs": [
                "t-304"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 11,
                "start": 536023,
                "end": 536034
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-278",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-221",
                "t-293"
            ],
            "outputs": [
                "t-305"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 536061,
                "end": 536071
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-279",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-243",
                "t-294"
            ],
            "outputs": [
                "t-306"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 536096,
                "end": 536106
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-280",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-250",
                "t-295"
            ],
            "outputs": [
                "t-307"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 536136,
                "end": 536146
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-281",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-267",
                "t-296"
            ],
            "outputs": [
                "t-308"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 10,
                "start": 536172,
                "end": 536182
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-282",
            "optype": "aten::copy_",
            "params": {},
            "inputs": [
                "t-274",
                "t-297"
            ],
            "outputs": [
                "t-309"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 9,
                "flops": 0.0
            },
            "args": [
                false
            ],
            "runtime": {
                "duration": 9,
                "start": 536208,
                "end": 536217
            },
            "stack": [
                "  File \"/usr/lib/python3.8/traceback.py\", line 197, in format_stack\n    return format_list(extract_stack(f, limit=limit))\n"
            ]
        },
        {
            "name": "op-283",
            "optype": "aten::zeros",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-310"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 152,
                "flops": 0.0
            },
            "args": [
                [
                    1
                ],
                6,
                false
            ],
            "runtime": {
                "duration": 152,
                "start": 536654,
                "end": 536806
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 432, in __init__\n    self.handle: torch.Tensor = torch.zeros(1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-284",
            "optype": "aten::empty",
            "params": {},
            "inputs": [],
            "outputs": [
                "t-311"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 3,
                "flops": 0.0
            },
            "args": [
                [
                    16
                ],
                0
            ],
            "runtime": {
                "duration": 3,
                "start": 536930,
                "end": 536933
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 87, in wrapper\n    with torch.autograd.profiler.record_function(profile_name):\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 435, in __enter__\n    self.handle = torch.ops.profiler._record_function_enter(self.name)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-285",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    784
                ]
            },
            "inputs": [
                "t-309",
                "t-5"
            ],
            "outputs": [
                "t-312"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 38,
                "flops": 401408.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 38,
                "start": 537418,
                "end": 537456
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-286",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-313",
                "t-314"
            ],
            "outputs": [
                "t-315"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 21,
                "start": 537573,
                "end": 537594
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-287",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-315",
                "t-312"
            ],
            "outputs": [
                "t-316"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 13,
                "start": 537684,
                "end": 537697
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-288",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-317",
                "t-314"
            ],
            "outputs": [
                "t-318"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 537790,
                "end": 537803
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-289",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-318",
                "t-312",
                "t-312"
            ],
            "outputs": [
                "t-319"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 17,
                "start": 537921,
                "end": 537938
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-290",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-319"
            ],
            "outputs": [
                "t-320"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 538041,
                "end": 538060
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-291",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-320",
                "t-321"
            ],
            "outputs": [
                "t-322"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 538173,
                "end": 538191
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-292",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-322",
                "t-320"
            ],
            "outputs": [
                "t-323"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 14,
                "start": 538285,
                "end": 538299
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-293",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-5",
                "t-316",
                "t-323"
            ],
            "outputs": [
                "t-324"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 15,
                "start": 538406,
                "end": 538421
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-294",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-308",
                "t-6"
            ],
            "outputs": [
                "t-325"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 21,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 21,
                "start": 538631,
                "end": 538652
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-295",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-326",
                "t-327"
            ],
            "outputs": [
                "t-328"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 538888,
                "end": 538903
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-296",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-328",
                "t-325"
            ],
            "outputs": [
                "t-329"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 13,
                "start": 539155,
                "end": 539168
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-297",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-330",
                "t-327"
            ],
            "outputs": [
                "t-331"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 539378,
                "end": 539391
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-298",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-331",
                "t-325",
                "t-325"
            ],
            "outputs": [
                "t-332"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 669,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 669,
                "start": 539588,
                "end": 540257
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-299",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-332"
            ],
            "outputs": [
                "t-333"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 540346,
                "end": 540363
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-300",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-333",
                "t-334"
            ],
            "outputs": [
                "t-335"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 17,
                "start": 540453,
                "end": 540470
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-301",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-335",
                "t-333"
            ],
            "outputs": [
                "t-336"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 17,
                "start": 540753,
                "end": 540770
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-302",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-6",
                "t-329",
                "t-336"
            ],
            "outputs": [
                "t-337"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 540862,
                "end": 540875
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-303",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-307",
                "t-9"
            ],
            "outputs": [
                "t-338"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 18,
                "start": 540974,
                "end": 540992
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-304",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-339",
                "t-333"
            ],
            "outputs": [
                "t-340"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 541081,
                "end": 541094
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-305",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-340",
                "t-338"
            ],
            "outputs": [
                "t-341"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 541175,
                "end": 541185
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-306",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-342",
                "t-333"
            ],
            "outputs": [
                "t-343"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 541265,
                "end": 541276
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-307",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-343",
                "t-338",
                "t-338"
            ],
            "outputs": [
                "t-344"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 541364,
                "end": 541376
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-308",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-344"
            ],
            "outputs": [
                "t-345"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 541465,
                "end": 541480
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-309",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-345",
                "t-346"
            ],
            "outputs": [
                "t-347"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 541570,
                "end": 541585
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-310",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-347",
                "t-345"
            ],
            "outputs": [
                "t-348"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 541682,
                "end": 541694
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-311",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-9",
                "t-341",
                "t-348"
            ],
            "outputs": [
                "t-349"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 14,
                "start": 541806,
                "end": 541820
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-312",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-306",
                "t-10"
            ],
            "outputs": [
                "t-350"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 17,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 17,
                "start": 541925,
                "end": 541942
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-313",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-351",
                "t-345"
            ],
            "outputs": [
                "t-352"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 542036,
                "end": 542049
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-314",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-352",
                "t-350"
            ],
            "outputs": [
                "t-353"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 542138,
                "end": 542148
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-315",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-354",
                "t-345"
            ],
            "outputs": [
                "t-355"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 542225,
                "end": 542236
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-316",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-355",
                "t-350",
                "t-350"
            ],
            "outputs": [
                "t-356"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 542317,
                "end": 542328
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-317",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-356"
            ],
            "outputs": [
                "t-357"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 542412,
                "end": 542426
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-318",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-357",
                "t-358"
            ],
            "outputs": [
                "t-359"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 542522,
                "end": 542537
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-319",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-359",
                "t-357"
            ],
            "outputs": [
                "t-360"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 542627,
                "end": 542639
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-320",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-10",
                "t-353",
                "t-360"
            ],
            "outputs": [
                "t-361"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 542728,
                "end": 542740
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-321",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-305",
                "t-13"
            ],
            "outputs": [
                "t-362"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 14,
                "start": 542838,
                "end": 542852
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-322",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-363",
                "t-357"
            ],
            "outputs": [
                "t-364"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 542948,
                "end": 542960
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-323",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-364",
                "t-362"
            ],
            "outputs": [
                "t-365"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 543042,
                "end": 543052
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-324",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-366",
                "t-357"
            ],
            "outputs": [
                "t-367"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 543136,
                "end": 543146
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-325",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-367",
                "t-362",
                "t-362"
            ],
            "outputs": [
                "t-368"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 543231,
                "end": 543243
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-326",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-368"
            ],
            "outputs": [
                "t-369"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 543325,
                "end": 543340
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-327",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-369",
                "t-370"
            ],
            "outputs": [
                "t-371"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 543427,
                "end": 543442
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-328",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-371",
                "t-369"
            ],
            "outputs": [
                "t-372"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 543528,
                "end": 543541
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-329",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-13",
                "t-365",
                "t-372"
            ],
            "outputs": [
                "t-373"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 543625,
                "end": 543637
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-330",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-304",
                "t-14"
            ],
            "outputs": [
                "t-374"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 543732,
                "end": 543748
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-331",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-375",
                "t-369"
            ],
            "outputs": [
                "t-376"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 543833,
                "end": 543844
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-332",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-376",
                "t-374"
            ],
            "outputs": [
                "t-377"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 543922,
                "end": 543932
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-333",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-378",
                "t-369"
            ],
            "outputs": [
                "t-379"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 544010,
                "end": 544020
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-334",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-379",
                "t-374",
                "t-374"
            ],
            "outputs": [
                "t-380"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 544109,
                "end": 544120
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-335",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-380"
            ],
            "outputs": [
                "t-381"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 544203,
                "end": 544217
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-336",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-381",
                "t-382"
            ],
            "outputs": [
                "t-383"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 544302,
                "end": 544317
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-337",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-383",
                "t-381"
            ],
            "outputs": [
                "t-384"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 11,
                "start": 544397,
                "end": 544408
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-338",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-14",
                "t-377",
                "t-384"
            ],
            "outputs": [
                "t-385"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 544490,
                "end": 544502
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-339",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-303",
                "t-17"
            ],
            "outputs": [
                "t-386"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 544592,
                "end": 544607
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-340",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-387",
                "t-381"
            ],
            "outputs": [
                "t-388"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 544692,
                "end": 544704
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-341",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-388",
                "t-386"
            ],
            "outputs": [
                "t-389"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 544792,
                "end": 544802
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-342",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-390",
                "t-381"
            ],
            "outputs": [
                "t-391"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 544897,
                "end": 544907
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-343",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-391",
                "t-386",
                "t-386"
            ],
            "outputs": [
                "t-392"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 545002,
                "end": 545014
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-344",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-392"
            ],
            "outputs": [
                "t-393"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 545091,
                "end": 545105
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-345",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-393",
                "t-394"
            ],
            "outputs": [
                "t-395"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 16,
                "start": 545193,
                "end": 545209
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-346",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-395",
                "t-393"
            ],
            "outputs": [
                "t-396"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 545294,
                "end": 545306
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-347",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-17",
                "t-389",
                "t-396"
            ],
            "outputs": [
                "t-397"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 545391,
                "end": 545404
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-348",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-302",
                "t-18"
            ],
            "outputs": [
                "t-398"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 545497,
                "end": 545513
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-349",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-399",
                "t-393"
            ],
            "outputs": [
                "t-400"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 545593,
                "end": 545605
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-350",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-400",
                "t-398"
            ],
            "outputs": [
                "t-401"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 545688,
                "end": 545698
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-351",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-402",
                "t-393"
            ],
            "outputs": [
                "t-403"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 545785,
                "end": 545796
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-352",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-403",
                "t-398",
                "t-398"
            ],
            "outputs": [
                "t-404"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 545881,
                "end": 545893
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-353",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-404"
            ],
            "outputs": [
                "t-405"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 545969,
                "end": 545987
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-354",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-405",
                "t-406"
            ],
            "outputs": [
                "t-407"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 546079,
                "end": 546093
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-355",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-407",
                "t-405"
            ],
            "outputs": [
                "t-408"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 546191,
                "end": 546203
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-356",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-18",
                "t-401",
                "t-408"
            ],
            "outputs": [
                "t-409"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 546286,
                "end": 546299
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-357",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-301",
                "t-21"
            ],
            "outputs": [
                "t-410"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 546410,
                "end": 546425
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-358",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-411",
                "t-405"
            ],
            "outputs": [
                "t-412"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 546506,
                "end": 546519
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-359",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-412",
                "t-410"
            ],
            "outputs": [
                "t-413"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 546601,
                "end": 546611
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-360",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-414",
                "t-405"
            ],
            "outputs": [
                "t-415"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 546694,
                "end": 546705
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-361",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-415",
                "t-410",
                "t-410"
            ],
            "outputs": [
                "t-416"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 546804,
                "end": 546815
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-362",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-416"
            ],
            "outputs": [
                "t-417"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 18,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 18,
                "start": 546894,
                "end": 546912
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-363",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-417",
                "t-418"
            ],
            "outputs": [
                "t-419"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 546993,
                "end": 547008
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-364",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-419",
                "t-417"
            ],
            "outputs": [
                "t-420"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 547093,
                "end": 547105
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-365",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-21",
                "t-413",
                "t-420"
            ],
            "outputs": [
                "t-421"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 547199,
                "end": 547211
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-366",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-300",
                "t-22"
            ],
            "outputs": [
                "t-422"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 547303,
                "end": 547319
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-367",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-423",
                "t-417"
            ],
            "outputs": [
                "t-424"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 547399,
                "end": 547411
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-368",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-424",
                "t-422"
            ],
            "outputs": [
                "t-425"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 547494,
                "end": 547504
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-369",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-426",
                "t-417"
            ],
            "outputs": [
                "t-427"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 547593,
                "end": 547603
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-370",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-427",
                "t-422",
                "t-422"
            ],
            "outputs": [
                "t-428"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 547685,
                "end": 547697
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-371",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-428"
            ],
            "outputs": [
                "t-429"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 547770,
                "end": 547784
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-372",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-429",
                "t-430"
            ],
            "outputs": [
                "t-431"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 547874,
                "end": 547889
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-373",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-431",
                "t-429"
            ],
            "outputs": [
                "t-432"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 547995,
                "end": 548007
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-374",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-22",
                "t-425",
                "t-432"
            ],
            "outputs": [
                "t-433"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 548089,
                "end": 548101
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-375",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-299",
                "t-25"
            ],
            "outputs": [
                "t-434"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 16,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 16,
                "start": 548197,
                "end": 548213
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-376",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-435",
                "t-429"
            ],
            "outputs": [
                "t-436"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 548293,
                "end": 548305
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-377",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-436",
                "t-434"
            ],
            "outputs": [
                "t-437"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 548391,
                "end": 548402
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-378",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-438",
                "t-429"
            ],
            "outputs": [
                "t-439"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 548492,
                "end": 548503
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-379",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-439",
                "t-434",
                "t-434"
            ],
            "outputs": [
                "t-440"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 548597,
                "end": 548608
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-380",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-440"
            ],
            "outputs": [
                "t-441"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 548692,
                "end": 548707
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-381",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-441",
                "t-442"
            ],
            "outputs": [
                "t-443"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 548801,
                "end": 548816
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-382",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-443",
                "t-441"
            ],
            "outputs": [
                "t-444"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 548904,
                "end": 548916
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-383",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-25",
                "t-437",
                "t-444"
            ],
            "outputs": [
                "t-445"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 549004,
                "end": 549017
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-384",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-298",
                "t-26"
            ],
            "outputs": [
                "t-446"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 549118,
                "end": 549133
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-385",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-447",
                "t-441"
            ],
            "outputs": [
                "t-448"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 549217,
                "end": 549229
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-386",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-448",
                "t-446"
            ],
            "outputs": [
                "t-449"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 549325,
                "end": 549335
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-387",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-450",
                "t-441"
            ],
            "outputs": [
                "t-451"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 549424,
                "end": 549435
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-388",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-451",
                "t-446",
                "t-446"
            ],
            "outputs": [
                "t-452"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 11,
                "start": 549524,
                "end": 549535
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-389",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-452"
            ],
            "outputs": [
                "t-453"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 549607,
                "end": 549622
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-390",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-453",
                "t-454"
            ],
            "outputs": [
                "t-455"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 549704,
                "end": 549718
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-391",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-455",
                "t-453"
            ],
            "outputs": [
                "t-456"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 13,
                "start": 549818,
                "end": 549831
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-392",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-26",
                "t-449",
                "t-456"
            ],
            "outputs": [
                "t-457"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 549912,
                "end": 549925
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-393",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512,
                    512
                ]
            },
            "inputs": [
                "t-285",
                "t-29"
            ],
            "outputs": [
                "t-458"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 262144.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 550021,
                "end": 550036
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-394",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-459",
                "t-453"
            ],
            "outputs": [
                "t-460"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 550115,
                "end": 550128
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-395",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-460",
                "t-458"
            ],
            "outputs": [
                "t-461"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 550209,
                "end": 550219
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-396",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-462",
                "t-453"
            ],
            "outputs": [
                "t-463"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 550296,
                "end": 550307
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-397",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-463",
                "t-458",
                "t-458"
            ],
            "outputs": [
                "t-464"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 13,
                "start": 550389,
                "end": 550402
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-398",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-464"
            ],
            "outputs": [
                "t-465"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 550478,
                "end": 550492
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-399",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-465",
                "t-466"
            ],
            "outputs": [
                "t-467"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 550579,
                "end": 550594
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-400",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-467",
                "t-465"
            ],
            "outputs": [
                "t-468"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 550683,
                "end": 550695
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-401",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-29",
                "t-461",
                "t-468"
            ],
            "outputs": [
                "t-469"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 550777,
                "end": 550789
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-402",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    512
                ]
            },
            "inputs": [
                "t-284",
                "t-30"
            ],
            "outputs": [
                "t-470"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 512.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 19,
                "start": 550877,
                "end": 550896
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-403",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-471",
                "t-465"
            ],
            "outputs": [
                "t-472"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 12,
                "start": 550986,
                "end": 550998
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-404",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-472",
                "t-470"
            ],
            "outputs": [
                "t-473"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 11,
                "start": 551082,
                "end": 551093
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-405",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-474",
                "t-465"
            ],
            "outputs": [
                "t-475"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 551170,
                "end": 551181
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-406",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-475",
                "t-470",
                "t-470"
            ],
            "outputs": [
                "t-476"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 551264,
                "end": 551276
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-407",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-476"
            ],
            "outputs": [
                "t-477"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 551352,
                "end": 551366
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-408",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-477",
                "t-478"
            ],
            "outputs": [
                "t-479"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 551456,
                "end": 551471
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-409",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-479",
                "t-477"
            ],
            "outputs": [
                "t-480"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 551560,
                "end": 551572
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-410",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-30",
                "t-473",
                "t-480"
            ],
            "outputs": [
                "t-481"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 551653,
                "end": 551665
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-411",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10,
                    512
                ]
            },
            "inputs": [
                "t-283",
                "t-33"
            ],
            "outputs": [
                "t-482"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 5120.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 19,
                "start": 551753,
                "end": 551772
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-412",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-483",
                "t-477"
            ],
            "outputs": [
                "t-484"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 551859,
                "end": 551872
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-413",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-484",
                "t-482"
            ],
            "outputs": [
                "t-485"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 551949,
                "end": 551959
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-414",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-486",
                "t-477"
            ],
            "outputs": [
                "t-487"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 11,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 11,
                "start": 552042,
                "end": 552053
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-415",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-487",
                "t-482",
                "t-482"
            ],
            "outputs": [
                "t-488"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 552130,
                "end": 552142
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-416",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-488"
            ],
            "outputs": [
                "t-489"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 14,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 14,
                "start": 552218,
                "end": 552232
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-417",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-489",
                "t-490"
            ],
            "outputs": [
                "t-491"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 19,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 19,
                "start": 552310,
                "end": 552329
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-418",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-491",
                "t-489"
            ],
            "outputs": [
                "t-492"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 552410,
                "end": 552422
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-419",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-33",
                "t-485",
                "t-492"
            ],
            "outputs": [
                "t-493"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 13,
                "start": 552508,
                "end": 552521
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-420",
            "optype": "aten::add",
            "params": {
                "mat_size": [
                    10
                ]
            },
            "inputs": [
                "t-282",
                "t-34"
            ],
            "outputs": [
                "t-494"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 10.0
            },
            "args": [
                0.0001
            ],
            "runtime": {
                "duration": 15,
                "start": 552609,
                "end": 552624
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 83, in adam\n    grad = grad.add(param, alpha=weight_decay)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-421",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-495",
                "t-489"
            ],
            "outputs": [
                "t-496"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 13,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 13,
                "start": 552709,
                "end": 552722
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-422",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-496",
                "t-494"
            ],
            "outputs": [
                "t-497"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [
                0.09999999999999998
            ],
            "runtime": {
                "duration": 10,
                "start": 552799,
                "end": 552809
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 86, in adam\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-423",
            "optype": "aten::mul_",
            "params": {},
            "inputs": [
                "t-498",
                "t-489"
            ],
            "outputs": [
                "t-499"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 10,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 10,
                "start": 552890,
                "end": 552900
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-424",
            "optype": "aten::addcmul_",
            "params": {},
            "inputs": [
                "t-499",
                "t-494",
                "t-494"
            ],
            "outputs": [
                "t-500"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                0.0010000000000000009
            ],
            "runtime": {
                "duration": 12,
                "start": 552979,
                "end": 552991
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 87, in adam\n    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-425",
            "optype": "aten::sqrt",
            "params": {},
            "inputs": [
                "t-500"
            ],
            "outputs": [
                "t-501"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 553078,
                "end": 553093
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-426",
            "optype": "aten::div",
            "params": {},
            "inputs": [
                "t-501",
                "t-502"
            ],
            "outputs": [
                "t-503"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 15,
                "flops": 0.0
            },
            "args": [],
            "runtime": {
                "duration": 15,
                "start": 553184,
                "end": 553199
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-427",
            "optype": "aten::add_",
            "params": {},
            "inputs": [
                "t-503",
                "t-501"
            ],
            "outputs": [
                "t-504"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                1
            ],
            "runtime": {
                "duration": 12,
                "start": 553285,
                "end": 553297
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 94, in adam\n    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n"
            ]
        },
        {
            "name": "Optimizer.step#Adam.step/op-428",
            "optype": "aten::addcdiv_",
            "params": {},
            "inputs": [
                "t-34",
                "t-497",
                "t-504"
            ],
            "outputs": [
                "t-505"
            ],
            "stats": {
                "cycles": 0.0,
                "instructions": 0.0,
                "l1_read": 0.0,
                "l1_write": 0.0,
                "llc_access": 0.0,
                "microseconds": 12,
                "flops": 0.0
            },
            "args": [
                -0.005815644082582146
            ],
            "runtime": {
                "duration": 12,
                "start": 553382,
                "end": 553394
            },
            "stack": [
                "  File \"ddp_mlp.py\", line 265, in <module>\n    init_processes(args)\n",
                "  File \"ddp_mlp.py\", line 71, in init_processes\n    avg_ips = train_and_test(local_rank, train_args)\n",
                "  File \"ddp_mlp.py\", line 173, in train_and_test\n    optimizer.step()\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n    return func(*args, **kwargs)\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 133, in step\n    F.adam(params_with_grad,\n",
                "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\", line 98, in adam\n    param.addcdiv_(exp_avg, denom, value=-step_size)\n"
            ]
        }
    ],
    "tensors": {
        "t-1": {
            "name": "t-1",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-2": {
            "name": "t-2",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-4": {
            "name": "t-4",
            "dtype": "FP32",
            "shape": [
                256,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-3": {
            "name": "t-3",
            "dtype": "FP32",
            "shape": [
                256,
                1,
                28,
                28
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-7": {
            "name": "t-7",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-5": {
            "name": "t-5",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-6": {
            "name": "t-6",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-8": {
            "name": "t-8",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-11": {
            "name": "t-11",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-9": {
            "name": "t-9",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-10": {
            "name": "t-10",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-12": {
            "name": "t-12",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-15": {
            "name": "t-15",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-13": {
            "name": "t-13",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-14": {
            "name": "t-14",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-16": {
            "name": "t-16",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-19": {
            "name": "t-19",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-17": {
            "name": "t-17",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-18": {
            "name": "t-18",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-20": {
            "name": "t-20",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-23": {
            "name": "t-23",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-21": {
            "name": "t-21",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-22": {
            "name": "t-22",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-24": {
            "name": "t-24",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-27": {
            "name": "t-27",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-25": {
            "name": "t-25",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-26": {
            "name": "t-26",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-28": {
            "name": "t-28",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-31": {
            "name": "t-31",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-29": {
            "name": "t-29",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-30": {
            "name": "t-30",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-32": {
            "name": "t-32",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-35": {
            "name": "t-35",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-33": {
            "name": "t-33",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-34": {
            "name": "t-34",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-36": {
            "name": "t-36",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-38": {
            "name": "t-38",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-37": {
            "name": "t-37",
            "dtype": "INT64",
            "shape": [
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-39": {
            "name": "t-39",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-43": {
            "name": "t-43",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-40": {
            "name": "t-40",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-41": {
            "name": "t-41",
            "dtype": "BIN",
            "shape": [
                0
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-42": {
            "name": "t-42",
            "dtype": "FP32",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-44": {
            "name": "t-44",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-45": {
            "name": "t-45",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-46": {
            "name": "t-46",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-47": {
            "name": "t-47",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-48": {
            "name": "t-48",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-50": {
            "name": "t-50",
            "dtype": "FP32",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-47",
            "allocation": null
        },
        "t-49": {
            "name": "t-49",
            "dtype": "UINT8",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-51": {
            "name": "t-51",
            "dtype": "BIN",
            "shape": [
                256,
                10
            ],
            "const": false,
            "view": "t-49",
            "allocation": null
        },
        "t-52": {
            "name": "t-52",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-54": {
            "name": "t-54",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-53": {
            "name": "t-53",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-55": {
            "name": "t-55",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-56": {
            "name": "t-56",
            "dtype": "FP32",
            "shape": [
                10,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-57": {
            "name": "t-57",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-58": {
            "name": "t-58",
            "dtype": "FP32",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-59": {
            "name": "t-59",
            "dtype": "FP32",
            "shape": [
                1,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-60": {
            "name": "t-60",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-61": {
            "name": "t-61",
            "dtype": "BIN",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-62": {
            "name": "t-62",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-63": {
            "name": "t-63",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-64": {
            "name": "t-64",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-62",
            "allocation": null
        },
        "t-65": {
            "name": "t-65",
            "dtype": "BIN",
            "shape": [
                512,
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-66": {
            "name": "t-66",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-64",
            "allocation": null
        },
        "t-68": {
            "name": "t-68",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-67",
            "allocation": null
        },
        "t-67": {
            "name": "t-67",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-70": {
            "name": "t-70",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-69",
            "allocation": null
        },
        "t-69": {
            "name": "t-69",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-71": {
            "name": "t-71",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-72": {
            "name": "t-72",
            "dtype": "BIN",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-73": {
            "name": "t-73",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-75": {
            "name": "t-75",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-74",
            "allocation": null
        },
        "t-74": {
            "name": "t-74",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-77": {
            "name": "t-77",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-76",
            "allocation": null
        },
        "t-76": {
            "name": "t-76",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-79": {
            "name": "t-79",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-78": {
            "name": "t-78",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-80": {
            "name": "t-80",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-78",
            "allocation": null
        },
        "t-81": {
            "name": "t-81",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-83": {
            "name": "t-83",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-82": {
            "name": "t-82",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-84": {
            "name": "t-84",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-85": {
            "name": "t-85",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-86": {
            "name": "t-86",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-87": {
            "name": "t-87",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-88": {
            "name": "t-88",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-89": {
            "name": "t-89",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-90": {
            "name": "t-90",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-91": {
            "name": "t-91",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-92": {
            "name": "t-92",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-93": {
            "name": "t-93",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-91",
            "allocation": null
        },
        "t-94": {
            "name": "t-94",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-95": {
            "name": "t-95",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-93",
            "allocation": null
        },
        "t-97": {
            "name": "t-97",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-96",
            "allocation": null
        },
        "t-96": {
            "name": "t-96",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-99": {
            "name": "t-99",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-98",
            "allocation": null
        },
        "t-98": {
            "name": "t-98",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-100": {
            "name": "t-100",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-101": {
            "name": "t-101",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-87",
            "allocation": null
        },
        "t-102": {
            "name": "t-102",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-104": {
            "name": "t-104",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-103",
            "allocation": null
        },
        "t-103": {
            "name": "t-103",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-106": {
            "name": "t-106",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-105",
            "allocation": null
        },
        "t-105": {
            "name": "t-105",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-107": {
            "name": "t-107",
            "dtype": "FP32",
            "shape": [
                267786
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-109": {
            "name": "t-109",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-108": {
            "name": "t-108",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-110": {
            "name": "t-110",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-108",
            "allocation": null
        },
        "t-111": {
            "name": "t-111",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-113": {
            "name": "t-113",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-112": {
            "name": "t-112",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-114": {
            "name": "t-114",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-115": {
            "name": "t-115",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-116": {
            "name": "t-116",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-86",
            "allocation": null
        },
        "t-117": {
            "name": "t-117",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-118": {
            "name": "t-118",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-119": {
            "name": "t-119",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-120": {
            "name": "t-120",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-121": {
            "name": "t-121",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-122": {
            "name": "t-122",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-123": {
            "name": "t-123",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-121",
            "allocation": null
        },
        "t-124": {
            "name": "t-124",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-125": {
            "name": "t-125",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-123",
            "allocation": null
        },
        "t-127": {
            "name": "t-127",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-126",
            "allocation": null
        },
        "t-126": {
            "name": "t-126",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-129": {
            "name": "t-129",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-128",
            "allocation": null
        },
        "t-128": {
            "name": "t-128",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-130": {
            "name": "t-130",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-131": {
            "name": "t-131",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-117",
            "allocation": null
        },
        "t-132": {
            "name": "t-132",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-134": {
            "name": "t-134",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-133",
            "allocation": null
        },
        "t-133": {
            "name": "t-133",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-136": {
            "name": "t-136",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-135",
            "allocation": null
        },
        "t-135": {
            "name": "t-135",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-138": {
            "name": "t-138",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-137": {
            "name": "t-137",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-139": {
            "name": "t-139",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-137",
            "allocation": null
        },
        "t-140": {
            "name": "t-140",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-142": {
            "name": "t-142",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-141": {
            "name": "t-141",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-143": {
            "name": "t-143",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-144": {
            "name": "t-144",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-145": {
            "name": "t-145",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-116",
            "allocation": null
        },
        "t-146": {
            "name": "t-146",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-131",
            "allocation": null
        },
        "t-147": {
            "name": "t-147",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-148": {
            "name": "t-148",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-149": {
            "name": "t-149",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-150": {
            "name": "t-150",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-151": {
            "name": "t-151",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-152": {
            "name": "t-152",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-150",
            "allocation": null
        },
        "t-153": {
            "name": "t-153",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-154": {
            "name": "t-154",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-152",
            "allocation": null
        },
        "t-156": {
            "name": "t-156",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-155",
            "allocation": null
        },
        "t-155": {
            "name": "t-155",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-158": {
            "name": "t-158",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-157",
            "allocation": null
        },
        "t-157": {
            "name": "t-157",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-159": {
            "name": "t-159",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-160": {
            "name": "t-160",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-146",
            "allocation": null
        },
        "t-161": {
            "name": "t-161",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-163": {
            "name": "t-163",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-162",
            "allocation": null
        },
        "t-162": {
            "name": "t-162",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-165": {
            "name": "t-165",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-164",
            "allocation": null
        },
        "t-164": {
            "name": "t-164",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-167": {
            "name": "t-167",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-166": {
            "name": "t-166",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-168": {
            "name": "t-168",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-166",
            "allocation": null
        },
        "t-169": {
            "name": "t-169",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-171": {
            "name": "t-171",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-170": {
            "name": "t-170",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-172": {
            "name": "t-172",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-173": {
            "name": "t-173",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-174": {
            "name": "t-174",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-145",
            "allocation": null
        },
        "t-175": {
            "name": "t-175",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-160",
            "allocation": null
        },
        "t-176": {
            "name": "t-176",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-177": {
            "name": "t-177",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-178": {
            "name": "t-178",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-179": {
            "name": "t-179",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-180": {
            "name": "t-180",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-181": {
            "name": "t-181",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-179",
            "allocation": null
        },
        "t-182": {
            "name": "t-182",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-183": {
            "name": "t-183",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-181",
            "allocation": null
        },
        "t-185": {
            "name": "t-185",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-184",
            "allocation": null
        },
        "t-184": {
            "name": "t-184",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-187": {
            "name": "t-187",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-186",
            "allocation": null
        },
        "t-186": {
            "name": "t-186",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-188": {
            "name": "t-188",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-189": {
            "name": "t-189",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-175",
            "allocation": null
        },
        "t-190": {
            "name": "t-190",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-192": {
            "name": "t-192",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-191",
            "allocation": null
        },
        "t-191": {
            "name": "t-191",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-194": {
            "name": "t-194",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-193",
            "allocation": null
        },
        "t-193": {
            "name": "t-193",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-196": {
            "name": "t-196",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-195": {
            "name": "t-195",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-197": {
            "name": "t-197",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-172",
            "allocation": null
        },
        "t-198": {
            "name": "t-198",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-200": {
            "name": "t-200",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-199": {
            "name": "t-199",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-201": {
            "name": "t-201",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-202": {
            "name": "t-202",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-203": {
            "name": "t-203",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-189",
            "allocation": null
        },
        "t-204": {
            "name": "t-204",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-182",
            "allocation": null
        },
        "t-205": {
            "name": "t-205",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-206": {
            "name": "t-206",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-207": {
            "name": "t-207",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-208": {
            "name": "t-208",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-209": {
            "name": "t-209",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-210": {
            "name": "t-210",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-208",
            "allocation": null
        },
        "t-211": {
            "name": "t-211",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-212": {
            "name": "t-212",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-210",
            "allocation": null
        },
        "t-214": {
            "name": "t-214",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-213",
            "allocation": null
        },
        "t-213": {
            "name": "t-213",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-216": {
            "name": "t-216",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-215",
            "allocation": null
        },
        "t-215": {
            "name": "t-215",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-217": {
            "name": "t-217",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-218": {
            "name": "t-218",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-204",
            "allocation": null
        },
        "t-219": {
            "name": "t-219",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-221": {
            "name": "t-221",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-220",
            "allocation": null
        },
        "t-220": {
            "name": "t-220",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-223": {
            "name": "t-223",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-222",
            "allocation": null
        },
        "t-222": {
            "name": "t-222",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-225": {
            "name": "t-225",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-224": {
            "name": "t-224",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-226": {
            "name": "t-226",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-201",
            "allocation": null
        },
        "t-227": {
            "name": "t-227",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-229": {
            "name": "t-229",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-228": {
            "name": "t-228",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-230": {
            "name": "t-230",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-231": {
            "name": "t-231",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-232": {
            "name": "t-232",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-218",
            "allocation": null
        },
        "t-233": {
            "name": "t-233",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-211",
            "allocation": null
        },
        "t-234": {
            "name": "t-234",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-235": {
            "name": "t-235",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-236": {
            "name": "t-236",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-237": {
            "name": "t-237",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-238": {
            "name": "t-238",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-239": {
            "name": "t-239",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-237",
            "allocation": null
        },
        "t-240": {
            "name": "t-240",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-241": {
            "name": "t-241",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-239",
            "allocation": null
        },
        "t-243": {
            "name": "t-243",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-242",
            "allocation": null
        },
        "t-242": {
            "name": "t-242",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-245": {
            "name": "t-245",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-244",
            "allocation": null
        },
        "t-244": {
            "name": "t-244",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-246": {
            "name": "t-246",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-247": {
            "name": "t-247",
            "dtype": "BIN",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-233",
            "allocation": null
        },
        "t-248": {
            "name": "t-248",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-250": {
            "name": "t-250",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-249",
            "allocation": null
        },
        "t-249": {
            "name": "t-249",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-252": {
            "name": "t-252",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-251",
            "allocation": null
        },
        "t-251": {
            "name": "t-251",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-254": {
            "name": "t-254",
            "dtype": "FP32",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-253": {
            "name": "t-253",
            "dtype": "UINT8",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-255": {
            "name": "t-255",
            "dtype": "BIN",
            "shape": [
                256,
                512
            ],
            "const": false,
            "view": "t-230",
            "allocation": null
        },
        "t-256": {
            "name": "t-256",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-257": {
            "name": "t-257",
            "dtype": "FP32",
            "shape": [
                512,
                256
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-258": {
            "name": "t-258",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-259": {
            "name": "t-259",
            "dtype": "FP32",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-260": {
            "name": "t-260",
            "dtype": "FP32",
            "shape": [
                1,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-261": {
            "name": "t-261",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-262": {
            "name": "t-262",
            "dtype": "BIN",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-263": {
            "name": "t-263",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-264": {
            "name": "t-264",
            "dtype": "BIN",
            "shape": [
                784,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-265": {
            "name": "t-265",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": "t-263",
            "allocation": null
        },
        "t-267": {
            "name": "t-267",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-266",
            "allocation": null
        },
        "t-266": {
            "name": "t-266",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-269": {
            "name": "t-269",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-268",
            "allocation": null
        },
        "t-268": {
            "name": "t-268",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-270": {
            "name": "t-270",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-271": {
            "name": "t-271",
            "dtype": "BIN",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-272": {
            "name": "t-272",
            "dtype": "BIN",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-274": {
            "name": "t-274",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-273",
            "allocation": null
        },
        "t-273": {
            "name": "t-273",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-276": {
            "name": "t-276",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-275",
            "allocation": null
        },
        "t-275": {
            "name": "t-275",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-277": {
            "name": "t-277",
            "dtype": "FP32",
            "shape": [
                1715200
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-278": {
            "name": "t-278",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-279": {
            "name": "t-279",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-280": {
            "name": "t-280",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-281": {
            "name": "t-281",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-282": {
            "name": "t-282",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-68",
            "allocation": null
        },
        "t-283": {
            "name": "t-283",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-75",
            "allocation": null
        },
        "t-284": {
            "name": "t-284",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-97",
            "allocation": null
        },
        "t-285": {
            "name": "t-285",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-104",
            "allocation": null
        },
        "t-286": {
            "name": "t-286",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-287": {
            "name": "t-287",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-288": {
            "name": "t-288",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-289": {
            "name": "t-289",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-290": {
            "name": "t-290",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-291": {
            "name": "t-291",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-292": {
            "name": "t-292",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-293": {
            "name": "t-293",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-294": {
            "name": "t-294",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-295": {
            "name": "t-295",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-296": {
            "name": "t-296",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-297": {
            "name": "t-297",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-298": {
            "name": "t-298",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-127",
            "allocation": null
        },
        "t-299": {
            "name": "t-299",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-134",
            "allocation": null
        },
        "t-300": {
            "name": "t-300",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-156",
            "allocation": null
        },
        "t-301": {
            "name": "t-301",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-163",
            "allocation": null
        },
        "t-302": {
            "name": "t-302",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-185",
            "allocation": null
        },
        "t-303": {
            "name": "t-303",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-192",
            "allocation": null
        },
        "t-304": {
            "name": "t-304",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-214",
            "allocation": null
        },
        "t-305": {
            "name": "t-305",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-221",
            "allocation": null
        },
        "t-306": {
            "name": "t-306",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-243",
            "allocation": null
        },
        "t-307": {
            "name": "t-307",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-250",
            "allocation": null
        },
        "t-308": {
            "name": "t-308",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-267",
            "allocation": null
        },
        "t-309": {
            "name": "t-309",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-274",
            "allocation": null
        },
        "t-310": {
            "name": "t-310",
            "dtype": "FP32",
            "shape": [
                1
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-311": {
            "name": "t-311",
            "dtype": "UINT8",
            "shape": [
                16
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-312": {
            "name": "t-312",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-315": {
            "name": "t-315",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-313",
            "allocation": null
        },
        "t-313": {
            "name": "t-313",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-314": {
            "name": "t-314",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-316": {
            "name": "t-316",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-315",
            "allocation": null
        },
        "t-318": {
            "name": "t-318",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-317",
            "allocation": null
        },
        "t-317": {
            "name": "t-317",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-319": {
            "name": "t-319",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-318",
            "allocation": null
        },
        "t-320": {
            "name": "t-320",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-322": {
            "name": "t-322",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-321": {
            "name": "t-321",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-323": {
            "name": "t-323",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-322",
            "allocation": null
        },
        "t-324": {
            "name": "t-324",
            "dtype": "FP32",
            "shape": [
                512,
                784
            ],
            "const": false,
            "view": "t-5",
            "allocation": null
        },
        "t-325": {
            "name": "t-325",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-328": {
            "name": "t-328",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-326",
            "allocation": null
        },
        "t-326": {
            "name": "t-326",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-327": {
            "name": "t-327",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-329": {
            "name": "t-329",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-328",
            "allocation": null
        },
        "t-331": {
            "name": "t-331",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-330",
            "allocation": null
        },
        "t-330": {
            "name": "t-330",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-332": {
            "name": "t-332",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-331",
            "allocation": null
        },
        "t-333": {
            "name": "t-333",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-335": {
            "name": "t-335",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-334": {
            "name": "t-334",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-336": {
            "name": "t-336",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-335",
            "allocation": null
        },
        "t-337": {
            "name": "t-337",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-6",
            "allocation": null
        },
        "t-338": {
            "name": "t-338",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-340": {
            "name": "t-340",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-339",
            "allocation": null
        },
        "t-339": {
            "name": "t-339",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-341": {
            "name": "t-341",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-340",
            "allocation": null
        },
        "t-343": {
            "name": "t-343",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-342",
            "allocation": null
        },
        "t-342": {
            "name": "t-342",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-344": {
            "name": "t-344",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-343",
            "allocation": null
        },
        "t-345": {
            "name": "t-345",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-347": {
            "name": "t-347",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-346": {
            "name": "t-346",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-348": {
            "name": "t-348",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-347",
            "allocation": null
        },
        "t-349": {
            "name": "t-349",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-9",
            "allocation": null
        },
        "t-350": {
            "name": "t-350",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-352": {
            "name": "t-352",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-351",
            "allocation": null
        },
        "t-351": {
            "name": "t-351",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-353": {
            "name": "t-353",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-352",
            "allocation": null
        },
        "t-355": {
            "name": "t-355",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-354",
            "allocation": null
        },
        "t-354": {
            "name": "t-354",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-356": {
            "name": "t-356",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-355",
            "allocation": null
        },
        "t-357": {
            "name": "t-357",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-359": {
            "name": "t-359",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-358": {
            "name": "t-358",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-360": {
            "name": "t-360",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-359",
            "allocation": null
        },
        "t-361": {
            "name": "t-361",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-10",
            "allocation": null
        },
        "t-362": {
            "name": "t-362",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-364": {
            "name": "t-364",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-363",
            "allocation": null
        },
        "t-363": {
            "name": "t-363",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-365": {
            "name": "t-365",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-364",
            "allocation": null
        },
        "t-367": {
            "name": "t-367",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-366",
            "allocation": null
        },
        "t-366": {
            "name": "t-366",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-368": {
            "name": "t-368",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-367",
            "allocation": null
        },
        "t-369": {
            "name": "t-369",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-371": {
            "name": "t-371",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-370": {
            "name": "t-370",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-372": {
            "name": "t-372",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-371",
            "allocation": null
        },
        "t-373": {
            "name": "t-373",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-13",
            "allocation": null
        },
        "t-374": {
            "name": "t-374",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-376": {
            "name": "t-376",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-375",
            "allocation": null
        },
        "t-375": {
            "name": "t-375",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-377": {
            "name": "t-377",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-376",
            "allocation": null
        },
        "t-379": {
            "name": "t-379",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-378",
            "allocation": null
        },
        "t-378": {
            "name": "t-378",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-380": {
            "name": "t-380",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-379",
            "allocation": null
        },
        "t-381": {
            "name": "t-381",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-383": {
            "name": "t-383",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-382": {
            "name": "t-382",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-384": {
            "name": "t-384",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-383",
            "allocation": null
        },
        "t-385": {
            "name": "t-385",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-14",
            "allocation": null
        },
        "t-386": {
            "name": "t-386",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-388": {
            "name": "t-388",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-387",
            "allocation": null
        },
        "t-387": {
            "name": "t-387",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-389": {
            "name": "t-389",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-388",
            "allocation": null
        },
        "t-391": {
            "name": "t-391",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-390",
            "allocation": null
        },
        "t-390": {
            "name": "t-390",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-392": {
            "name": "t-392",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-391",
            "allocation": null
        },
        "t-393": {
            "name": "t-393",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-395": {
            "name": "t-395",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-394": {
            "name": "t-394",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-396": {
            "name": "t-396",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-395",
            "allocation": null
        },
        "t-397": {
            "name": "t-397",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-17",
            "allocation": null
        },
        "t-398": {
            "name": "t-398",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-400": {
            "name": "t-400",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-399",
            "allocation": null
        },
        "t-399": {
            "name": "t-399",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-401": {
            "name": "t-401",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-400",
            "allocation": null
        },
        "t-403": {
            "name": "t-403",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-402",
            "allocation": null
        },
        "t-402": {
            "name": "t-402",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-404": {
            "name": "t-404",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-403",
            "allocation": null
        },
        "t-405": {
            "name": "t-405",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-407": {
            "name": "t-407",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-406": {
            "name": "t-406",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-408": {
            "name": "t-408",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-407",
            "allocation": null
        },
        "t-409": {
            "name": "t-409",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-18",
            "allocation": null
        },
        "t-410": {
            "name": "t-410",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-412": {
            "name": "t-412",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-411",
            "allocation": null
        },
        "t-411": {
            "name": "t-411",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-413": {
            "name": "t-413",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-412",
            "allocation": null
        },
        "t-415": {
            "name": "t-415",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-414",
            "allocation": null
        },
        "t-414": {
            "name": "t-414",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-416": {
            "name": "t-416",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-415",
            "allocation": null
        },
        "t-417": {
            "name": "t-417",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-419": {
            "name": "t-419",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-418": {
            "name": "t-418",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-420": {
            "name": "t-420",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-419",
            "allocation": null
        },
        "t-421": {
            "name": "t-421",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-21",
            "allocation": null
        },
        "t-422": {
            "name": "t-422",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-424": {
            "name": "t-424",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-423",
            "allocation": null
        },
        "t-423": {
            "name": "t-423",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-425": {
            "name": "t-425",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-424",
            "allocation": null
        },
        "t-427": {
            "name": "t-427",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-426",
            "allocation": null
        },
        "t-426": {
            "name": "t-426",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-428": {
            "name": "t-428",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-427",
            "allocation": null
        },
        "t-429": {
            "name": "t-429",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-431": {
            "name": "t-431",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-430": {
            "name": "t-430",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-432": {
            "name": "t-432",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-431",
            "allocation": null
        },
        "t-433": {
            "name": "t-433",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-22",
            "allocation": null
        },
        "t-434": {
            "name": "t-434",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-436": {
            "name": "t-436",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-435",
            "allocation": null
        },
        "t-435": {
            "name": "t-435",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-437": {
            "name": "t-437",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-436",
            "allocation": null
        },
        "t-439": {
            "name": "t-439",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-438",
            "allocation": null
        },
        "t-438": {
            "name": "t-438",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-440": {
            "name": "t-440",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-439",
            "allocation": null
        },
        "t-441": {
            "name": "t-441",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-443": {
            "name": "t-443",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-442": {
            "name": "t-442",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-444": {
            "name": "t-444",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-443",
            "allocation": null
        },
        "t-445": {
            "name": "t-445",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-25",
            "allocation": null
        },
        "t-446": {
            "name": "t-446",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-448": {
            "name": "t-448",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-447",
            "allocation": null
        },
        "t-447": {
            "name": "t-447",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-449": {
            "name": "t-449",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-448",
            "allocation": null
        },
        "t-451": {
            "name": "t-451",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-450",
            "allocation": null
        },
        "t-450": {
            "name": "t-450",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-452": {
            "name": "t-452",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-451",
            "allocation": null
        },
        "t-453": {
            "name": "t-453",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-455": {
            "name": "t-455",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-454": {
            "name": "t-454",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-456": {
            "name": "t-456",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-455",
            "allocation": null
        },
        "t-457": {
            "name": "t-457",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-26",
            "allocation": null
        },
        "t-458": {
            "name": "t-458",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-460": {
            "name": "t-460",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-459",
            "allocation": null
        },
        "t-459": {
            "name": "t-459",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-461": {
            "name": "t-461",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-460",
            "allocation": null
        },
        "t-463": {
            "name": "t-463",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-462",
            "allocation": null
        },
        "t-462": {
            "name": "t-462",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-464": {
            "name": "t-464",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-463",
            "allocation": null
        },
        "t-465": {
            "name": "t-465",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-467": {
            "name": "t-467",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-466": {
            "name": "t-466",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-468": {
            "name": "t-468",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-467",
            "allocation": null
        },
        "t-469": {
            "name": "t-469",
            "dtype": "FP32",
            "shape": [
                512,
                512
            ],
            "const": false,
            "view": "t-29",
            "allocation": null
        },
        "t-470": {
            "name": "t-470",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-472": {
            "name": "t-472",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-471",
            "allocation": null
        },
        "t-471": {
            "name": "t-471",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-473": {
            "name": "t-473",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-472",
            "allocation": null
        },
        "t-475": {
            "name": "t-475",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-474",
            "allocation": null
        },
        "t-474": {
            "name": "t-474",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-476": {
            "name": "t-476",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-475",
            "allocation": null
        },
        "t-477": {
            "name": "t-477",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-479": {
            "name": "t-479",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-478": {
            "name": "t-478",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-480": {
            "name": "t-480",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-479",
            "allocation": null
        },
        "t-481": {
            "name": "t-481",
            "dtype": "FP32",
            "shape": [
                512
            ],
            "const": false,
            "view": "t-30",
            "allocation": null
        },
        "t-482": {
            "name": "t-482",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-484": {
            "name": "t-484",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-483",
            "allocation": null
        },
        "t-483": {
            "name": "t-483",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-485": {
            "name": "t-485",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-484",
            "allocation": null
        },
        "t-487": {
            "name": "t-487",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-486",
            "allocation": null
        },
        "t-486": {
            "name": "t-486",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-488": {
            "name": "t-488",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-487",
            "allocation": null
        },
        "t-489": {
            "name": "t-489",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-491": {
            "name": "t-491",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-490": {
            "name": "t-490",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-492": {
            "name": "t-492",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-491",
            "allocation": null
        },
        "t-493": {
            "name": "t-493",
            "dtype": "FP32",
            "shape": [
                10,
                512
            ],
            "const": false,
            "view": "t-33",
            "allocation": null
        },
        "t-494": {
            "name": "t-494",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-496": {
            "name": "t-496",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-495",
            "allocation": null
        },
        "t-495": {
            "name": "t-495",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-497": {
            "name": "t-497",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-496",
            "allocation": null
        },
        "t-499": {
            "name": "t-499",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-498",
            "allocation": null
        },
        "t-498": {
            "name": "t-498",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-500": {
            "name": "t-500",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-499",
            "allocation": null
        },
        "t-501": {
            "name": "t-501",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-503": {
            "name": "t-503",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-502": {
            "name": "t-502",
            "dtype": "FP64",
            "shape": [],
            "const": false,
            "view": null,
            "allocation": null
        },
        "t-504": {
            "name": "t-504",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-503",
            "allocation": null
        },
        "t-505": {
            "name": "t-505",
            "dtype": "FP32",
            "shape": [
                10
            ],
            "const": false,
            "view": "t-34",
            "allocation": null
        }
    },
    "inputs": [
        "t-3",
        "t-5",
        "t-6",
        "t-9",
        "t-10",
        "t-13",
        "t-14",
        "t-17",
        "t-18",
        "t-21",
        "t-22",
        "t-25",
        "t-26",
        "t-29",
        "t-30",
        "t-33",
        "t-34",
        "t-37",
        "t-40",
        "t-41",
        "t-42",
        "t-49",
        "t-53",
        "t-67",
        "t-69",
        "t-74",
        "t-76",
        "t-78",
        "t-82",
        "t-96",
        "t-98",
        "t-103",
        "t-105",
        "t-107",
        "t-108",
        "t-112",
        "t-126",
        "t-128",
        "t-133",
        "t-135",
        "t-137",
        "t-141",
        "t-155",
        "t-157",
        "t-162",
        "t-164",
        "t-166",
        "t-170",
        "t-184",
        "t-186",
        "t-191",
        "t-193",
        "t-195",
        "t-199",
        "t-213",
        "t-215",
        "t-220",
        "t-222",
        "t-224",
        "t-228",
        "t-242",
        "t-244",
        "t-249",
        "t-251",
        "t-253",
        "t-266",
        "t-268",
        "t-273",
        "t-275",
        "t-277",
        "t-313",
        "t-314",
        "t-317",
        "t-321",
        "t-326",
        "t-327",
        "t-330",
        "t-334",
        "t-339",
        "t-342",
        "t-346",
        "t-351",
        "t-354",
        "t-358",
        "t-363",
        "t-366",
        "t-370",
        "t-375",
        "t-378",
        "t-382",
        "t-387",
        "t-390",
        "t-394",
        "t-399",
        "t-402",
        "t-406",
        "t-411",
        "t-414",
        "t-418",
        "t-423",
        "t-426",
        "t-430",
        "t-435",
        "t-438",
        "t-442",
        "t-447",
        "t-450",
        "t-454",
        "t-459",
        "t-462",
        "t-466",
        "t-471",
        "t-474",
        "t-478",
        "t-483",
        "t-486",
        "t-490",
        "t-495",
        "t-498",
        "t-502"
    ],
    "outputs": []
}